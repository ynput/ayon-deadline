{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Deadline addon","text":"<p>Deadline integration for AYON.</p>"},{"location":"license.html","title":"License","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright [yyyy][name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"autoapi/summary.html","title":"Summary","text":"<ul> <li>client<ul> <li>ayon_deadline<ul> <li>abstract_submit_deadline</li> <li>addon</li> <li>constants</li> <li>lib</li> <li>plugins<ul> <li>publish<ul> <li>aftereffects<ul> <li>submit_aftereffects_deadline</li> </ul> </li> <li>blender<ul> <li>submit_blender_deadline</li> </ul> </li> <li>celaction<ul> <li>submit_celaction_deadline</li> </ul> </li> <li>fusion<ul> <li>submit_fusion_deadline</li> </ul> </li> <li>global<ul> <li>collect_deadline_job_env_vars</li> <li>collect_deadline_server_from_instance</li> <li>collect_default_deadline_server</li> <li>collect_environment_file_to_delete</li> <li>collect_jobinfo</li> <li>collect_scene_render_cleanup</li> <li>collect_usd_pinning_env_vars</li> <li>collect_user_credentials</li> <li>extract_last_version_files</li> <li>submit_publish_job</li> <li>validate_deadline_connection</li> <li>validate_deadline_jobinfo</li> <li>validate_deadline_pools</li> <li>validate_expected_and_rendered_files</li> </ul> </li> <li>harmony<ul> <li>submit_harmony_deadline</li> </ul> </li> <li>houdini<ul> <li>submit_houdini_cache_deadline</li> <li>submit_houdini_render_deadline</li> <li>submit_publish_cache_job</li> </ul> </li> <li>max<ul> <li>submit_max_deadline</li> </ul> </li> <li>maya<ul> <li>submit_maya_cache_deadline</li> <li>submit_maya_deadline</li> </ul> </li> <li>nuke<ul> <li>submit_nuke_deadline</li> </ul> </li> <li>unreal<ul> <li>submit_unreal_deadline</li> </ul> </li> </ul> </li> </ul> </li> <li>repository<ul> <li>custom<ul> <li>plugins<ul> <li>Ayon<ul> <li>Ayon</li> </ul> </li> <li>CelAction<ul> <li>CelAction</li> </ul> </li> <li>GlobalJobPreLoad</li> <li>HarmonyAYON<ul> <li>HarmonyAYON</li> </ul> </li> <li>UnrealEngine5<ul> <li>DeadlineRPC</li> <li>JobPreLoad</li> <li>PluginPreLoad</li> <li>UnrealEngine5</li> <li>UnrealEnginePlugins<ul> <li>MoviePipelineDeadline<ul> <li>Content<ul> <li>Python<ul> <li>init_unreal</li> <li>mrq_cli</li> <li>mrq_cli_modes<ul> <li>render_manifest</li> <li>render_queue</li> <li>render_queue_jobs</li> <li>render_sequence</li> <li>utils</li> </ul> </li> <li>mrq_rpc</li> <li>pipeline_actions<ul> <li>render_queue_action</li> </ul> </li> <li>remote_executor</li> </ul> </li> </ul> </li> </ul> </li> <li>UnrealDeadlineService<ul> <li>Content<ul> <li>Python<ul> <li>deadline_command</li> <li>deadline_enums</li> <li>deadline_http</li> <li>deadline_job</li> <li>deadline_menus<ul> <li>base_menu_action</li> <li>deadline_toolbar_menu</li> </ul> </li> <li>deadline_rpc<ul> <li>base_server</li> <li>base_ue_rpc</li> <li>client</li> <li>exceptions</li> <li>factory</li> <li>server</li> <li>validations</li> </ul> </li> <li>deadline_service</li> <li>deadline_utils</li> <li>init_unreal</li> <li>service_actions<ul> <li>submit_job_action</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>UnrealSyncUtil</li> <li>ue_utils<ul> <li>rpc<ul> <li>base_server</li> <li>client</li> <li>exceptions</li> <li>factory</li> <li>server</li> <li>validations</li> </ul> </li> <li>submit_deadline_job</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>scripts<ul> <li>remote_publish</li> </ul> </li> <li>version</li> </ul> </li> </ul> </li> <li>server<ul> <li>settings<ul> <li>main</li> <li>publish_plugins</li> <li>site_settings</li> </ul> </li> </ul> </li> </ul>"},{"location":"autoapi/client/ayon_deadline/index.html","title":"ayon_deadline","text":""},{"location":"autoapi/client/ayon_deadline/index.html#client.ayon_deadline.DeadlineAddon","title":"<code>DeadlineAddon</code>","text":"<p>               Bases: <code>AYONAddon</code>, <code>IPluginPaths</code></p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>class DeadlineAddon(AYONAddon, IPluginPaths):\n    name = \"deadline\"\n    version = __version__\n\n    def initialize(self, studio_settings):\n        deadline_settings = studio_settings[self.name]\n        deadline_servers_info = {\n            url_item[\"name\"]: url_item\n            for url_item in deadline_settings[\"deadline_urls\"]\n        }\n\n        if not deadline_servers_info:\n            self.enabled = False\n            self.log.warning((\n                \"Deadline Webservice URLs are not specified. Disabling addon.\"\n            ))\n\n        self.deadline_servers_info = deadline_servers_info\n\n        self._server_info_by_name: Dict[str, DeadlineServerInfo] = {}\n\n        self._local_settings_cache = CacheItem(lifetime=60)\n\n    def get_plugin_paths(self):\n        \"\"\"Deadline plugin paths.\"\"\"\n        # Note: We are not returning `publish` key because we have overridden\n        # `get_publish_plugin_paths` to return paths host-specific. However,\n        # `get_plugin_paths` still needs to be implemented because it's\n        # abstract on the parent class\n        return {}\n\n    def get_publish_plugin_paths(\n        self,\n        host_name: Optional[str] = None\n    ) -&gt; List[str]:\n        publish_dir = os.path.join(DEADLINE_ADDON_ROOT, \"plugins\", \"publish\")\n        paths = [os.path.join(publish_dir, \"global\")]\n        if host_name:\n            paths.append(os.path.join(publish_dir, host_name))\n        return paths\n\n    def get_server_info_by_name(\n        self,\n        server_name: str,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; DeadlineServerInfo:\n        \"\"\"Returns Deadline server info by name.\n\n        Args:\n            server_name (str): Deadline Server name from Project Settings.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            DeadlineServerInfo: Deadline server info.\n\n        \"\"\"\n        server_info = self._server_info_by_name.get(server_name)\n        if server_info is None:\n            con_info = self.get_deadline_server_connection_info(\n                server_name, local_settings\n            )\n            args = con_info.url, con_info.auth, con_info.verify\n            pools = get_deadline_pools(*args)\n            groups = get_deadline_groups(*args)\n            limit_groups = get_deadline_limit_groups(*args)\n            machines = get_deadline_workers(*args)\n            server_info = DeadlineServerInfo(\n                pools=pools,\n                limit_groups=limit_groups,\n                groups=groups,\n                machines=machines\n            )\n            self._server_info_by_name[server_name] = server_info\n\n        return server_info\n\n    def get_job_info(\n        self,\n        server_name: str,\n        job_id: str,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get job info from Deadline.\n\n        Args:\n            server_name (str): Deadline Server name from project Settings.\n            job_id (str): Deadline job id.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            Optional[Dict[str, Any]]: Job info from Deadline.\n\n        \"\"\"\n        con_info = self.get_deadline_server_connection_info(\n            server_name, local_settings\n        )\n        response = requests.get(\n            f\"{con_info.url}/api/jobs?JobID={job_id}\",\n            auth=con_info.auth,\n            verify=con_info.verify\n        )\n        response.raise_for_status()\n        data = response.json()\n        if data:\n            return data.pop(0)\n        return None\n\n    def submit_job(\n        self,\n        server_name: str,\n        plugin_info: Dict[str, Any],\n        job_info: \"Union[DeadlineJobInfo, Dict[str, Any]]\",\n        aux_files: Optional[List[str]] = None,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Submit job to Deadline.\n\n        Args:\n            server_name (str): Deadline Server name from project Settings.\n            plugin_info (dict): Plugin info data.\n            job_info (Union[DeadlineJobInfo, Dict[str, Any]]): Job info data.\n            aux_files (Optional[List[str]]): List of auxiliary files.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            Dict[str, Any]: Job payload, with 'response' key containing\n                response data.\n\n        \"\"\"\n        if isinstance(job_info, DeadlineJobInfo):\n            job_info = job_info.serialize()\n\n        payload = {\n            \"JobInfo\": job_info,\n            \"PluginInfo\": plugin_info,\n            \"AuxFiles\": aux_files or [],\n        }\n        con_info = self.get_deadline_server_connection_info(\n            server_name, local_settings\n        )\n        response = requests.post(\n            f\"{con_info.url}/api/jobs\",\n            json=payload,\n            timeout=10,\n            auth=con_info.auth,\n            verify=con_info.verify\n        )\n        response.raise_for_status()\n        payload[\"response\"] = response.json()\n        return payload\n\n    def submit_ayon_plugin_job(\n        self,\n        server_name: str,\n        args: \"Union[List[str], str]\",\n        job_info: \"Union[DeadlineJobInfo, Dict[str, Any]]\",\n        aux_files: Optional[List[str]] = None,\n        single_frame_only: bool = True,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Submit job to Deadline using Ayon plugin.\n\n        Args:\n            server_name (str): Deadline Server name from settings.\n            args (Union[List[str], str]): Command line arguments.\n            job_info (Union[DeadlineJobInfo, Dict[str, Any]]): Job info data.\n            aux_files (Optional[List[str]]): List of auxiliary files.\n            single_frame_only (bool): Submit job for single frame only.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            Dict[str, Any]: Job payload, with 'job_id' key.\n\n        \"\"\"\n        if not isinstance(args, str):\n            args = subprocess.list2cmdline(args)\n\n        if isinstance(job_info, DeadlineJobInfo):\n            job_info = job_info.serialize()\n        job_info[\"Plugin\"] = \"Ayon\"\n\n        plugin_info = {\n            \"Version\": AYON_PLUGIN_VERSION,\n            \"Arguments\": args,\n            \"SingleFrameOnly\": \"True\" if single_frame_only else \"False\",\n        }\n        return self.submit_job(\n            server_name,\n            plugin_info,\n            job_info,\n            aux_files,\n            local_settings=local_settings\n        )\n\n    def get_deadline_server_connection_info(\n        self,\n        server_name: str,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; DeadlineConnectionInfo:\n        \"\"\"Get Deadline server info.\n\n        Args:\n            server_name (str): Deadline Server name from project Settings.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            DeadlineConnectionInfo: Server connection information with\n                server url, auth and verify ssl flag.\n\n        \"\"\"\n        dl_server_info = self.deadline_servers_info[server_name]\n        auth = self._get_server_user_auth(dl_server_info, local_settings)\n        return DeadlineConnectionInfo(\n            server_name,\n            dl_server_info[\"value\"].rstrip(\"/\"),\n            auth,\n            not dl_server_info[\"not_verify_ssl\"],\n        )\n\n    def _get_local_settings(self) -&gt; Dict[str, Any]:\n        if not self._local_settings_cache.is_valid:\n            # TODO import 'get_addon_site_settings' when available\n            #   in public 'ayon_api'\n            con = ayon_api.get_server_api_connection()\n            self._local_settings_cache.update_data(\n                con.get_addon_site_settings(\n                    self.name, self.version\n                )\n            )\n        return self._local_settings_cache.get_data()\n\n    def _get_server_user_auth(\n        self,\n        server_info: Dict[str, Any],\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; Optional[Tuple[str, str]]:\n        selected_server_name = server_info[\"name\"]\n\n        require_authentication = server_info[\"require_authentication\"]\n        if require_authentication:\n            if local_settings is None:\n                local_settings = self._get_local_settings()\n\n            for local_info in local_settings[\"local_settings\"]:\n                if selected_server_name != local_info[\"server_name\"]:\n                    continue\n\n                if local_info[\"username\"] and local_info[\"password\"]:\n                    return local_info[\"username\"], local_info[\"password\"]\n\n        default_username = server_info[\"default_username\"]\n        default_password = server_info[\"default_password\"]\n        if default_username and default_password:\n            return default_username, default_password\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/index.html#client.ayon_deadline.DeadlineAddon.get_deadline_server_connection_info","title":"<code>get_deadline_server_connection_info(server_name, local_settings=None)</code>","text":"<p>Get Deadline server info.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from project Settings.</p> required <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeadlineConnectionInfo</code> <code>DeadlineConnectionInfo</code> <p>Server connection information with server url, auth and verify ssl flag.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def get_deadline_server_connection_info(\n    self,\n    server_name: str,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; DeadlineConnectionInfo:\n    \"\"\"Get Deadline server info.\n\n    Args:\n        server_name (str): Deadline Server name from project Settings.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        DeadlineConnectionInfo: Server connection information with\n            server url, auth and verify ssl flag.\n\n    \"\"\"\n    dl_server_info = self.deadline_servers_info[server_name]\n    auth = self._get_server_user_auth(dl_server_info, local_settings)\n    return DeadlineConnectionInfo(\n        server_name,\n        dl_server_info[\"value\"].rstrip(\"/\"),\n        auth,\n        not dl_server_info[\"not_verify_ssl\"],\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/index.html#client.ayon_deadline.DeadlineAddon.get_job_info","title":"<code>get_job_info(server_name, job_id, local_settings=None)</code>","text":"<p>Get job info from Deadline.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from project Settings.</p> required <code>job_id</code> <code>str</code> <p>Deadline job id.</p> required <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Optional[Dict[str, Any]]: Job info from Deadline.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def get_job_info(\n    self,\n    server_name: str,\n    job_id: str,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Get job info from Deadline.\n\n    Args:\n        server_name (str): Deadline Server name from project Settings.\n        job_id (str): Deadline job id.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        Optional[Dict[str, Any]]: Job info from Deadline.\n\n    \"\"\"\n    con_info = self.get_deadline_server_connection_info(\n        server_name, local_settings\n    )\n    response = requests.get(\n        f\"{con_info.url}/api/jobs?JobID={job_id}\",\n        auth=con_info.auth,\n        verify=con_info.verify\n    )\n    response.raise_for_status()\n    data = response.json()\n    if data:\n        return data.pop(0)\n    return None\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/index.html#client.ayon_deadline.DeadlineAddon.get_plugin_paths","title":"<code>get_plugin_paths()</code>","text":"<p>Deadline plugin paths.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def get_plugin_paths(self):\n    \"\"\"Deadline plugin paths.\"\"\"\n    # Note: We are not returning `publish` key because we have overridden\n    # `get_publish_plugin_paths` to return paths host-specific. However,\n    # `get_plugin_paths` still needs to be implemented because it's\n    # abstract on the parent class\n    return {}\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/index.html#client.ayon_deadline.DeadlineAddon.get_server_info_by_name","title":"<code>get_server_info_by_name(server_name, local_settings=None)</code>","text":"<p>Returns Deadline server info by name.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from Project Settings.</p> required <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeadlineServerInfo</code> <code>DeadlineServerInfo</code> <p>Deadline server info.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def get_server_info_by_name(\n    self,\n    server_name: str,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; DeadlineServerInfo:\n    \"\"\"Returns Deadline server info by name.\n\n    Args:\n        server_name (str): Deadline Server name from Project Settings.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        DeadlineServerInfo: Deadline server info.\n\n    \"\"\"\n    server_info = self._server_info_by_name.get(server_name)\n    if server_info is None:\n        con_info = self.get_deadline_server_connection_info(\n            server_name, local_settings\n        )\n        args = con_info.url, con_info.auth, con_info.verify\n        pools = get_deadline_pools(*args)\n        groups = get_deadline_groups(*args)\n        limit_groups = get_deadline_limit_groups(*args)\n        machines = get_deadline_workers(*args)\n        server_info = DeadlineServerInfo(\n            pools=pools,\n            limit_groups=limit_groups,\n            groups=groups,\n            machines=machines\n        )\n        self._server_info_by_name[server_name] = server_info\n\n    return server_info\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/index.html#client.ayon_deadline.DeadlineAddon.submit_ayon_plugin_job","title":"<code>submit_ayon_plugin_job(server_name, args, job_info, aux_files=None, single_frame_only=True, local_settings=None)</code>","text":"<p>Submit job to Deadline using Ayon plugin.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from settings.</p> required <code>args</code> <code>Union[List[str], str]</code> <p>Command line arguments.</p> required <code>job_info</code> <code>Union[DeadlineJobInfo, Dict[str, Any]]</code> <p>Job info data.</p> required <code>aux_files</code> <code>Optional[List[str]]</code> <p>List of auxiliary files.</p> <code>None</code> <code>single_frame_only</code> <code>bool</code> <p>Submit job for single frame only.</p> <code>True</code> <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Job payload, with 'job_id' key.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def submit_ayon_plugin_job(\n    self,\n    server_name: str,\n    args: \"Union[List[str], str]\",\n    job_info: \"Union[DeadlineJobInfo, Dict[str, Any]]\",\n    aux_files: Optional[List[str]] = None,\n    single_frame_only: bool = True,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"Submit job to Deadline using Ayon plugin.\n\n    Args:\n        server_name (str): Deadline Server name from settings.\n        args (Union[List[str], str]): Command line arguments.\n        job_info (Union[DeadlineJobInfo, Dict[str, Any]]): Job info data.\n        aux_files (Optional[List[str]]): List of auxiliary files.\n        single_frame_only (bool): Submit job for single frame only.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        Dict[str, Any]: Job payload, with 'job_id' key.\n\n    \"\"\"\n    if not isinstance(args, str):\n        args = subprocess.list2cmdline(args)\n\n    if isinstance(job_info, DeadlineJobInfo):\n        job_info = job_info.serialize()\n    job_info[\"Plugin\"] = \"Ayon\"\n\n    plugin_info = {\n        \"Version\": AYON_PLUGIN_VERSION,\n        \"Arguments\": args,\n        \"SingleFrameOnly\": \"True\" if single_frame_only else \"False\",\n    }\n    return self.submit_job(\n        server_name,\n        plugin_info,\n        job_info,\n        aux_files,\n        local_settings=local_settings\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/index.html#client.ayon_deadline.DeadlineAddon.submit_job","title":"<code>submit_job(server_name, plugin_info, job_info, aux_files=None, local_settings=None)</code>","text":"<p>Submit job to Deadline.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from project Settings.</p> required <code>plugin_info</code> <code>dict</code> <p>Plugin info data.</p> required <code>job_info</code> <code>Union[DeadlineJobInfo, Dict[str, Any]]</code> <p>Job info data.</p> required <code>aux_files</code> <code>Optional[List[str]]</code> <p>List of auxiliary files.</p> <code>None</code> <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Job payload, with 'response' key containing response data.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def submit_job(\n    self,\n    server_name: str,\n    plugin_info: Dict[str, Any],\n    job_info: \"Union[DeadlineJobInfo, Dict[str, Any]]\",\n    aux_files: Optional[List[str]] = None,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"Submit job to Deadline.\n\n    Args:\n        server_name (str): Deadline Server name from project Settings.\n        plugin_info (dict): Plugin info data.\n        job_info (Union[DeadlineJobInfo, Dict[str, Any]]): Job info data.\n        aux_files (Optional[List[str]]): List of auxiliary files.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        Dict[str, Any]: Job payload, with 'response' key containing\n            response data.\n\n    \"\"\"\n    if isinstance(job_info, DeadlineJobInfo):\n        job_info = job_info.serialize()\n\n    payload = {\n        \"JobInfo\": job_info,\n        \"PluginInfo\": plugin_info,\n        \"AuxFiles\": aux_files or [],\n    }\n    con_info = self.get_deadline_server_connection_info(\n        server_name, local_settings\n    )\n    response = requests.post(\n        f\"{con_info.url}/api/jobs\",\n        json=payload,\n        timeout=10,\n        auth=con_info.auth,\n        verify=con_info.verify\n    )\n    response.raise_for_status()\n    payload[\"response\"] = response.json()\n    return payload\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html","title":"abstract_submit_deadline","text":"<p>Abstract package for submitting jobs to Deadline.</p> <p>It provides Deadline JobInfo data class.</p>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline","title":"<code>AbstractSubmitDeadline</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>AYONPyblishPluginMixin</code></p> <p>Class abstracting access to Deadline.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>class AbstractSubmitDeadline(\n    pyblish.api.InstancePlugin,\n    AYONPyblishPluginMixin,\n    metaclass=AbstractMetaInstancePlugin\n):\n    \"\"\"Class abstracting access to Deadline.\"\"\"\n\n    label = \"Submit to Deadline\"\n    order = pyblish.api.IntegratorOrder + 0.1\n\n    import_reference = False\n\n    def __init__(self, *args, **kwargs):\n        super(AbstractSubmitDeadline, self).__init__(*args, **kwargs)\n        self._instance: Optional[pyblish.api.Instance] = None\n        self._deadline_url = None\n        self.scene_path: Optional[str] = None\n        self.job_info: Optional[PublishDeadlineJobInfo] = None\n        self.plugin_info: Optional[dict[str, Any]] = None\n        self.aux_files: Optional[list[str]] = None\n\n    def process(self, instance):\n        \"\"\"Plugin entry point.\"\"\"\n        self._instance = instance\n        context = instance.context\n        self._deadline_url = instance.data[\"deadline\"][\"url\"]\n\n        assert self._deadline_url, \"Requires Deadline Webservice URL\"\n\n        job_info = self.get_generic_job_info(instance)\n        self.job_info = self.get_job_info(job_info=deepcopy(job_info))\n\n        self._set_scene_path(\n            context.data[\"currentFile\"],\n            job_info.use_published,\n            instance.data.get(\"stagingDir_is_custom\", False)\n        )\n        if instance.data.get(\"expectedFiles\"):\n            self._append_job_output_paths(\n                instance,\n                self.job_info\n            )\n        self.plugin_info = self.get_plugin_info()\n\n        self.aux_files = self.get_aux_files()\n\n        plugin_info_data = instance.data[\"deadline\"][\"plugin_info_data\"]\n        if plugin_info_data:\n            self.apply_additional_plugin_info(plugin_info_data)\n\n        job_id = self.process_submission()\n        self.log.info(f\"Submitted job to Deadline: {job_id}.\")\n\n        instance.data[\"deadline\"][\"job_info\"] = deepcopy(self.job_info)\n\n        # TODO: Find a way that's more generic and not render type specific\n        if instance.data.get(\"splitRender\"):\n            self.log.info(\"Splitting export and render in two jobs\")\n            self.log.info(\"Export job id: %s\", job_id)\n            render_job_info = self.get_job_info(\n                job_info=job_info, dependency_job_ids=[job_id])\n            render_plugin_info = self.get_plugin_info(job_type=\"render\")\n            payload = self.assemble_payload(\n                job_info=render_job_info,\n                plugin_info=render_plugin_info\n            )\n            auth = instance.data[\"deadline\"][\"auth\"]\n            verify = instance.data[\"deadline\"][\"verify\"]\n            render_job_id = self.submit(payload, auth, verify)\n\n            instance.data[\"deadline\"][\"job_info\"] = deepcopy(render_job_info)\n            self.log.info(\"Render job id: %s\", render_job_id)\n\n    def _set_scene_path(\n        self,\n        current_file,\n        use_published,\n        has_custom_staging_dir\n    ):\n        \"\"\"Points which workfile should be rendered\"\"\"\n        file_path = None\n        if use_published:\n            if not self.import_reference:  # TODO remove or implement\n                file_path = self.from_published_scene(\n                    replace_in_path=not has_custom_staging_dir)\n            else:\n                self.log.info(\n                    \"use the scene with imported reference for rendering\")\n                file_path = current_file\n\n        # fallback if nothing was set\n        if not file_path:\n            self.log.warning(\"Falling back to workfile\")\n            file_path = current_file\n        self.scene_path = file_path\n        self.log.info(\"Using {} for render/export.\".format(file_path))\n\n    def _append_job_output_paths(self, instance, job_info):\n        \"\"\"Set output part to Job info\n\n        Note: 'expectedFiles' might be remapped after `_set_scene_path`\n            due to remapping workfile to published workfile.\n        Used in JobOutput &gt; Explore output\n        \"\"\"\n        collections, remainder = clique.assemble(\n            iter_expected_files(instance.data[\"expectedFiles\"]),\n            assume_padded_when_ambiguous=True,\n            patterns=[clique.PATTERNS[\"frames\"]])\n        paths = []\n        for collection in collections:\n            padding = \"#\" * collection.padding\n            path = collection.format(f\"{{head}}{padding}{{tail}}\")\n            paths.append(path)\n        paths.extend(remainder)\n\n        for path in paths:\n            job_info.OutputDirectory += os.path.dirname(path)\n            job_info.OutputFilename += os.path.basename(path)\n\n    def process_submission(self):\n        \"\"\"Process data for submission.\n\n        This takes Deadline JobInfo, PluginInfo, AuxFile, creates payload\n        from them and submit it do Deadline.\n\n        Returns:\n            str: Deadline job ID\n\n        \"\"\"\n        payload = self.assemble_payload()\n        auth = self._instance.data[\"deadline\"][\"auth\"]\n        verify = self._instance.data[\"deadline\"][\"verify\"]\n        return self.submit(payload, auth, verify)\n\n    def get_generic_job_info(self, instance: pyblish.api.Instance):\n        context: pyblish.api.Context = instance.context\n        job_info: PublishDeadlineJobInfo = (\n            instance.data[\"deadline\"][\"job_info\"]\n        )\n\n        # Always use the original work file name for the Job name even when\n        # rendering is done from the published Work File. The original work\n        # file name is clearer because it can also have subversion strings,\n        # etc. which are stripped for the published file.\n        batch_name = os.path.basename(context.data[\"currentFile\"])\n\n        if is_in_tests():\n            batch_name += datetime.now().strftime(\"%d%m%Y%H%M%S\")\n\n        job_info.Name = \"%s - %s\" % (batch_name, instance.name)\n        job_info.BatchName = batch_name\n        # TODO clean deadlineUser\n        job_info.UserName = context.data.get(\"deadlineUser\", getpass.getuser())\n        job_info.Comment = context.data.get(\"comment\")\n\n        if job_info.Pool != \"none\":\n            job_info.Pool = job_info.Pool\n        if job_info.SecondaryPool != \"none\":\n            job_info.SecondaryPool = job_info.SecondaryPool\n\n        if job_info.Frames:\n            instance.data[\"hasExplicitFrames\"] = True\n\n        if job_info.reuse_last_version:\n            instance.data[\"reuseLastVersion\"] = True\n\n        # Adding file dependencies.\n        if not is_in_tests() and job_info.use_asset_dependencies:\n            dependencies = instance.context.data.get(\"fileDependencies\", [])\n            for dependency in dependencies:\n                job_info.AssetDependency += dependency\n\n        # Set job environment variables\n        job_info.add_instance_job_env_vars(instance)\n        job_info.add_render_job_env_var()\n\n        return job_info\n\n    def apply_additional_plugin_info(self, plugin_info_data):\n        \"\"\"Adds additional fields and values which aren't explicitly impl.\"\"\"\n        for key, value in plugin_info_data.items():\n            # self.plugin_info is dict, should it be?\n            self.plugin_info[key] = value\n\n    @abstractmethod\n    def get_job_info(\n        self, job_info: Optional[PublishDeadlineJobInfo] = None, **kwargs\n    ):\n        \"\"\"Return filled Deadline JobInfo.\n\n        This is host/plugin specific implementation of how to fill data in.\n\n        Args:\n            job_info (PublishDeadlineJobInfo): dataclass object with collected\n                values from Settings and Publisher UI\n\n        See:\n            :class:`PublishDeadlineJobInfo`\n\n        Returns:\n            :class:`PublishDeadlineJobInfo`: Filled Deadline JobInfo.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_plugin_info(self, **kwargs):\n        \"\"\"Return filled Deadline PluginInfo.\n\n        This is host/plugin specific implementation of how to fill data in.\n\n        See:\n            :class:`PublishDeadlineJobInfo`\n\n        Returns:\n            dict: Filled Deadline JobInfo.\n\n        \"\"\"\n        pass\n\n    def get_aux_files(self):\n        \"\"\"Return list of auxiliary files for Deadline job.\n\n        If needed this should be overridden, otherwise return empty list as\n        that field even empty must be present on Deadline submission.\n\n        Returns:\n            list[str]: List of files.\n\n        \"\"\"\n        return []\n\n    def from_published_scene(self, replace_in_path=True):\n        \"\"\"Switch work scene for published scene.\n\n        If rendering/exporting from published scenes is enabled, this will\n        replace paths from working scene to published scene.\n\n        Args:\n            replace_in_path (bool): if True, it will try to find\n                old scene name in path of expected files and replace it\n                with name of published scene.\n\n        Returns:\n            str: Published scene path.\n            None: if no published scene is found.\n\n        Note:\n            Published scene path is actually determined from project Anatomy\n            as at the time this plugin is running scene can still no be\n            published.\n\n        \"\"\"\n        return replace_with_published_scene_path(\n            self._instance, replace_in_path=replace_in_path)\n\n    def assemble_payload(\n            self, job_info=None, plugin_info=None, aux_files=None):\n        \"\"\"Assemble payload data from its various parts.\n\n        Args:\n            job_info (PublishDeadlineJobInfo): Deadline JobInfo. You can use\n                :class:`PublishDeadlineJobInfo` for it.\n            plugin_info (dict): Deadline PluginInfo. Plugin specific options.\n            aux_files (list, optional): List of auxiliary file to submit with\n                the job.\n\n        Returns:\n            dict: Deadline Payload.\n\n        \"\"\"\n        job = job_info or self.job_info\n        return {\n            \"JobInfo\": job.serialize(),\n            \"PluginInfo\": plugin_info or self.plugin_info,\n            \"AuxFiles\": aux_files or self.aux_files\n        }\n\n    def submit(self, payload, auth, verify):\n        \"\"\"Submit payload to Deadline API end-point.\n\n        This takes payload in the form of JSON file and POST it to\n        Deadline jobs end-point.\n\n        Args:\n            payload (dict): dict to become json in deadline submission.\n            auth (tuple): (username, password)\n            verify (bool): verify SSL certificate if present\n\n        Returns:\n            str: resulting Deadline job id.\n\n        Throws:\n            KnownPublishError: if submission fails.\n\n        \"\"\"\n        url = \"{}/api/jobs\".format(self._deadline_url)\n        response = requests_post(\n            url, json=payload, auth=auth, verify=verify)\n        if not response.ok:\n            self.log.error(\"Submission failed!\")\n            self.log.error(response.status_code)\n            self.log.error(response.content)\n            self.log.debug(payload)\n            raise KnownPublishError(response.text)\n\n        try:\n            result = response.json()\n        except JSONDecodeError:\n            msg = f\"Broken response {response.text}. \"\n            msg += \"Try restarting the Deadline Webservice.\"\n            self.log.warning(msg, exc_info=True)\n            raise KnownPublishError(\"Broken response from DL\")\n\n        # for submit publish job\n        self._instance.data[\"deadlineSubmissionJob\"] = result\n\n        return result[\"_id\"]\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.apply_additional_plugin_info","title":"<code>apply_additional_plugin_info(plugin_info_data)</code>","text":"<p>Adds additional fields and values which aren't explicitly impl.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def apply_additional_plugin_info(self, plugin_info_data):\n    \"\"\"Adds additional fields and values which aren't explicitly impl.\"\"\"\n    for key, value in plugin_info_data.items():\n        # self.plugin_info is dict, should it be?\n        self.plugin_info[key] = value\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.assemble_payload","title":"<code>assemble_payload(job_info=None, plugin_info=None, aux_files=None)</code>","text":"<p>Assemble payload data from its various parts.</p> <p>Parameters:</p> Name Type Description Default <code>job_info</code> <code>PublishDeadlineJobInfo</code> <p>Deadline JobInfo. You can use :class:<code>PublishDeadlineJobInfo</code> for it.</p> <code>None</code> <code>plugin_info</code> <code>dict</code> <p>Deadline PluginInfo. Plugin specific options.</p> <code>None</code> <code>aux_files</code> <code>list</code> <p>List of auxiliary file to submit with the job.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Deadline Payload.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def assemble_payload(\n        self, job_info=None, plugin_info=None, aux_files=None):\n    \"\"\"Assemble payload data from its various parts.\n\n    Args:\n        job_info (PublishDeadlineJobInfo): Deadline JobInfo. You can use\n            :class:`PublishDeadlineJobInfo` for it.\n        plugin_info (dict): Deadline PluginInfo. Plugin specific options.\n        aux_files (list, optional): List of auxiliary file to submit with\n            the job.\n\n    Returns:\n        dict: Deadline Payload.\n\n    \"\"\"\n    job = job_info or self.job_info\n    return {\n        \"JobInfo\": job.serialize(),\n        \"PluginInfo\": plugin_info or self.plugin_info,\n        \"AuxFiles\": aux_files or self.aux_files\n    }\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.from_published_scene","title":"<code>from_published_scene(replace_in_path=True)</code>","text":"<p>Switch work scene for published scene.</p> <p>If rendering/exporting from published scenes is enabled, this will replace paths from working scene to published scene.</p> <p>Parameters:</p> Name Type Description Default <code>replace_in_path</code> <code>bool</code> <p>if True, it will try to find old scene name in path of expected files and replace it with name of published scene.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <p>Published scene path.</p> <code>None</code> <p>if no published scene is found.</p> Note <p>Published scene path is actually determined from project Anatomy as at the time this plugin is running scene can still no be published.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def from_published_scene(self, replace_in_path=True):\n    \"\"\"Switch work scene for published scene.\n\n    If rendering/exporting from published scenes is enabled, this will\n    replace paths from working scene to published scene.\n\n    Args:\n        replace_in_path (bool): if True, it will try to find\n            old scene name in path of expected files and replace it\n            with name of published scene.\n\n    Returns:\n        str: Published scene path.\n        None: if no published scene is found.\n\n    Note:\n        Published scene path is actually determined from project Anatomy\n        as at the time this plugin is running scene can still no be\n        published.\n\n    \"\"\"\n    return replace_with_published_scene_path(\n        self._instance, replace_in_path=replace_in_path)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.get_aux_files","title":"<code>get_aux_files()</code>","text":"<p>Return list of auxiliary files for Deadline job.</p> <p>If needed this should be overridden, otherwise return empty list as that field even empty must be present on Deadline submission.</p> <p>Returns:</p> Type Description <p>list[str]: List of files.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def get_aux_files(self):\n    \"\"\"Return list of auxiliary files for Deadline job.\n\n    If needed this should be overridden, otherwise return empty list as\n    that field even empty must be present on Deadline submission.\n\n    Returns:\n        list[str]: List of files.\n\n    \"\"\"\n    return []\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.get_job_info","title":"<code>get_job_info(job_info=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return filled Deadline JobInfo.</p> <p>This is host/plugin specific implementation of how to fill data in.</p> <p>Parameters:</p> Name Type Description Default <code>job_info</code> <code>PublishDeadlineJobInfo</code> <p>dataclass object with collected values from Settings and Publisher UI</p> <code>None</code> See <p>:class:<code>PublishDeadlineJobInfo</code></p> <p>Returns:</p> Type Description <p>class:<code>PublishDeadlineJobInfo</code>: Filled Deadline JobInfo.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>@abstractmethod\ndef get_job_info(\n    self, job_info: Optional[PublishDeadlineJobInfo] = None, **kwargs\n):\n    \"\"\"Return filled Deadline JobInfo.\n\n    This is host/plugin specific implementation of how to fill data in.\n\n    Args:\n        job_info (PublishDeadlineJobInfo): dataclass object with collected\n            values from Settings and Publisher UI\n\n    See:\n        :class:`PublishDeadlineJobInfo`\n\n    Returns:\n        :class:`PublishDeadlineJobInfo`: Filled Deadline JobInfo.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.get_plugin_info","title":"<code>get_plugin_info(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return filled Deadline PluginInfo.</p> <p>This is host/plugin specific implementation of how to fill data in.</p> See <p>:class:<code>PublishDeadlineJobInfo</code></p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Filled Deadline JobInfo.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>@abstractmethod\ndef get_plugin_info(self, **kwargs):\n    \"\"\"Return filled Deadline PluginInfo.\n\n    This is host/plugin specific implementation of how to fill data in.\n\n    See:\n        :class:`PublishDeadlineJobInfo`\n\n    Returns:\n        dict: Filled Deadline JobInfo.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.process","title":"<code>process(instance)</code>","text":"<p>Plugin entry point.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def process(self, instance):\n    \"\"\"Plugin entry point.\"\"\"\n    self._instance = instance\n    context = instance.context\n    self._deadline_url = instance.data[\"deadline\"][\"url\"]\n\n    assert self._deadline_url, \"Requires Deadline Webservice URL\"\n\n    job_info = self.get_generic_job_info(instance)\n    self.job_info = self.get_job_info(job_info=deepcopy(job_info))\n\n    self._set_scene_path(\n        context.data[\"currentFile\"],\n        job_info.use_published,\n        instance.data.get(\"stagingDir_is_custom\", False)\n    )\n    if instance.data.get(\"expectedFiles\"):\n        self._append_job_output_paths(\n            instance,\n            self.job_info\n        )\n    self.plugin_info = self.get_plugin_info()\n\n    self.aux_files = self.get_aux_files()\n\n    plugin_info_data = instance.data[\"deadline\"][\"plugin_info_data\"]\n    if plugin_info_data:\n        self.apply_additional_plugin_info(plugin_info_data)\n\n    job_id = self.process_submission()\n    self.log.info(f\"Submitted job to Deadline: {job_id}.\")\n\n    instance.data[\"deadline\"][\"job_info\"] = deepcopy(self.job_info)\n\n    # TODO: Find a way that's more generic and not render type specific\n    if instance.data.get(\"splitRender\"):\n        self.log.info(\"Splitting export and render in two jobs\")\n        self.log.info(\"Export job id: %s\", job_id)\n        render_job_info = self.get_job_info(\n            job_info=job_info, dependency_job_ids=[job_id])\n        render_plugin_info = self.get_plugin_info(job_type=\"render\")\n        payload = self.assemble_payload(\n            job_info=render_job_info,\n            plugin_info=render_plugin_info\n        )\n        auth = instance.data[\"deadline\"][\"auth\"]\n        verify = instance.data[\"deadline\"][\"verify\"]\n        render_job_id = self.submit(payload, auth, verify)\n\n        instance.data[\"deadline\"][\"job_info\"] = deepcopy(render_job_info)\n        self.log.info(\"Render job id: %s\", render_job_id)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.process_submission","title":"<code>process_submission()</code>","text":"<p>Process data for submission.</p> <p>This takes Deadline JobInfo, PluginInfo, AuxFile, creates payload from them and submit it do Deadline.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>Deadline job ID</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def process_submission(self):\n    \"\"\"Process data for submission.\n\n    This takes Deadline JobInfo, PluginInfo, AuxFile, creates payload\n    from them and submit it do Deadline.\n\n    Returns:\n        str: Deadline job ID\n\n    \"\"\"\n    payload = self.assemble_payload()\n    auth = self._instance.data[\"deadline\"][\"auth\"]\n    verify = self._instance.data[\"deadline\"][\"verify\"]\n    return self.submit(payload, auth, verify)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.AbstractSubmitDeadline.submit","title":"<code>submit(payload, auth, verify)</code>","text":"<p>Submit payload to Deadline API end-point.</p> <p>This takes payload in the form of JSON file and POST it to Deadline jobs end-point.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>dict</code> <p>dict to become json in deadline submission.</p> required <code>auth</code> <code>tuple</code> <p>(username, password)</p> required <code>verify</code> <code>bool</code> <p>verify SSL certificate if present</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>resulting Deadline job id.</p> Throws <p>KnownPublishError: if submission fails.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def submit(self, payload, auth, verify):\n    \"\"\"Submit payload to Deadline API end-point.\n\n    This takes payload in the form of JSON file and POST it to\n    Deadline jobs end-point.\n\n    Args:\n        payload (dict): dict to become json in deadline submission.\n        auth (tuple): (username, password)\n        verify (bool): verify SSL certificate if present\n\n    Returns:\n        str: resulting Deadline job id.\n\n    Throws:\n        KnownPublishError: if submission fails.\n\n    \"\"\"\n    url = \"{}/api/jobs\".format(self._deadline_url)\n    response = requests_post(\n        url, json=payload, auth=auth, verify=verify)\n    if not response.ok:\n        self.log.error(\"Submission failed!\")\n        self.log.error(response.status_code)\n        self.log.error(response.content)\n        self.log.debug(payload)\n        raise KnownPublishError(response.text)\n\n    try:\n        result = response.json()\n    except JSONDecodeError:\n        msg = f\"Broken response {response.text}. \"\n        msg += \"Try restarting the Deadline Webservice.\"\n        self.log.warning(msg, exc_info=True)\n        raise KnownPublishError(\"Broken response from DL\")\n\n    # for submit publish job\n    self._instance.data[\"deadlineSubmissionJob\"] = result\n\n    return result[\"_id\"]\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.requests_get","title":"<code>requests_get(*args, **kwargs)</code>","text":"<p>Wrap request get method.</p> <p>Disabling SSL certificate validation if <code>verify</code> kwarg is set to False. This is useful when Deadline server is running with self-signed certificates and its certificate is not added to trusted certificates on client machines.</p> Warning <p>Disabling SSL certificate validation is defeating one line of defense SSL is providing, and it is not recommended.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def requests_get(*args, **kwargs):\n    \"\"\"Wrap request get method.\n\n    Disabling SSL certificate validation if ``verify`` kwarg is set to False.\n    This is useful when Deadline server is\n    running with self-signed certificates and its certificate is not\n    added to trusted certificates on client machines.\n\n    Warning:\n        Disabling SSL certificate validation is defeating one line\n        of defense SSL is providing, and it is not recommended.\n\n    \"\"\"\n    auth = kwargs.get(\"auth\")\n    if auth:\n        kwargs[\"auth\"] = tuple(auth)\n    # add 10sec timeout before bailing out\n    kwargs['timeout'] = 10\n    return requests.get(*args, **kwargs)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/abstract_submit_deadline.html#client.ayon_deadline.abstract_submit_deadline.requests_post","title":"<code>requests_post(*args, **kwargs)</code>","text":"<p>Wrap request post method.</p> <p>Disabling SSL certificate validation if <code>verify</code> kwarg is set to False. This is useful when Deadline server is running with self-signed certificates and its certificate is not added to trusted certificates on client machines.</p> Warning <p>Disabling SSL certificate validation is defeating one line of defense SSL is providing, and it is not recommended.</p> Source code in <code>client/ayon_deadline/abstract_submit_deadline.py</code> <pre><code>def requests_post(*args, **kwargs):\n    \"\"\"Wrap request post method.\n\n    Disabling SSL certificate validation if ``verify`` kwarg is set to False.\n    This is useful when Deadline server is\n    running with self-signed certificates and its certificate is not\n    added to trusted certificates on client machines.\n\n    Warning:\n        Disabling SSL certificate validation is defeating one line\n        of defense SSL is providing, and it is not recommended.\n\n    \"\"\"\n    auth = kwargs.get(\"auth\")\n    if auth:\n        kwargs[\"auth\"] = tuple(auth)  # explicit cast to tuple\n    # add 10sec timeout before bailing out\n    kwargs['timeout'] = 10\n    return requests.post(*args, **kwargs)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/addon.html","title":"addon","text":""},{"location":"autoapi/client/ayon_deadline/addon.html#client.ayon_deadline.addon.DeadlineAddon","title":"<code>DeadlineAddon</code>","text":"<p>               Bases: <code>AYONAddon</code>, <code>IPluginPaths</code></p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>class DeadlineAddon(AYONAddon, IPluginPaths):\n    name = \"deadline\"\n    version = __version__\n\n    def initialize(self, studio_settings):\n        deadline_settings = studio_settings[self.name]\n        deadline_servers_info = {\n            url_item[\"name\"]: url_item\n            for url_item in deadline_settings[\"deadline_urls\"]\n        }\n\n        if not deadline_servers_info:\n            self.enabled = False\n            self.log.warning((\n                \"Deadline Webservice URLs are not specified. Disabling addon.\"\n            ))\n\n        self.deadline_servers_info = deadline_servers_info\n\n        self._server_info_by_name: Dict[str, DeadlineServerInfo] = {}\n\n        self._local_settings_cache = CacheItem(lifetime=60)\n\n    def get_plugin_paths(self):\n        \"\"\"Deadline plugin paths.\"\"\"\n        # Note: We are not returning `publish` key because we have overridden\n        # `get_publish_plugin_paths` to return paths host-specific. However,\n        # `get_plugin_paths` still needs to be implemented because it's\n        # abstract on the parent class\n        return {}\n\n    def get_publish_plugin_paths(\n        self,\n        host_name: Optional[str] = None\n    ) -&gt; List[str]:\n        publish_dir = os.path.join(DEADLINE_ADDON_ROOT, \"plugins\", \"publish\")\n        paths = [os.path.join(publish_dir, \"global\")]\n        if host_name:\n            paths.append(os.path.join(publish_dir, host_name))\n        return paths\n\n    def get_server_info_by_name(\n        self,\n        server_name: str,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; DeadlineServerInfo:\n        \"\"\"Returns Deadline server info by name.\n\n        Args:\n            server_name (str): Deadline Server name from Project Settings.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            DeadlineServerInfo: Deadline server info.\n\n        \"\"\"\n        server_info = self._server_info_by_name.get(server_name)\n        if server_info is None:\n            con_info = self.get_deadline_server_connection_info(\n                server_name, local_settings\n            )\n            args = con_info.url, con_info.auth, con_info.verify\n            pools = get_deadline_pools(*args)\n            groups = get_deadline_groups(*args)\n            limit_groups = get_deadline_limit_groups(*args)\n            machines = get_deadline_workers(*args)\n            server_info = DeadlineServerInfo(\n                pools=pools,\n                limit_groups=limit_groups,\n                groups=groups,\n                machines=machines\n            )\n            self._server_info_by_name[server_name] = server_info\n\n        return server_info\n\n    def get_job_info(\n        self,\n        server_name: str,\n        job_id: str,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get job info from Deadline.\n\n        Args:\n            server_name (str): Deadline Server name from project Settings.\n            job_id (str): Deadline job id.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            Optional[Dict[str, Any]]: Job info from Deadline.\n\n        \"\"\"\n        con_info = self.get_deadline_server_connection_info(\n            server_name, local_settings\n        )\n        response = requests.get(\n            f\"{con_info.url}/api/jobs?JobID={job_id}\",\n            auth=con_info.auth,\n            verify=con_info.verify\n        )\n        response.raise_for_status()\n        data = response.json()\n        if data:\n            return data.pop(0)\n        return None\n\n    def submit_job(\n        self,\n        server_name: str,\n        plugin_info: Dict[str, Any],\n        job_info: \"Union[DeadlineJobInfo, Dict[str, Any]]\",\n        aux_files: Optional[List[str]] = None,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Submit job to Deadline.\n\n        Args:\n            server_name (str): Deadline Server name from project Settings.\n            plugin_info (dict): Plugin info data.\n            job_info (Union[DeadlineJobInfo, Dict[str, Any]]): Job info data.\n            aux_files (Optional[List[str]]): List of auxiliary files.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            Dict[str, Any]: Job payload, with 'response' key containing\n                response data.\n\n        \"\"\"\n        if isinstance(job_info, DeadlineJobInfo):\n            job_info = job_info.serialize()\n\n        payload = {\n            \"JobInfo\": job_info,\n            \"PluginInfo\": plugin_info,\n            \"AuxFiles\": aux_files or [],\n        }\n        con_info = self.get_deadline_server_connection_info(\n            server_name, local_settings\n        )\n        response = requests.post(\n            f\"{con_info.url}/api/jobs\",\n            json=payload,\n            timeout=10,\n            auth=con_info.auth,\n            verify=con_info.verify\n        )\n        response.raise_for_status()\n        payload[\"response\"] = response.json()\n        return payload\n\n    def submit_ayon_plugin_job(\n        self,\n        server_name: str,\n        args: \"Union[List[str], str]\",\n        job_info: \"Union[DeadlineJobInfo, Dict[str, Any]]\",\n        aux_files: Optional[List[str]] = None,\n        single_frame_only: bool = True,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Submit job to Deadline using Ayon plugin.\n\n        Args:\n            server_name (str): Deadline Server name from settings.\n            args (Union[List[str], str]): Command line arguments.\n            job_info (Union[DeadlineJobInfo, Dict[str, Any]]): Job info data.\n            aux_files (Optional[List[str]]): List of auxiliary files.\n            single_frame_only (bool): Submit job for single frame only.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            Dict[str, Any]: Job payload, with 'job_id' key.\n\n        \"\"\"\n        if not isinstance(args, str):\n            args = subprocess.list2cmdline(args)\n\n        if isinstance(job_info, DeadlineJobInfo):\n            job_info = job_info.serialize()\n        job_info[\"Plugin\"] = \"Ayon\"\n\n        plugin_info = {\n            \"Version\": AYON_PLUGIN_VERSION,\n            \"Arguments\": args,\n            \"SingleFrameOnly\": \"True\" if single_frame_only else \"False\",\n        }\n        return self.submit_job(\n            server_name,\n            plugin_info,\n            job_info,\n            aux_files,\n            local_settings=local_settings\n        )\n\n    def get_deadline_server_connection_info(\n        self,\n        server_name: str,\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; DeadlineConnectionInfo:\n        \"\"\"Get Deadline server info.\n\n        Args:\n            server_name (str): Deadline Server name from project Settings.\n            local_settings (Optional[Dict[str, Any]]): Deadline local\n                settings.\n\n        Returns:\n            DeadlineConnectionInfo: Server connection information with\n                server url, auth and verify ssl flag.\n\n        \"\"\"\n        dl_server_info = self.deadline_servers_info[server_name]\n        auth = self._get_server_user_auth(dl_server_info, local_settings)\n        return DeadlineConnectionInfo(\n            server_name,\n            dl_server_info[\"value\"].rstrip(\"/\"),\n            auth,\n            not dl_server_info[\"not_verify_ssl\"],\n        )\n\n    def _get_local_settings(self) -&gt; Dict[str, Any]:\n        if not self._local_settings_cache.is_valid:\n            # TODO import 'get_addon_site_settings' when available\n            #   in public 'ayon_api'\n            con = ayon_api.get_server_api_connection()\n            self._local_settings_cache.update_data(\n                con.get_addon_site_settings(\n                    self.name, self.version\n                )\n            )\n        return self._local_settings_cache.get_data()\n\n    def _get_server_user_auth(\n        self,\n        server_info: Dict[str, Any],\n        local_settings: Optional[Dict[str, Any]] = None,\n    ) -&gt; Optional[Tuple[str, str]]:\n        selected_server_name = server_info[\"name\"]\n\n        require_authentication = server_info[\"require_authentication\"]\n        if require_authentication:\n            if local_settings is None:\n                local_settings = self._get_local_settings()\n\n            for local_info in local_settings[\"local_settings\"]:\n                if selected_server_name != local_info[\"server_name\"]:\n                    continue\n\n                if local_info[\"username\"] and local_info[\"password\"]:\n                    return local_info[\"username\"], local_info[\"password\"]\n\n        default_username = server_info[\"default_username\"]\n        default_password = server_info[\"default_password\"]\n        if default_username and default_password:\n            return default_username, default_password\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/addon.html#client.ayon_deadline.addon.DeadlineAddon.get_deadline_server_connection_info","title":"<code>get_deadline_server_connection_info(server_name, local_settings=None)</code>","text":"<p>Get Deadline server info.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from project Settings.</p> required <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeadlineConnectionInfo</code> <code>DeadlineConnectionInfo</code> <p>Server connection information with server url, auth and verify ssl flag.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def get_deadline_server_connection_info(\n    self,\n    server_name: str,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; DeadlineConnectionInfo:\n    \"\"\"Get Deadline server info.\n\n    Args:\n        server_name (str): Deadline Server name from project Settings.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        DeadlineConnectionInfo: Server connection information with\n            server url, auth and verify ssl flag.\n\n    \"\"\"\n    dl_server_info = self.deadline_servers_info[server_name]\n    auth = self._get_server_user_auth(dl_server_info, local_settings)\n    return DeadlineConnectionInfo(\n        server_name,\n        dl_server_info[\"value\"].rstrip(\"/\"),\n        auth,\n        not dl_server_info[\"not_verify_ssl\"],\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/addon.html#client.ayon_deadline.addon.DeadlineAddon.get_job_info","title":"<code>get_job_info(server_name, job_id, local_settings=None)</code>","text":"<p>Get job info from Deadline.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from project Settings.</p> required <code>job_id</code> <code>str</code> <p>Deadline job id.</p> required <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Optional[Dict[str, Any]]: Job info from Deadline.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def get_job_info(\n    self,\n    server_name: str,\n    job_id: str,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Get job info from Deadline.\n\n    Args:\n        server_name (str): Deadline Server name from project Settings.\n        job_id (str): Deadline job id.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        Optional[Dict[str, Any]]: Job info from Deadline.\n\n    \"\"\"\n    con_info = self.get_deadline_server_connection_info(\n        server_name, local_settings\n    )\n    response = requests.get(\n        f\"{con_info.url}/api/jobs?JobID={job_id}\",\n        auth=con_info.auth,\n        verify=con_info.verify\n    )\n    response.raise_for_status()\n    data = response.json()\n    if data:\n        return data.pop(0)\n    return None\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/addon.html#client.ayon_deadline.addon.DeadlineAddon.get_plugin_paths","title":"<code>get_plugin_paths()</code>","text":"<p>Deadline plugin paths.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def get_plugin_paths(self):\n    \"\"\"Deadline plugin paths.\"\"\"\n    # Note: We are not returning `publish` key because we have overridden\n    # `get_publish_plugin_paths` to return paths host-specific. However,\n    # `get_plugin_paths` still needs to be implemented because it's\n    # abstract on the parent class\n    return {}\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/addon.html#client.ayon_deadline.addon.DeadlineAddon.get_server_info_by_name","title":"<code>get_server_info_by_name(server_name, local_settings=None)</code>","text":"<p>Returns Deadline server info by name.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from Project Settings.</p> required <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeadlineServerInfo</code> <code>DeadlineServerInfo</code> <p>Deadline server info.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def get_server_info_by_name(\n    self,\n    server_name: str,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; DeadlineServerInfo:\n    \"\"\"Returns Deadline server info by name.\n\n    Args:\n        server_name (str): Deadline Server name from Project Settings.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        DeadlineServerInfo: Deadline server info.\n\n    \"\"\"\n    server_info = self._server_info_by_name.get(server_name)\n    if server_info is None:\n        con_info = self.get_deadline_server_connection_info(\n            server_name, local_settings\n        )\n        args = con_info.url, con_info.auth, con_info.verify\n        pools = get_deadline_pools(*args)\n        groups = get_deadline_groups(*args)\n        limit_groups = get_deadline_limit_groups(*args)\n        machines = get_deadline_workers(*args)\n        server_info = DeadlineServerInfo(\n            pools=pools,\n            limit_groups=limit_groups,\n            groups=groups,\n            machines=machines\n        )\n        self._server_info_by_name[server_name] = server_info\n\n    return server_info\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/addon.html#client.ayon_deadline.addon.DeadlineAddon.submit_ayon_plugin_job","title":"<code>submit_ayon_plugin_job(server_name, args, job_info, aux_files=None, single_frame_only=True, local_settings=None)</code>","text":"<p>Submit job to Deadline using Ayon plugin.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from settings.</p> required <code>args</code> <code>Union[List[str], str]</code> <p>Command line arguments.</p> required <code>job_info</code> <code>Union[DeadlineJobInfo, Dict[str, Any]]</code> <p>Job info data.</p> required <code>aux_files</code> <code>Optional[List[str]]</code> <p>List of auxiliary files.</p> <code>None</code> <code>single_frame_only</code> <code>bool</code> <p>Submit job for single frame only.</p> <code>True</code> <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Job payload, with 'job_id' key.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def submit_ayon_plugin_job(\n    self,\n    server_name: str,\n    args: \"Union[List[str], str]\",\n    job_info: \"Union[DeadlineJobInfo, Dict[str, Any]]\",\n    aux_files: Optional[List[str]] = None,\n    single_frame_only: bool = True,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"Submit job to Deadline using Ayon plugin.\n\n    Args:\n        server_name (str): Deadline Server name from settings.\n        args (Union[List[str], str]): Command line arguments.\n        job_info (Union[DeadlineJobInfo, Dict[str, Any]]): Job info data.\n        aux_files (Optional[List[str]]): List of auxiliary files.\n        single_frame_only (bool): Submit job for single frame only.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        Dict[str, Any]: Job payload, with 'job_id' key.\n\n    \"\"\"\n    if not isinstance(args, str):\n        args = subprocess.list2cmdline(args)\n\n    if isinstance(job_info, DeadlineJobInfo):\n        job_info = job_info.serialize()\n    job_info[\"Plugin\"] = \"Ayon\"\n\n    plugin_info = {\n        \"Version\": AYON_PLUGIN_VERSION,\n        \"Arguments\": args,\n        \"SingleFrameOnly\": \"True\" if single_frame_only else \"False\",\n    }\n    return self.submit_job(\n        server_name,\n        plugin_info,\n        job_info,\n        aux_files,\n        local_settings=local_settings\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/addon.html#client.ayon_deadline.addon.DeadlineAddon.submit_job","title":"<code>submit_job(server_name, plugin_info, job_info, aux_files=None, local_settings=None)</code>","text":"<p>Submit job to Deadline.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Deadline Server name from project Settings.</p> required <code>plugin_info</code> <code>dict</code> <p>Plugin info data.</p> required <code>job_info</code> <code>Union[DeadlineJobInfo, Dict[str, Any]]</code> <p>Job info data.</p> required <code>aux_files</code> <code>Optional[List[str]]</code> <p>List of auxiliary files.</p> <code>None</code> <code>local_settings</code> <code>Optional[Dict[str, Any]]</code> <p>Deadline local settings.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Job payload, with 'response' key containing response data.</p> Source code in <code>client/ayon_deadline/addon.py</code> <pre><code>def submit_job(\n    self,\n    server_name: str,\n    plugin_info: Dict[str, Any],\n    job_info: \"Union[DeadlineJobInfo, Dict[str, Any]]\",\n    aux_files: Optional[List[str]] = None,\n    local_settings: Optional[Dict[str, Any]] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"Submit job to Deadline.\n\n    Args:\n        server_name (str): Deadline Server name from project Settings.\n        plugin_info (dict): Plugin info data.\n        job_info (Union[DeadlineJobInfo, Dict[str, Any]]): Job info data.\n        aux_files (Optional[List[str]]): List of auxiliary files.\n        local_settings (Optional[Dict[str, Any]]): Deadline local\n            settings.\n\n    Returns:\n        Dict[str, Any]: Job payload, with 'response' key containing\n            response data.\n\n    \"\"\"\n    if isinstance(job_info, DeadlineJobInfo):\n        job_info = job_info.serialize()\n\n    payload = {\n        \"JobInfo\": job_info,\n        \"PluginInfo\": plugin_info,\n        \"AuxFiles\": aux_files or [],\n    }\n    con_info = self.get_deadline_server_connection_info(\n        server_name, local_settings\n    )\n    response = requests.post(\n        f\"{con_info.url}/api/jobs\",\n        json=payload,\n        timeout=10,\n        auth=con_info.auth,\n        verify=con_info.verify\n    )\n    response.raise_for_status()\n    payload[\"response\"] = response.json()\n    return payload\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/constants.html","title":"constants","text":""},{"location":"autoapi/client/ayon_deadline/lib.html","title":"lib","text":""},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.DeadlineConnectionInfo","title":"<code>DeadlineConnectionInfo</code>  <code>dataclass</code>","text":"<p>Connection information for Deadline server.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>@dataclass\nclass DeadlineConnectionInfo:\n    \"\"\"Connection information for Deadline server.\"\"\"\n    name: str\n    url: str\n    auth: Tuple[str, str]\n    verify: bool\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.DeadlineIndexedVar","title":"<code>DeadlineIndexedVar</code>","text":"<p>               Bases: <code>dict</code></p> Allows to set and query values by integer indices <p>Query: var[1] or var.get(1) Set: var[1] = \"my_value\" Append: var += \"value\"</p> Iterating the instance is not guaranteed to be the order of the <p>indices. To do so iterate with <code>sorted()</code></p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>class DeadlineIndexedVar(dict):\n    \"\"\"\n\n    Allows to set and query values by integer indices:\n        Query: var[1] or var.get(1)\n        Set: var[1] = \"my_value\"\n        Append: var += \"value\"\n\n    Note: Iterating the instance is not guaranteed to be the order of the\n          indices. To do so iterate with `sorted()`\n\n    \"\"\"\n    def __init__(self, key: str):\n        super().__init__()\n        if \"{}\" not in key:\n            key += \"{}\"\n        self._key = key\n\n    def serialize(self) -&gt; Dict[str, str]:\n        return {\n            self._key.format(index): value\n            for index, value in sorted(self.items())\n        }\n\n    def next_available_index(self):\n        # Add as first unused entry\n        i = 0\n        while i in self.keys():\n            i += 1\n        return i\n\n    def add(self, value: str):\n        if value not in self.values():\n            self.append(value)\n\n    def append(self, value: str):\n        index = self.next_available_index()\n        self[index] = value\n\n    def extend(self, values: Iterable[str]):\n        for value in values:\n            self.append(value)\n\n    def update(self, data: Dict[int, str]):\n        # Force the integer key check\n        for key, value in data.items():\n            self.__setitem__(key, value)\n\n    def __iadd__(self, value: str):\n        self.append(value)\n        return self\n\n    def __setitem__(self, key, value):\n        if not isinstance(key, int):\n            raise TypeError(f\"Key must be an 'int', got {type(key)} ({key}).\")\n\n        if key &lt; 0:\n            raise ValueError(f\"Negative index can't be set: {key}\")\n        dict.__setitem__(self, key, value)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.DeadlineJobInfo","title":"<code>DeadlineJobInfo</code>  <code>dataclass</code>","text":"<p>Mapping of all Deadline JobInfo attributes.</p> <p>This contains all JobInfo attributes plus their default values. Those attributes set to <code>None</code> shouldn't be posted to Deadline as the only required one is <code>Plugin</code>.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>@dataclass\nclass DeadlineJobInfo:\n    \"\"\"Mapping of all Deadline JobInfo attributes.\n\n    This contains all JobInfo attributes plus their default values.\n    Those attributes set to `None` shouldn't be posted to Deadline as\n    the only required one is `Plugin`.\n    \"\"\"\n\n    # Required\n    Plugin: str = field(default=\"Untitled\")\n\n    # General\n    Name: str = field(default=\"Untitled\")\n    # Default: '0'\n    Frames: Optional[str] = field(default=None)\n    # Default: empty\n    Comment: Optional[str] = field(default=None)\n    # Default: empty\n    Department: Optional[str] = field(default=None)\n    # Default: empty\n    BatchName: Optional[str] = field(default=None)\n    UserName: Optional[str] = field(default=None)\n    MachineName: Optional[str] = field(default=None)\n    # Default: \"none\"\n    Pool: Optional[str] = field(default=None)\n    SecondaryPool: Optional[str] = field(default=None)\n    # Default: \"none\"\n    Group: Optional[str] = field(default=None)\n    Priority: int = field(default=None)\n    ChunkSize: int = field(default=None)\n    ConcurrentTasks: int = field(default=None)\n    # Default: \"true\"\n    LimitConcurrentTasksToNumberOfCpus: Optional[bool] = field(default=None)\n    OnJobComplete: str = field(default=None)\n    # Default: false\n    SynchronizeAllAuxiliaryFiles: Optional[bool] = field(default=None)\n    # Default: false\n    ForceReloadPlugin: Optional[bool] = field(default=None)\n    # Default: false\n    Sequential: Optional[bool] = field(default=None)\n    # Default: false\n    SuppressEvents: Optional[bool] = field(default=None)\n    # Default: false\n    Protected: Optional[bool] = field(default=None)\n    InitialStatus: \"InitialStatus\" = field(default=\"Active\")\n    NetworkRoot: Optional[str] = field(default=None)\n\n    # Timeouts\n    # Default: 0\n    MinRenderTimeSeconds: Optional[int] = field(default=None)\n    # Default: 0\n    MinRenderTimeMinutes: Optional[int] = field(default=None)\n    # Default: 0\n    TaskTimeoutSeconds: Optional[int] = field(default=None)\n    # Default: 0\n    TaskTimeoutMinutes: Optional[int] = field(default=None)\n    # Default: 0\n    StartJobTimeoutSeconds: Optional[int] = field(default=None)\n    # Default: 0\n    StartJobTimeoutMinutes: Optional[int] = field(default=None)\n    # Default: 0\n    InitializePluginTimeoutSeconds: Optional[int] = field(default=None)\n    # Default: 'Error'\n    # Options: 'Error', 'Notify', 'ErrorAndNotify', 'Complete'\n    OnTaskTimeout: Optional[str] = field(default=None)\n    # Default: false\n    EnableTimeoutsForScriptTasks: Optional[bool] = field(default=None)\n    # Default: false\n    EnableFrameTimeouts: Optional[bool] = field(default=None)\n    # Default: false\n    EnableAutoTimeout: Optional[bool] = field(default=None)\n\n    # Interruptible\n    Interruptible: Optional[bool] = field(default=None)  # Default: false\n    InterruptiblePercentage: Optional[int] = field(default=None)\n    RemTimeThreshold: Optional[int] = field(default=None)\n\n    # Notifications\n    # Default: blank (comma-separated list of users)\n    NotificationTargets: Optional[str] = field(default=None)\n    # Default: false\n    ClearNotificationTargets: Optional[bool] = field(default=None)\n    # Default: blank (comma-separated list of email addresses)\n    NotificationEmails: Optional[str] = field(default=None)\n    OverrideNotificationMethod: Optional[bool] = field(\n        default=None)  # Default: false\n    # Default: false\n    EmailNotification: Optional[bool] = field(default=None)\n    # Default: false\n    PopupNotification: Optional[bool] = field(default=None)\n    # Default: blank\n    NotificationNote: Optional[str] = field(default=None)\n\n    # Machine Limit\n    # Default: 0\n    MachineLimit: Optional[int] = field(default=None)\n    # Default -1.0\n    MachineLimitProgress: Optional[float] = field(default=None)\n    # Default blank (comma-separated list)\n    Whitelist: Optional[List[str]] = field(default_factory=list)\n    # Default blank (comma-separated list)\n    Blacklist: Optional[List[str]] = field(default_factory=list)\n\n    # Limits\n    # Default: blank\n    LimitGroups: Optional[List[str]] = field(default_factory=list)\n\n    # Dependencies\n    # Default: blank\n    JobDependencies: List[str] = field(default_factory=list)\n    # Default: -1\n    JobDependencyPercentage: Optional[int] = field(default=None)\n    # Default: false\n    IsFrameDependent: Optional[bool] = field(default=None)\n    # Default: 0\n    FrameDependencyOffsetStart: Optional[int] = field(default=None)\n    # Default: 0\n    FrameDependencyOffsetEnd: Optional[int] = field(default=None)\n    # Default: true\n    ResumeOnCompleteDependencies: Optional[bool] = field(default=True)\n    # Default: false\n    ResumeOnDeletedDependencies: Optional[bool] = field(default=False)\n    # Default: false\n    ResumeOnFailedDependencies: Optional[bool] = field(default=False)\n    # Default: blank (comma-separated list)\n    RequiredAssets: Optional[str] = field(default=None)\n    # Default: blank (comma-separated list)\n    ScriptDependencies: Optional[str] = field(default=None)\n\n    # Failure Detection\n    # Default: false\n    OverrideJobFailureDetection: Optional[bool] = field(default=False)\n    # 0..x\n    FailureDetectionJobErrors: Optional[int] = field(default=None)\n    # Default: false\n    OverrideTaskFailureDetection: Optional[bool] = field(default=False)\n    # 0..x\n    FailureDetectionTaskErrors: Optional[int] = field(default=None)\n    # Default: false\n    IgnoreBadJobDetection: Optional[bool] = field(default=False)\n    # Default: false\n    SendJobErrorWarning: Optional[bool] = field(default=False)\n\n    # Cleanup\n    # Default: false\n    DeleteOnComplete: Optional[bool] = field(default=False)\n    # Default: false\n    ArchiveOnComplete: Optional[bool] = field(default=False)\n    # Default: false\n    OverrideAutoJobCleanup: Optional[bool] = field(default=False)\n    OverrideJobCleanup: Optional[bool] = field(default=None)\n    # Default: false (not clear)\n    JobCleanupDays: Optional[int] = field(default=None)\n    OverrideJobCleanupType: Optional[str] = field(default=None)\n\n    # Scheduling\n    # Default: 'None'\n    # Options: 'None', 'Once', 'Daily', 'Custom'\n    ScheduledType: Optional[str] = field(default=None)\n    # &lt;dd/MM/yyyy HH:mm&gt;\n    ScheduledStartDateTime: Optional[str] = field(default=None)\n    # Default: 1\n    ScheduledDays: Optional[int] = field(default=1)\n    # &lt;dd:hh:mm:ss&gt;\n    JobDelay: Optional[str] = field(default=None)\n    # &lt;Day of the Week&gt;&lt;Start/Stop&gt;Time=&lt;HH:mm:ss&gt;\n    Scheduled: Optional[str] = field(default=None)\n\n    # Scripts\n    # Default: blank\n    PreJobScript: Optional[str] = field(default=None)\n    # Default: blank\n    PostJobScript: Optional[str] = field(default=None)\n    # Default: blank\n    PreTaskScript: Optional[str] = field(default=None)\n    # Default: blank\n    PostTaskScript: Optional[str] = field(default=None)\n\n    # Event Opt-Ins\n    # Default blank (comma-separated list)\n    EventOptIns: Optional[str] = field(default=None)\n\n    # Environment\n    EnvironmentKeyValue: DeadlineKeyValueVar = field(\n        default_factory=_partial_key_value(\"EnvironmentKeyValue\"))\n    # Default: false\n    IncludeEnvironment: Optional[bool] = field(default=False)\n    # Default: false\n    UseJobEnvironmentOnly: Optional[bool] = field(default=False)\n    # Default blank\n    CustomPluginDirectory: Optional[str] = field(default=None)\n\n    # Job Extra Info\n    ExtraInfo: DeadlineIndexedVar = field(\n        default_factory=_partial_indexed(\"ExtraInfo\"))\n    ExtraInfoKeyValue: DeadlineKeyValueVar = field(\n        default_factory=_partial_key_value(\"ExtraInfoKeyValue\"))\n\n    # Default false\n    OverrideTaskExtraInfoNames: Optional[bool] = field(default=False)\n\n    TaskExtraInfoName: DeadlineIndexedVar = field(\n        default_factory=_partial_indexed(\"TaskExtraInfoName\"))\n\n    OutputFilename: DeadlineIndexedVar = field(\n        default_factory=_partial_indexed(\"OutputFilename\"))\n    OutputFilenameTile: DeadlineIndexedVar = field(\n        default_factory=_partial_indexed(\"OutputFilename{}Tile\"))\n    OutputDirectory: DeadlineIndexedVar = field(\n        default_factory=_partial_indexed(\"OutputDirectory\"))\n\n    AssetDependency: DeadlineIndexedVar = field(\n        default_factory=_partial_indexed(\"AssetDependency\"))\n\n    TileJob: bool = field(default=False)\n    TileJobFrame: int = field(default=0)\n    TileJobTilesInX: int = field(default=0)\n    TileJobTilesInY: int = field(default=0)\n    TileJobTileCount: int = field(default=0)\n\n    MaintenanceJob: bool = field(default=False)\n    MaintenanceJobStartFrame: int = field(default=0)\n    MaintenanceJobEndFrame: int = field(default=0)\n\n    def __post_init__(self):\n        for attr_name in (\n            \"JobDependencies\",\n            \"Whitelist\",\n            \"Blacklist\",\n            \"LimitGroups\",\n        ):\n            value = getattr(self, attr_name)\n            if value is None:\n                continue\n            if not isinstance(value, list):\n                setattr(self, attr_name, value)\n\n        for attr_name in (\n            \"ExtraInfo\",\n            \"TaskExtraInfoName\",\n            \"OutputFilename\",\n            \"OutputFilenameTile\",\n            \"OutputDirectory\",\n            \"AssetDependency\",\n        ):\n            value = getattr(self, attr_name)\n            if value is None:\n                continue\n            if not isinstance(value, DeadlineIndexedVar):\n                setattr(self, attr_name, value)\n\n        for attr_name in (\n            \"ExtraInfoKeyValue\",\n            \"EnvironmentKeyValue\",\n        ):\n            value = getattr(self, attr_name)\n            if value is None:\n                continue\n            if not isinstance(value, DeadlineKeyValueVar):\n                setattr(self, attr_name, value)\n\n    def __setattr__(self, key, value):\n        if value is None:\n            super().__setattr__(key, value)\n            return\n\n        if key in (\n            \"JobDependencies\",\n            \"Whitelist\",\n            \"Blacklist\",\n            \"LimitGroups\",\n        ):\n            if isinstance(value, str):\n                value = value.split(\",\")\n\n        elif key in (\n            \"ExtraInfo\",\n            \"TaskExtraInfoName\",\n            \"OutputFilename\",\n            \"OutputFilenameTile\",\n            \"OutputDirectory\",\n            \"AssetDependency\",\n        ):\n            if not isinstance(value, DeadlineIndexedVar):\n                new_value = DeadlineIndexedVar(key)\n                new_value.update(value)\n                value = new_value\n\n        elif key in (\n            \"ExtraInfoKeyValue\",\n            \"EnvironmentKeyValue\",\n        ):\n            if not isinstance(value, DeadlineKeyValueVar):\n                new_value = DeadlineKeyValueVar(key)\n                new_value.update(value)\n                value = new_value\n\n        super().__setattr__(key, value)\n\n    def serialize(self):\n        \"\"\"Return all data serialized as dictionary.\n\n        Returns:\n            OrderedDict: all serialized data.\n\n        \"\"\"\n        output = {}\n        for field_item in fields(self):\n            self._fill_serialize_value(\n                field_item.name, getattr(self, field_item.name), output\n            )\n        return output\n\n    def _fill_serialize_value(\n        self, key: str, value: Any, output: Dict[str, Any]\n    ) -&gt; Any:\n        if isinstance(value, (DeadlineIndexedVar, DeadlineKeyValueVar)):\n            output.update(value.serialize())\n        elif isinstance(value, list):\n            output[key] = \",\".join(value)\n        elif value is not None:\n            output[key] = value\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.DeadlineJobInfo.serialize","title":"<code>serialize()</code>","text":"<p>Return all data serialized as dictionary.</p> <p>Returns:</p> Name Type Description <code>OrderedDict</code> <p>all serialized data.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>def serialize(self):\n    \"\"\"Return all data serialized as dictionary.\n\n    Returns:\n        OrderedDict: all serialized data.\n\n    \"\"\"\n    output = {}\n    for field_item in fields(self):\n        self._fill_serialize_value(\n            field_item.name, getattr(self, field_item.name), output\n        )\n    return output\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.DeadlineKeyValueVar","title":"<code>DeadlineKeyValueVar</code>","text":"<p>               Bases: <code>dict</code></p> <p>Serializes dictionary key values as \"{key}={value}\" like Deadline uses for EnvironmentKeyValue.</p> As an example <p>EnvironmentKeyValue0=\"A_KEY=VALUE_A\" EnvironmentKeyValue1=\"OTHER_KEY=VALUE_B\"</p> <p>The keys are serialized in alphabetical order (sorted).</p> Example <p>var = DeadlineKeyValueVar(\"EnvironmentKeyValue\") var[\"my_var\"] = \"hello\" var[\"my_other_var\"] = \"hello2\" var.serialize()</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>class DeadlineKeyValueVar(dict):\n    \"\"\"\n\n    Serializes dictionary key values as \"{key}={value}\" like Deadline uses\n    for EnvironmentKeyValue.\n\n    As an example:\n        EnvironmentKeyValue0=\"A_KEY=VALUE_A\"\n        EnvironmentKeyValue1=\"OTHER_KEY=VALUE_B\"\n\n    The keys are serialized in alphabetical order (sorted).\n\n    Example:\n        &gt;&gt;&gt; var = DeadlineKeyValueVar(\"EnvironmentKeyValue\")\n        &gt;&gt;&gt; var[\"my_var\"] = \"hello\"\n        &gt;&gt;&gt; var[\"my_other_var\"] = \"hello2\"\n        &gt;&gt;&gt; var.serialize()\n\n\n    \"\"\"\n    def __init__(self, key: str):\n        super().__init__()\n        if not key.endswith(\"{}\"):\n            key += \"{}\"\n        self._key = key\n\n    def serialize(self):\n        # Allow custom location for index in serialized string\n        return {\n            self._key.format(idx): f\"{key}={value}\"\n            for idx, (key, value) in enumerate(sorted(self.items()))\n        }\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.DeadlineWebserviceError","title":"<code>DeadlineWebserviceError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception to throw when connection to Deadline server fails.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>class DeadlineWebserviceError(Exception):\n    \"\"\"\n    Exception to throw when connection to Deadline server fails.\n    \"\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.PublishDeadlineJobInfo","title":"<code>PublishDeadlineJobInfo</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DeadlineJobInfo</code></p> <p>Contains additional AYON variables from Settings for internal logic.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>@dataclass\nclass PublishDeadlineJobInfo(DeadlineJobInfo):\n    \"\"\"Contains additional AYON variables from Settings for internal logic.\"\"\"\n\n    # AYON custom fields used for Settings\n    publish_job_state : Optional[str] = field(default=None)\n    use_published: Optional[bool] = field(default=None)\n    use_asset_dependencies: Optional[bool] = field(default=None)\n    use_workfile_dependency: Optional[bool] = field(default=None)\n    reuse_last_version: Optional[bool] = field(default=None)\n\n    @classmethod\n    def from_attribute_values(\n        cls, data: Dict[str, Any]\n    ) -&gt; \"Self\":\n        return cls(**{\n            \"ChunkSize\": data[\"chunk_size\"],\n            \"Priority\": data[\"priority\"],\n            \"MachineLimit\": data[\"machine_limit\"],\n            \"ConcurrentTasks\": data[\"concurrent_tasks\"],\n            \"Frames\": data.get(\"frames\", \"\"),\n            \"Group\": cls._sanitize(data[\"group\"]),\n            \"LimitGroups\": cls._sanitize(data[\"limit_groups\"]),\n            \"Pool\": cls._sanitize(data[\"primary_pool\"]),\n            \"SecondaryPool\": cls._sanitize(data[\"secondary_pool\"]),\n\n            # fields needed for logic, values unavailable during collection\n            \"publish_job_state\": data[\"publish_job_state\"],\n            \"use_published\": data[\"use_published\"],\n            \"use_asset_dependencies\": data[\"use_asset_dependencies\"],\n            \"use_workfile_dependency\": data[\"use_workfile_dependency\"],\n            \"reuse_last_version\": data.get(\"reuse_last_version\", False),\n        })\n\n    def add_render_job_env_var(self):\n        \"\"\"Add required env vars for valid render job submission.\"\"\"\n        self.EnvironmentKeyValue.update(\n            JobType.RENDER.get_job_env()\n        )\n\n    def add_instance_job_env_vars(self, instance):\n        \"\"\"Add all job environments as specified on the instance and context\n\n        Any instance `job_env` vars will override the context `job_env` vars.\n        \"\"\"\n        for key, value in get_instance_job_envs(instance).items():\n            self.EnvironmentKeyValue[key] = value\n\n    def _fill_serialize_value(\n        self, key: str, value: Any, output: Dict[str, Any]\n    ):\n        if key not in (\n            \"publish_job_state\",\n            \"use_published\",\n            \"use_asset_dependencies\",\n            \"use_workfile_dependency\",\n        ):\n            super()._fill_serialize_value(key, value, output)\n\n    @staticmethod\n    def _sanitize(value) -&gt; \"Union[str, List[str], None]\":\n        if isinstance(value, str):\n            if value == \"none\":\n                return None\n            return value\n        if isinstance(value, list):\n            filtered = []\n            for val in value:\n                if val and val != \"none\":\n                    filtered.append(val)\n            return filtered\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.PublishDeadlineJobInfo.add_instance_job_env_vars","title":"<code>add_instance_job_env_vars(instance)</code>","text":"<p>Add all job environments as specified on the instance and context</p> <p>Any instance <code>job_env</code> vars will override the context <code>job_env</code> vars.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>def add_instance_job_env_vars(self, instance):\n    \"\"\"Add all job environments as specified on the instance and context\n\n    Any instance `job_env` vars will override the context `job_env` vars.\n    \"\"\"\n    for key, value in get_instance_job_envs(instance).items():\n        self.EnvironmentKeyValue[key] = value\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.PublishDeadlineJobInfo.add_render_job_env_var","title":"<code>add_render_job_env_var()</code>","text":"<p>Add required env vars for valid render job submission.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>def add_render_job_env_var(self):\n    \"\"\"Add required env vars for valid render job submission.\"\"\"\n    self.EnvironmentKeyValue.update(\n        JobType.RENDER.get_job_env()\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.get_deadline_groups","title":"<code>get_deadline_groups(webservice_url, auth=None, verify=None, log=None)</code>","text":"<p>Get Groups from Deadline API.</p> <p>Parameters:</p> Name Type Description Default <code>webservice_url</code> <code>str</code> <p>Server url.</p> required <code>auth</code> <code>Optional[Tuple[str, str]]</code> <p>Tuple containing username, password</p> <code>None</code> <code>verify</code> <code>Optional[bool]</code> <p>Whether to verify the TLS certificate of the Deadline Web Service.</p> <code>None</code> <code>log</code> <code>Optional[Logger]</code> <p>Logger to log errors to, if provided.</p> <code>None</code> <p>Returns:     List[str]: Limit Groups.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If deadline webservice_url is unreachable.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>def get_deadline_groups(\n    webservice_url: str,\n    auth: Optional[Tuple[str, str]] = None,\n    verify: Optional[bool] = None,\n    log: Optional[Logger] = None,\n) -&gt; List[str]:\n    \"\"\"Get Groups from Deadline API.\n\n    Args:\n        webservice_url (str): Server url.\n        auth (Optional[Tuple[str, str]]): Tuple containing username,\n            password\n        verify(Optional[bool]): Whether to verify the TLS certificate\n            of the Deadline Web Service.\n        log (Optional[Logger]): Logger to log errors to, if provided.\n    Returns:\n        List[str]: Limit Groups.\n\n    Raises:\n        RuntimeError: If deadline webservice_url is unreachable.\n\n    \"\"\"\n    endpoint = f\"{webservice_url}/api/groups\"\n    return _get_deadline_info(endpoint, auth, verify, \"groups\", log)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.get_deadline_limit_groups","title":"<code>get_deadline_limit_groups(webservice_url, auth=None, verify=None, log=None)</code>","text":"<p>Get Limit Groups from Deadline API.</p> <p>Parameters:</p> Name Type Description Default <code>webservice_url</code> <code>str</code> <p>Server url.</p> required <code>auth</code> <code>Optional[Tuple[str, str]]</code> <p>Tuple containing username, password</p> <code>None</code> <code>verify</code> <code>Optional[bool]</code> <p>Whether to verify the TLS certificate of the Deadline Web Service.</p> <code>None</code> <code>log</code> <code>Optional[Logger]</code> <p>Logger to log errors to, if provided.</p> <code>None</code> <p>Returns:     List[str]: Limit Groups.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If deadline webservice_url is unreachable.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>def get_deadline_limit_groups(\n    webservice_url: str,\n    auth: Optional[Tuple[str, str]] = None,\n    verify: Optional[bool] = None,\n    log: Optional[Logger] = None,\n) -&gt; List[str]:\n    \"\"\"Get Limit Groups from Deadline API.\n\n    Args:\n        webservice_url (str): Server url.\n        auth (Optional[Tuple[str, str]]): Tuple containing username,\n            password\n        verify(Optional[bool]): Whether to verify the TLS certificate\n            of the Deadline Web Service.\n        log (Optional[Logger]): Logger to log errors to, if provided.\n    Returns:\n        List[str]: Limit Groups.\n\n    Raises:\n        RuntimeError: If deadline webservice_url is unreachable.\n\n    \"\"\"\n    endpoint = f\"{webservice_url}/api/limitgroups?NamesOnly=true\"\n    return _get_deadline_info(endpoint, auth, verify, \"limitgroups\", log)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.get_deadline_pools","title":"<code>get_deadline_pools(webservice_url, auth=None, verify=None, log=None)</code>","text":"<p>Get pools from Deadline API.</p> <p>Parameters:</p> Name Type Description Default <code>webservice_url</code> <code>str</code> <p>Server url.</p> required <code>auth</code> <code>Optional[Tuple[str, str]]</code> <p>Tuple containing username, password</p> <code>None</code> <code>verify</code> <code>Optional[bool]</code> <p>Whether to verify the TLS certificate of the Deadline Web Service.</p> <code>None</code> <code>log</code> <code>Optional[Logger]</code> <p>Logger to log errors to, if provided.</p> <code>None</code> <p>Returns:     List[str]: Limit Groups.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If deadline webservice is unreachable.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>def get_deadline_pools(\n    webservice_url: str,\n    auth: Optional[Tuple[str, str]] = None,\n    verify: Optional[bool] = None,\n    log: Optional[Logger] = None,\n) -&gt; List[str]:\n    \"\"\"Get pools from Deadline API.\n\n    Args:\n        webservice_url (str): Server url.\n        auth (Optional[Tuple[str, str]]): Tuple containing username,\n            password\n        verify(Optional[bool]): Whether to verify the TLS certificate\n            of the Deadline Web Service.\n        log (Optional[Logger]): Logger to log errors to, if provided.\n    Returns:\n        List[str]: Limit Groups.\n\n    Raises:\n        RuntimeError: If deadline webservice is unreachable.\n\n    \"\"\"\n    endpoint = f\"{webservice_url}/api/pools?NamesOnly=true\"\n    return _get_deadline_info(endpoint, auth, verify, \"pools\", log)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.get_deadline_workers","title":"<code>get_deadline_workers(webservice_url, auth=None, verify=None, log=None)</code>","text":"<p>Get Workers (eg.machine names) from Deadline API.</p> <p>Parameters:</p> Name Type Description Default <code>webservice_url</code> <code>str</code> <p>Server url.</p> required <code>auth</code> <code>Optional[Tuple[str, str]]</code> <p>Tuple containing username, password</p> <code>None</code> <code>verify</code> <code>Optional[bool]</code> <p>Whether to verify the TLS certificate of the Deadline Web Service.</p> <code>None</code> <code>log</code> <code>Optional[Logger]</code> <p>Logger to log errors to, if provided.</p> <code>None</code> <p>Returns:     List[str]: Limit Groups.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If deadline webservice_url is unreachable.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>def get_deadline_workers(\n    webservice_url: str,\n    auth: Optional[Tuple[str, str]] = None,\n    verify: Optional[bool] = None,\n    log: Optional[Logger] = None,\n) -&gt; List[str]:\n    \"\"\"Get Workers (eg.machine names) from Deadline API.\n\n    Args:\n        webservice_url (str): Server url.\n        auth (Optional[Tuple[str, str]]): Tuple containing username,\n            password\n        verify(Optional[bool]): Whether to verify the TLS certificate\n            of the Deadline Web Service.\n        log (Optional[Logger]): Logger to log errors to, if provided.\n    Returns:\n        List[str]: Limit Groups.\n\n    Raises:\n        RuntimeError: If deadline webservice_url is unreachable.\n\n    \"\"\"\n    endpoint = f\"{webservice_url}/api/slaves?NamesOnly=true\"\n    return _get_deadline_info(endpoint, auth, verify, \"workers\", log)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/lib.html#client.ayon_deadline.lib.get_instance_job_envs","title":"<code>get_instance_job_envs(instance)</code>","text":"<p>Add all job environments as specified on the instance and context.</p> <p>Any instance <code>job_env</code> vars will override the context <code>job_env</code> vars.</p> Source code in <code>client/ayon_deadline/lib.py</code> <pre><code>def get_instance_job_envs(instance) -&gt; \"dict[str, str]\":\n    \"\"\"Add all job environments as specified on the instance and context.\n\n    Any instance `job_env` vars will override the context `job_env` vars.\n    \"\"\"\n    # Avoid import from 'ayon_core.pipeline'\n    from ayon_core.pipeline.publish import FARM_JOB_ENV_DATA_KEY\n\n    env = {}\n    for job_env in [\n        instance.context.data.get(FARM_JOB_ENV_DATA_KEY, {}),\n        instance.data.get(FARM_JOB_ENV_DATA_KEY, {})\n    ]:\n        if job_env:\n            env.update(job_env)\n\n    # Return the dict sorted just for readability in future logs\n    if env:\n        env = dict(sorted(env.items()))\n\n    return env\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/version.html","title":"version","text":"<p>Package declaring AYON addon 'deadline' version.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/index.html","title":"plugins","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/index.html","title":"publish","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/aftereffects/index.html","title":"aftereffects","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/aftereffects/submit_aftereffects_deadline.html","title":"submit_aftereffects_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/aftereffects/submit_aftereffects_deadline.html#client.ayon_deadline.plugins.publish.aftereffects.submit_aftereffects_deadline.AfterEffectsSubmitDeadline","title":"<code>AfterEffectsSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code></p> Source code in <code>client/ayon_deadline/plugins/publish/aftereffects/submit_aftereffects_deadline.py</code> <pre><code>class AfterEffectsSubmitDeadline(\n    abstract_submit_deadline.AbstractSubmitDeadline\n):\n\n    label = \"Submit AE to Deadline\"\n    order = pyblish.api.IntegratorOrder + 0.1\n    hosts = [\"aftereffects\"]\n    families = [\"render.farm\"]  # cannot be \"render' as that is integrated\n    use_published = True\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    def get_job_info(self, job_info=None):\n        job_info.Plugin = \"AfterEffects\"\n\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            # Deadline requires integers in frame range\n            frame_range = \"{}-{}\".format(\n                int(round(self._instance.data[\"frameStart\"])),\n                int(round(self._instance.data[\"frameEnd\"])))\n            job_info.Frames = frame_range\n\n        return job_info\n\n    def get_plugin_info(self):\n        deadline_plugin_info = DeadlinePluginInfo()\n\n        render_path = self._instance.data[\"expectedFiles\"][0]\n\n        file_name, frame = list(collect_frames([render_path]).items())[0]\n        if frame:\n            # Replace frame ('000001') with Deadline's required '[#######]'\n            #   expects filename in format:\n            #   'project_folder_product_version.FRAME.ext'\n            render_dir = os.path.dirname(render_path)\n            file_name = os.path.basename(render_path)\n            hashed = '[{}]'.format(len(frame) * \"#\")\n            file_name = file_name.replace(frame, hashed)\n            render_path = os.path.join(render_dir, file_name)\n\n        deadline_plugin_info.Comp = self._instance.data[\"comp_name\"]\n        deadline_plugin_info.Version = self._instance.data[\"app_version\"]\n        # must be here because of DL AE plugin\n        # added override of multiprocess by env var, if shouldn't be used for\n        # some app variant use MULTIPROCESS:false in Settings, default is True\n        deadline_plugin_info.MultiProcess = env_value_to_bool(\n            \"MULTIPROCESS\", default=True\n        )\n        deadline_plugin_info.SceneFile = self.scene_path\n        deadline_plugin_info.Output = render_path.replace(\"\\\\\", \"/\")\n\n        return asdict(deadline_plugin_info)\n\n    def from_published_scene(self, replace_in_path=True):\n        \"\"\" Do not overwrite expected files.\n\n            Use published is set to True, so rendering will be triggered\n            from published scene (in 'publish' folder). Default implementation\n            of abstract class renames expected (eg. rendered) files accordingly\n            which is not needed here.\n        \"\"\"\n        return super().from_published_scene(False)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/aftereffects/submit_aftereffects_deadline.html#client.ayon_deadline.plugins.publish.aftereffects.submit_aftereffects_deadline.AfterEffectsSubmitDeadline.from_published_scene","title":"<code>from_published_scene(replace_in_path=True)</code>","text":"<p>Do not overwrite expected files.</p> <p>Use published is set to True, so rendering will be triggered from published scene (in 'publish' folder). Default implementation of abstract class renames expected (eg. rendered) files accordingly which is not needed here.</p> Source code in <code>client/ayon_deadline/plugins/publish/aftereffects/submit_aftereffects_deadline.py</code> <pre><code>def from_published_scene(self, replace_in_path=True):\n    \"\"\" Do not overwrite expected files.\n\n        Use published is set to True, so rendering will be triggered\n        from published scene (in 'publish' folder). Default implementation\n        of abstract class renames expected (eg. rendered) files accordingly\n        which is not needed here.\n    \"\"\"\n    return super().from_published_scene(False)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/blender/index.html","title":"blender","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/blender/submit_blender_deadline.html","title":"submit_blender_deadline","text":"<p>Submitting render job to Deadline.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/blender/submit_blender_deadline.html#client.ayon_deadline.plugins.publish.blender.submit_blender_deadline.BlenderSubmitDeadline","title":"<code>BlenderSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code>, <code>AYONPyblishPluginMixin</code></p> Source code in <code>client/ayon_deadline/plugins/publish/blender/submit_blender_deadline.py</code> <pre><code>class BlenderSubmitDeadline(abstract_submit_deadline.AbstractSubmitDeadline,\n                            AYONPyblishPluginMixin):\n    label = \"Submit Render to Deadline\"\n    hosts = [\"blender\"]\n    families = [\"render\"]  # TODO this should be farm specific as render.farm\n    settings_category = \"deadline\"\n\n    def process(self, instance):\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Render on farm is disabled. \"\n                           \"Skipping deadline submission.\")\n            return\n\n        # Always set instance output directory to the expected\n        expected_files = instance.data[\"expectedFiles\"]\n        if not expected_files:\n            raise PublishError(\n                message=\"No Render Elements found.\",\n                title=\"No Render Elements found.\",\n                description=\"Expected files for render elements are empty.\"\n            )\n\n        first_file = next(iter_expected_files(expected_files))\n        output_dir = os.path.dirname(first_file)\n        instance.data[\"outputDir\"] = output_dir\n        instance.data[\"toBeRenderedOn\"] = \"deadline\"\n\n        # We are submitting a farm job not per instance - but once per Blender\n        # scene. This is a hack to avoid submitting multiple jobs for each\n        # comp file output because the Deadline job will always render all\n        # active ones anyway (and the relevant view layers).\n        context = instance.context\n        key = f\"__hasRun{self.__class__.__name__}\"\n        if context.data.get(key, False):\n            return\n\n        context.data[key] = True\n\n        # Collect all saver instances in context that are to be rendered\n        render_instances = []\n        for inst in context:\n            if inst.data[\"productType\"] != \"render\":\n                # Allow only render instances\n                continue\n\n            if not inst.data.get(\"publish\", True):\n                # Skip inactive instances\n                continue\n\n            if not inst.data.get(\"farm\"):\n                # Only consider instances that are also set to be rendered on\n                # farm\n                continue\n\n            render_instances.append(inst)\n\n        if not render_instances:\n            raise PublishError(\"No instances found for Deadline submission\")\n\n        instance.data[\"_farmRenderInstances\"] = render_instances\n\n        super().process(instance)\n\n        # Store the response for dependent job submission plug-ins for all\n        # the instances\n        transfer_keys = [\"deadlineSubmissionJob\", \"deadline\"]\n        for render_instance in render_instances:\n            for key in transfer_keys:\n                render_instance.data[key] = instance.data[key]\n\n        # Remove this data which we only added to get access to the data\n        # in the inherited `self.get_job_info()` method.\n        instance.data.pop(\"_farmRenderInstances\", None)\n\n    def get_job_info(self, job_info=None, **kwargs):\n        instance = self._instance\n        job_info.Plugin = instance.data.get(\"blenderRenderPlugin\", \"Blender\")\n\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            # Deadline requires integers in frame range\n            frames = \"{start}-{end}x{step}\".format(\n                start=int(instance.data[\"frameStartHandle\"]),\n                end=int(instance.data[\"frameEndHandle\"]),\n                step=int(instance.data[\"byFrameStep\"]),\n            )\n            job_info.Frames = frames\n\n        # We override the default behavior of AbstractSubmitDeadline here to\n        # include the output directory and output filename for each individual\n        # render instance, instead of only the current instance, because we're\n        # submitting one job for multiple render instances.\n        for render_instance in instance.data[\"_farmRenderInstances\"]:\n            if render_instance is instance:\n                continue\n\n            self._append_job_output_paths(render_instance, job_info)\n\n        return job_info\n\n    def get_plugin_info(self):\n        # Not all hosts can import this module.\n        import bpy\n\n        plugin_info = BlenderPluginInfo(\n            SceneFile=self.scene_path,\n            Version=bpy.app.version_string,\n            SaveFile=True,\n        )\n\n        plugin_payload = asdict(plugin_info)\n\n        return plugin_payload\n\n    def process_submission(self, auth=None):\n        payload = self.assemble_payload()\n        auth = self._instance.data[\"deadline\"][\"auth\"]\n        verify = self._instance.data[\"deadline\"][\"verify\"]\n        return self.submit(payload, auth=auth, verify=verify)\n\n    def from_published_scene(self, replace_in_path=True):\n        \"\"\"\n        This is needed to set the correct path for the json metadata. Because\n        the rendering path is set in the blend file during the collection,\n        and the path is adjusted to use the published scene, this ensures that\n        the metadata and the rendered files are in the same location.\n        \"\"\"\n        return super().from_published_scene(False)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/blender/submit_blender_deadline.html#client.ayon_deadline.plugins.publish.blender.submit_blender_deadline.BlenderSubmitDeadline.from_published_scene","title":"<code>from_published_scene(replace_in_path=True)</code>","text":"<p>This is needed to set the correct path for the json metadata. Because the rendering path is set in the blend file during the collection, and the path is adjusted to use the published scene, this ensures that the metadata and the rendered files are in the same location.</p> Source code in <code>client/ayon_deadline/plugins/publish/blender/submit_blender_deadline.py</code> <pre><code>def from_published_scene(self, replace_in_path=True):\n    \"\"\"\n    This is needed to set the correct path for the json metadata. Because\n    the rendering path is set in the blend file during the collection,\n    and the path is adjusted to use the published scene, this ensures that\n    the metadata and the rendered files are in the same location.\n    \"\"\"\n    return super().from_published_scene(False)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/celaction/index.html","title":"celaction","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/celaction/submit_celaction_deadline.html","title":"submit_celaction_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/celaction/submit_celaction_deadline.html#client.ayon_deadline.plugins.publish.celaction.submit_celaction_deadline.CelactionSubmitDeadline","title":"<code>CelactionSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code></p> <p>Submit CelAction2D scene to Deadline</p> <p>Renders are submitted to a Deadline Web Service.</p> Source code in <code>client/ayon_deadline/plugins/publish/celaction/submit_celaction_deadline.py</code> <pre><code>class CelactionSubmitDeadline(abstract_submit_deadline.AbstractSubmitDeadline):\n    \"\"\"Submit CelAction2D scene to Deadline\n\n    Renders are submitted to a Deadline Web Service.\n\n    \"\"\"\n\n    label = \"Submit CelAction to Deadline\"\n    order = pyblish.api.IntegratorOrder + 0.1\n    hosts = [\"celaction\"]\n    families = [\"render.farm\"]\n\n    def get_job_info(self, job_info=None):\n        job_info.Plugin = \"CelAction\"\n\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            # Deadline requires integers in frame range\n            frame_range = \"{}-{}\".format(\n                int(round(self._instance.data[\"frameStart\"])),\n                int(round(self._instance.data[\"frameEnd\"])))\n            job_info.Frames = frame_range\n\n        return job_info\n\n    def get_plugin_info(self):\n        plugin_info = CelactionPluginInfo()\n        instance = self._instance\n\n        render_path = instance.data[\"path\"]\n        render_dir = os.path.dirname(render_path)\n\n        self._expected_files(instance, render_path)\n\n        script_path = self.scene_path\n        plugin_info.SceneFile = script_path\n        plugin_info.ProjectPath = script_path\n        plugin_info.OutputFilePath = render_dir.replace(\"\\\\\", \"/\")\n        plugin_info.StartupDirectory = \"\"\n\n        resolution_width = instance.data[\"resolutionWidth\"]\n        resolution_height = instance.data[\"resolutionHeight\"]\n        search_results = re.search(r\"(%0)(\\d)(d)[._]\", render_path).groups()\n        split_patern = \"\".join(search_results)\n        padding_number = int(search_results[1])\n\n        args = [\n            f\"&lt;QUOTE&gt;{script_path}&lt;QUOTE&gt;\",\n            \"-a\",\n            \"-16\",\n            \"-s &lt;STARTFRAME&gt;\",\n            \"-e &lt;ENDFRAME&gt;\",\n            f\"-d &lt;QUOTE&gt;{render_dir}&lt;QUOTE&gt;\",\n            f\"-x {resolution_width}\",\n            f\"-y {resolution_height}\",\n            f\"-r &lt;QUOTE&gt;{render_path.replace(split_patern, '')}&lt;QUOTE&gt;\",\n            f\"-= AbsoluteFrameNumber=on -= PadDigits={padding_number}\",\n            \"-= ClearAttachment=on\",\n        ]\n        plugin_info.Arguments = \" \".join(args)\n\n        # adding 2d render specific family for version identification in Loader\n        instance.data[\"families\"] = [\"render2d\"]\n\n        return asdict(plugin_info)\n\n    def _expected_files(self, instance, filepath):\n        \"\"\" Create expected files in instance data\n        \"\"\"\n        if not instance.data.get(\"expectedFiles\"):\n            instance.data[\"expectedFiles\"] = []\n\n        dirpath = os.path.dirname(filepath)\n        filename = os.path.basename(filepath)\n\n        if \"#\" in filename:\n            pparts = filename.split(\"#\")\n            padding = \"%0{}d\".format(len(pparts) - 1)\n            filename = pparts[0] + padding + pparts[-1]\n\n        if \"%\" not in filename:\n            instance.data[\"expectedFiles\"].append(filepath)\n            return\n\n        for i in range(self._frame_start, (self._frame_end + 1)):\n            instance.data[\"expectedFiles\"].append(\n                os.path.join(dirpath, (filename % i)).replace(\"\\\\\", \"/\")\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/fusion/index.html","title":"fusion","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/fusion/submit_fusion_deadline.html","title":"submit_fusion_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/fusion/submit_fusion_deadline.html#client.ayon_deadline.plugins.publish.fusion.submit_fusion_deadline.FusionSubmitDeadline","title":"<code>FusionSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code>, <code>AYONPyblishPluginMixin</code></p> <p>Submit current Comp to Deadline</p> <p>Renders are submitted to a Deadline Web Service as supplied via settings key \"DEADLINE_REST_URL\".</p> Source code in <code>client/ayon_deadline/plugins/publish/fusion/submit_fusion_deadline.py</code> <pre><code>class FusionSubmitDeadline(abstract_submit_deadline.AbstractSubmitDeadline,\n                           AYONPyblishPluginMixin):\n    \"\"\"Submit current Comp to Deadline\n\n    Renders are submitted to a Deadline Web Service as\n    supplied via settings key \"DEADLINE_REST_URL\".\n\n    \"\"\"\n    label = \"Submit Fusion to Deadline\"\n    order = pyblish.api.IntegratorOrder\n    hosts = [\"fusion\"]\n    families = [\"render\", \"image\"]\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    # presets\n    plugin = None\n\n    def process(self, instance):\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Render on farm is disabled. \"\n                           \"Skipping deadline submission.\")\n            return\n\n        # TODO: Avoid this hack and instead use a proper way to submit\n        #  each render per instance individually\n        # TODO: Also, we should support submitting a job per group of instances\n        #  that are set to a different frame range. Currently we're always\n        #  expecting to render the full frame range for each. Which may mean\n        #  we need multiple render jobs but a single publish job dependent on\n        #  the multiple separate instance jobs?\n        # We are submitting a farm job not per instance - but once per Fusion\n        # comp. This is a hack to avoid submitting multiple jobs for each\n        # saver separately which would be much slower.\n        context = instance.context\n        key = \"__hasRun{}\".format(self.__class__.__name__)\n        if context.data.get(key, False):\n            return\n        else:\n            context.data[key] = True\n\n        # Collect all saver instances in context that are to be rendered\n        saver_instances = []\n        context = instance.context\n        for inst in context:\n            if inst.data[\"productType\"] not in {\"image\", \"render\"}:\n                # Allow only saver family instances\n                continue\n\n            if not inst.data.get(\"publish\", True):\n                # Skip inactive instances\n                continue\n\n            self.log.debug(inst.data[\"name\"])\n            saver_instances.append(inst)\n\n        if not saver_instances:\n            raise RuntimeError(\"No instances found for Deadline submission\")\n\n        instance.data[\"_farmSaverInstances\"] = saver_instances\n\n        super().process(instance)\n\n        # Store the response for dependent job submission plug-ins for all\n        # the instances\n        transfer_keys = [\"deadlineSubmissionJob\", \"deadline\"]\n        for saver_instance in saver_instances:\n            for key in transfer_keys:\n                saver_instance.data[key] = instance.data[key]\n\n    def get_job_info(self, job_info=None, **kwargs):\n        instance = self._instance\n\n        # Deadline requires integers in frame range\n        job_info.Plugin = self.plugin or \"Fusion\"\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            job_info.Frames = \"{start}-{end}\".format(\n                start=int(instance.data[\"frameStartHandle\"]),\n                end=int(instance.data[\"frameEndHandle\"])\n            )\n\n        # We override the default behavior of AbstractSubmitDeadline here to\n        # include the output directory and output filename for each individual\n        # saver instance, instead of only the current instance, because we're\n        # submitting one job for multiple savers\n        for saver_instance in instance.data[\"_farmSaverInstances\"]:\n            if saver_instance is instance:\n                continue\n\n            self._append_job_output_paths(instance, job_info)\n\n        return job_info\n\n    def get_plugin_info(self):\n        instance = self._instance\n        plugin_info = FusionPluginInfo(\n            FlowFile=self.scene_path,\n            Version=str(instance.data[\"app_version\"]),\n        )\n        plugin_payload: dict = asdict(plugin_info)\n        return plugin_payload\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/index.html","title":"global","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_deadline_job_env_vars.html","title":"collect_deadline_job_env_vars","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_deadline_job_env_vars.html#client.ayon_deadline.plugins.publish.global.collect_deadline_job_env_vars.CollectDeadlineJobEnvVars","title":"<code>CollectDeadlineJobEnvVars</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Collect set of environment variables to submit with deadline jobs</p> Source code in <code>client/ayon_deadline/plugins/publish/global/collect_deadline_job_env_vars.py</code> <pre><code>class CollectDeadlineJobEnvVars(pyblish.api.ContextPlugin):\n    \"\"\"Collect set of environment variables to submit with deadline jobs\"\"\"\n    order = pyblish.api.CollectorOrder\n    label = \"Deadline Farm Environment Variables\"\n    targets = [\"local\"]\n\n    ENV_KEYS = [\n        # applications addon\n        \"AYON_APP_NAME\",\n\n        # ftrack addon\n        \"FTRACK_API_KEY\",\n        \"FTRACK_API_USER\",\n        \"FTRACK_SERVER\",\n\n        # kitsu addon\n        \"KITSU_SERVER\",\n        \"KITSU_LOGIN\",\n        \"KITSU_PWD\",\n\n        # Shotgrid / Flow addon\n        \"OPENPYPE_SG_USER\",\n\n        # Not sure how this is usefull for farm, scared to remove\n        \"PYBLISHPLUGINPATH\",\n\n        # NOTE still required by GlobalPreLoadJob.py, but might not be set by\n        #   ayon-core anymore\n        \"AYON_DEFAULT_SETTINGS_VARIANT\",\n    ]\n\n    def process(self, context):\n        env = context.data.setdefault(FARM_JOB_ENV_DATA_KEY, {})\n        for key in self.ENV_KEYS:\n            # Skip already set keys\n            if key in env:\n                continue\n            value = os.getenv(key)\n            if value:\n                self.log.debug(f\"Setting job env: {key}: {value}\")\n                env[key] = value\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_deadline_server_from_instance.html","title":"collect_deadline_server_from_instance","text":"<p>Collect Deadline server information from instance.</p> <p>This module collects Deadline Webservice name and URL for instance. Based on data stored on instance a deadline information is stored to instance data.</p> <p>For maya this is resolving index of server lists stored in <code>deadlineServers</code> instance attribute or using default server if that attribute doesn't exists. That happens for backwards compatibility and should be removed in future releases.</p> <p>TODOS: - Remove backwards compatibility for <code>deadlineServers</code> attribute. - Remove backwards compatibility for <code>deadlineUrl</code> attribute. - Don't store deadline url, but use server name instead.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_deadline_server_from_instance.html#client.ayon_deadline.plugins.publish.global.collect_deadline_server_from_instance.CollectDeadlineServerFromInstance","title":"<code>CollectDeadlineServerFromInstance</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collect Deadline Webservice URL from instance.</p> Source code in <code>client/ayon_deadline/plugins/publish/global/collect_deadline_server_from_instance.py</code> <pre><code>class CollectDeadlineServerFromInstance(pyblish.api.InstancePlugin):\n    \"\"\"Collect Deadline Webservice URL from instance.\"\"\"\n\n    # Run before collect_render.\n    order = pyblish.api.CollectorOrder + 0.225\n    label = \"Deadline Webservice from the Instance\"\n    targets = [\"local\"]\n\n    families = FARM_FAMILIES\n\n    def process(self, instance):\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Should not be processed on farm, skipping.\")\n            return\n\n        # NOTE: Remove when nothing sets 'deadline' to 'None'\n        if not instance.data.get(\"deadline\"):\n            # reset if key is None or not available\n            instance.data[\"deadline\"] = {}\n        deadline_info = instance.data[\"deadline\"]\n\n        context = instance.context\n        host_name = context.data[\"hostName\"]\n        # TODO: Host specific logic should be avoided\n        #   - all hosts should have same data structure on instances\n        server_name = None\n        if host_name == \"maya\":\n            deadline_url, server_name = self._collect_maya_deadline_server(\n                instance\n            )\n        else:\n            # TODO remove backwards compatibility\n            deadline_url = instance.data.get(\"deadlineUrl\")\n            if not deadline_url:\n                deadline_url = deadline_info.get(\"url\")\n                server_name = deadline_info.get(\"serverName\")\n\n        if not deadline_url:\n            context_deadline_info = context.data[\"deadline\"]\n            deadline_url = context_deadline_info[\"defaultUrl\"]\n            server_name = context_deadline_info[\"defaultServerName\"]\n\n        if not server_name:\n            server_name = self._find_server_name(instance, deadline_url)\n\n        if not server_name:\n            raise PublishError(\n                f\"Collected deadline URL '{deadline_url}' does not match any\"\n                f\" existing deadline servers configured in Studio Settings.\"\n            )\n\n        deadline_url = deadline_url.strip().rstrip(\"/\")\n        deadline_info[\"url\"] = deadline_url\n        # TODO prefer server name over url\n        deadline_info[\"serverName\"] = server_name\n\n        self.log.debug(\n            f\"Server '{server_name}' ({deadline_url})\"\n            \" will be used for submission.\"\n        )\n\n    def _find_server_name(\n        self, instance: pyblish.api.Instance,\n        deadline_url: str,\n    ) -&gt; Optional[str]:\n        \"\"\"Find server name from project settings based on url.\n\n        Args:\n            instance (pyblish.api.Instance): Instance object.\n            deadline_url (str): Deadline Webservice URL.\n\n        Returns:\n            Optional[str]: Deadline server name.\n\n        \"\"\"\n        deadline_url = deadline_url.strip().rstrip(\"/\")\n\n        deadline_settings = (\n            instance.context.data[\"project_settings\"][\"deadline\"]\n        )\n        for server_info in deadline_settings[\"deadline_servers_info\"]:\n            if server_info[\"value\"].strip().rstrip(\"/\") == deadline_url:\n                return server_info[\"name\"]\n        return None\n\n    def _collect_maya_deadline_server(\n        self, render_instance: pyblish.api.Instance\n    ) -&gt; Tuple[str, str]:\n        \"\"\"Get Deadline Webservice URL from render instance.\n\n        This will get all configured Deadline Webservice URLs and create\n        subset of them based upon project configuration. It will then take\n        `deadlineServers` from render instance that is now basically `int`\n        index of that list.\n\n        Args:\n            render_instance (pyblish.api.Instance): Render instance created\n                by Creator in Maya.\n\n        Returns:\n            tuple[str, str]: Selected Deadline Webservice URL.\n\n        \"\"\"\n        from maya import cmds\n\n        deadline_settings = (\n            render_instance.context.data\n            [\"project_settings\"]\n            [\"deadline\"]\n        )\n        # QUESTION How and where is this is set? Should be removed?\n        instance_server = render_instance.data.get(\"deadlineServers\")\n        if not instance_server:\n            context_deadline_info = render_instance.context.data[\"deadline\"]\n            default_server_url = context_deadline_info[\"defaultUrl\"]\n            default_server_name = context_deadline_info[\"defaultServerName\"]\n            self.log.debug(\"Using default server.\")\n            return default_server_url, default_server_name\n\n        # Get instance server as sting.\n        if isinstance(instance_server, int):\n            instance_server = cmds.getAttr(\n                \"{}.deadlineServers\".format(render_instance.data[\"objset\"]),\n                asString=True\n            )\n\n        default_servers = {\n            url_item[\"name\"]: url_item[\"value\"]\n            for url_item in deadline_settings[\"deadline_servers_info\"]\n        }\n        project_servers = deadline_settings[\"deadline_servers\"]\n        if not project_servers:\n            self.log.debug(\"Not project servers found. Using default servers.\")\n            return default_servers[instance_server], instance_server\n\n        # TODO create validation plugin for this check\n        project_enabled_servers = {\n            k: default_servers[k]\n            for k in project_servers\n            if k in default_servers\n        }\n        if instance_server not in project_enabled_servers:\n            msg = (\n                \"\\\"{}\\\" server on instance is not enabled in project settings.\"\n                \" Enabled project servers:\\n{}\".format(\n                    instance_server, project_enabled_servers\n                )\n            )\n            raise KnownPublishError(msg)\n\n        self.log.debug(\"Using project approved server.\")\n        return project_enabled_servers[instance_server], instance_server\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_default_deadline_server.html","title":"collect_default_deadline_server","text":"<p>Collect default Deadline server.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_default_deadline_server.html#client.ayon_deadline.plugins.publish.global.collect_default_deadline_server.CollectDefaultDeadlineServer","title":"<code>CollectDefaultDeadlineServer</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Collect default Deadline Webservice URL.</p> <p>DL webservice addresses must be configured first in System Settings for project settings enum to work.</p> <p>Default webservice could be overridden by <code>project_settings/deadline/deadline_servers</code>. Currently only single url is expected.</p> <p>This url could be overridden by some hosts directly on instances with <code>CollectDeadlineServerFromInstance</code>.</p> Source code in <code>client/ayon_deadline/plugins/publish/global/collect_default_deadline_server.py</code> <pre><code>class CollectDefaultDeadlineServer(pyblish.api.ContextPlugin):\n    \"\"\"Collect default Deadline Webservice URL.\n\n    DL webservice addresses must be configured first in System Settings for\n    project settings enum to work.\n\n    Default webservice could be overridden by\n    `project_settings/deadline/deadline_servers`. Currently only single url\n    is expected.\n\n    This url could be overridden by some hosts directly on instances with\n    `CollectDeadlineServerFromInstance`.\n    \"\"\"\n\n    # Run before collect_deadline_server_instance.\n    order = pyblish.api.CollectorOrder + 0.200\n    label = \"Default Deadline Webservice\"\n    targets = [\"local\"]\n\n    def process(self, context):\n        deadline_addon = context.data[\"ayonAddonsManager\"][\"deadline\"]\n\n        deadline_settings = context.data[\"project_settings\"][\"deadline\"]\n        deadline_server_name = deadline_settings[\"deadline_server\"]\n\n        dl_server_info = None\n        if deadline_server_name:\n            dl_server_info = deadline_addon.deadline_servers_info.get(\n                deadline_server_name)\n\n        if dl_server_info:\n            deadline_url = dl_server_info[\"value\"]\n        else:\n            key = next(k for k in deadline_addon.deadline_servers_info.keys())\n            default_dl_server_info = deadline_addon.deadline_servers_info[key]\n            deadline_url = default_dl_server_info[\"value\"]\n\n        context.data[\"deadline\"] = {\n            \"defaultUrl\": deadline_url.strip().rstrip(\"/\"),\n            \"defaultServerName\": deadline_server_name,\n        }\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_environment_file_to_delete.html","title":"collect_environment_file_to_delete","text":"<p>Collect persistent environment file to be deleted.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_environment_file_to_delete.html#client.ayon_deadline.plugins.publish.global.collect_environment_file_to_delete.CollectEnvironmentFileToDelete","title":"<code>CollectEnvironmentFileToDelete</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Marks file with extracted environments to be deleted too.</p> <p>'GlobalJobPreLoad' produces persistent environment file which gets created only once per AYON_SITE_ID which should be set on all (similar) render nodes. (More granular values for AYON_SITE_ID could be used if necessary.)</p> <p>This approach limits DB querying, but keeps extracting of environments on render workers, not during submission.</p> <p>These files are created next to metadata.json in <code>.ayon_env_cache</code> folder and need to be removed also, but only during publish job.</p> Source code in <code>client/ayon_deadline/plugins/publish/global/collect_environment_file_to_delete.py</code> <pre><code>class CollectEnvironmentFileToDelete(pyblish.api.ContextPlugin):\n    \"\"\"Marks file with extracted environments to be deleted too.\n\n    'GlobalJobPreLoad' produces persistent environment file which gets created\n    only once per AYON_SITE_ID which should be set on all (similar) render\n    nodes. (More granular values for AYON_SITE_ID could be used if necessary.)\n\n    This approach limits DB querying, but keeps extracting\n    of environments on render workers, not during submission.\n\n    These files are created next to metadata.json in `.ayon_env_cache` folder\n    and need to be removed also, but only during publish job.\n    \"\"\"\n\n    order = pyblish.api.CollectorOrder\n    label = \"Collect Environment File\"\n    targets = [\"farm\"]\n\n    def process(self, context):\n        for instance in context:\n            is_persistent = instance.data.get(\"stagingDir_persistent\", False)\n            if is_persistent:\n                self.log.debug(\"Staging dir is persistent, no cleaning.\")\n                return\n\n        publish_data_paths = os.environ.get(\"AYON_PUBLISH_DATA\")\n        if not publish_data_paths:\n            self.log.warning(\"Cannot find folder with metadata files.\")\n            return\n\n        anatomy = context.data[\"anatomy\"]\n        paths = publish_data_paths.split(os.pathsep)\n        for path in paths:\n            if not path:\n                continue\n            path = anatomy.fill_root(path)\n            metadata_folder = os.path.dirname(path)\n            shared_env_folder = os.path.join(\n                metadata_folder, \".ayon_env_cache\")\n            if not os.path.exists(shared_env_folder):\n                continue\n            for file_name in os.listdir(shared_env_folder):\n                if file_name.startswith('env_'):\n                    file_path = os.path.join(shared_env_folder, file_name)\n                    context.data[\"cleanupFullPaths\"].append(file_path)\n\n            context.data[\"cleanupEmptyDirs\"].append(shared_env_folder)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_jobinfo.html","title":"collect_jobinfo","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_jobinfo.html#client.ayon_deadline.plugins.publish.global.collect_jobinfo.CollectJobInfo","title":"<code>CollectJobInfo</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>AYONPyblishPluginMixin</code></p> <p>Collect variables that belong to Deadline's JobInfo.</p> <p>Variables like: - department - priority - chunk size</p> Source code in <code>client/ayon_deadline/plugins/publish/global/collect_jobinfo.py</code> <pre><code>class CollectJobInfo(pyblish.api.InstancePlugin, AYONPyblishPluginMixin):\n    \"\"\"Collect variables that belong to Deadline's JobInfo.\n\n    Variables like:\n    - department\n    - priority\n    - chunk size\n\n    \"\"\"\n\n    order = pyblish.api.CollectorOrder + 0.420\n    label = \"Collect Deadline JobInfo\"\n\n    families = FARM_FAMILIES\n    targets = [\"local\"]\n\n    profiles = []\n    pool_enum_values = []\n    group_enum_values = []\n    limit_group_enum_values = []\n    machines_enum_values = []\n\n    def process(self, instance):\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Should not be processed on farm, skipping.\")\n            return\n\n        attr_values = self._get_jobinfo_defaults(instance)\n        if not attr_values:\n            raise PublishError(\n                \"No profile selected for defaults. Ask Admin to \"\n                \"fill generic profiles at \"\n                \"ayon+settings://deadline/publish/CollectJobInfo/profiles\"\n            )\n\n        attr_values.update(self.get_attr_values_from_data(instance.data))\n        job_info = PublishDeadlineJobInfo.from_attribute_values(attr_values)\n\n        self._handle_machine_list(attr_values, job_info)\n        self._handle_job_delay(attr_values, job_info)\n        self._handle_custom_frames(attr_values, job_info)\n\n        self._handle_additional_jobinfo(attr_values, job_info)\n\n        # pass through explicitly key and values for PluginInfo\n        plugin_info_data = None\n        if attr_values[\"additional_plugin_info\"]:\n            plugin_info_data = json.loads(\n                attr_values[\"additional_plugin_info\"]\n            )\n\n        deadline_info = instance.data[\"deadline\"]\n        deadline_info[\"job_info\"] = job_info\n        deadline_info[\"plugin_info_data\"] = plugin_info_data\n\n        self._add_deadline_families(instance)\n\n    def _add_deadline_families(self, instance):\n        \"\"\"Add deadline specific families to instance.\n\n        Add 'deadline' to all instances and 'deadline.submit.publish.job'\n            to instances that should create publish job.\n\n        \"\"\"\n        instance_families = instance.data.setdefault(\"families\", [])\n        all_families = set(instance_families)\n        all_families.add(instance.data[\"family\"])\n\n        # Add deadline family\n        if \"deadline\" not in instance_families:\n            instance_families.append(\"deadline\")\n\n        # 'publish.hou' has different submit job plugin\n        # TODO find out if we need separate submit publish job plugin\n        if (\n            \"publish.hou\" in all_families\n            or \"remote_publish_on_farm\" in all_families\n        ):\n            return\n\n        # Add submit publish job family\n        if \"deadline.submit.publish.job\" not in instance_families:\n            instance_families.append(\"deadline.submit.publish.job\")\n\n    def _handle_additional_jobinfo(self,attr_values, job_info):\n        \"\"\"Adds not explicitly implemented fields by values from Settings.\"\"\"\n        additional_job_info = attr_values[\"additional_job_info\"]\n        if not additional_job_info:\n            return\n        for key, value in json.loads(additional_job_info).items():\n            setattr(job_info, key, value)\n\n    def _handle_machine_list(self, attr_values, job_info):\n        machine_list = attr_values[\"machine_list\"]\n        if machine_list:\n            if attr_values[\"machine_list_deny\"]:\n                job_info.Blacklist = machine_list\n                job_info.Whitelist = None\n            else:\n                job_info.Whitelist = machine_list\n                job_info.Blacklist = None\n\n    def _handle_job_delay(self, attr_values, job_info):\n        job_delay = attr_values[\"job_delay\"]\n        if not job_delay:\n            return\n        try:\n            parts = job_delay.split(':')\n            if len(parts) != 4:\n                raise ValueError(\"Invalid format: requires dd:hh:mm:ss\")\n\n            _days = int(parts[0])\n            hours = int(parts[1])\n            minutes = int(parts[2])\n            seconds = int(parts[3])\n\n            formatted_time_string = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n            _ = datetime.strptime(formatted_time_string, \"%H:%M:%S\").time()\n            job_info.JobDelay = job_delay\n            job_info.ScheduledType = \"Once\"\n        except ValueError:\n            self.log.warning(\n                f\"Job delay '{job_delay}' doesn't match to \"\n                \"'dd:hh:mm:ss' format\"\n            )\n            job_info.JobDelay = None\n\n    def _handle_custom_frames(self, attr_values, job_info):\n        \"\"\"Fill JobInfo.Frames only if dropdown says so.\"\"\"\n        job_info.Frames = None\n        job_info.reuse_last_version = False\n        use_custom_frames = self._is_custom_frames_used(\n            attr_values[\"use_custom_frames\"]\n        )\n        if use_custom_frames:\n            if not attr_values[\"frames\"]:\n                raise KnownPublishError(\"Please fill `Custom Frames` value\")\n            job_info.Frames = attr_values[\"frames\"]\n            if attr_values[\"use_custom_frames\"] == \"reuse_last_version\":\n                job_info.reuse_last_version = True\n\n    @classmethod\n    def apply_settings(cls, project_settings):\n        settings = project_settings[\"deadline\"]\n        profiles = settings[\"publish\"][cls.__name__][\"profiles\"]\n\n        cls.profiles = profiles or []\n\n        addons_manager = AddonsManager(project_settings)\n        deadline_addon = addons_manager[\"deadline\"]\n        deadline_server_name = settings[\"deadline_server\"]\n        pools = []\n        groups = []\n        limit_groups = []\n        machines = []\n        try:\n            server_info = deadline_addon.get_server_info_by_name(\n                deadline_server_name\n            )\n            pools = [\n                {\"value\": pool, \"label\": pool}\n                for pool in server_info.pools\n            ]\n            # Groups always includes the default 'none' group\n            groups = [\n                {\"value\": group, \"label\": group}\n                for group in server_info.groups\n            ]\n            limit_groups = [\n                {\"value\": limit_group, \"label\": limit_group}\n                for limit_group in server_info.limit_groups\n            ]\n            machines = [\n                {\"value\": machine, \"label\": machine}\n                for machine in server_info.machines\n            ]\n        except DeadlineWebserviceError:\n            cls.log.warning(f\"Unable to connect to {deadline_server_name}\")\n\n        for items in [\n            pools, groups, limit_groups, machines\n        ]:\n            if not items:\n                items.append({\"value\": None, \"label\": \"&lt; none &gt;\"})\n\n        cls.pool_enum_values = pools\n        cls.group_enum_values = groups\n        cls.limit_group_enum_values = limit_groups\n        cls.machines_enum_values = machines\n\n    @classmethod\n    def get_attr_defs_for_instance(cls, create_context, instance):\n        \"\"\"Get list of attr defs that are set in Settings as artist overridable\n\n        Args:\n            create_context (ayon_core.pipeline.create.CreateContext)\n            instance (ayon_core.pipeline.create.CreatedInstance):\n\n        Returns:\n            (list)\n        \"\"\"\n        if not cls.instance_matches_plugin_families(instance):\n            return []\n\n        host_name = create_context.host_name\n\n        task_name = instance[\"task\"]\n        folder_path = instance[\"folderPath\"]\n        task_entity = create_context.get_task_entity(folder_path, task_name)\n\n        task_name = task_type = None\n        if task_entity:\n            task_name = task_entity[\"name\"]\n            task_type = task_entity[\"taskType\"]\n        profile = filter_profiles(\n            cls.profiles,\n            {\n                \"host_names\": host_name,\n                \"task_types\": task_type,\n                \"task_names\": task_name,\n                # \"product_type\": product_type\n            }\n        )\n        if not profile:\n            return []\n        overrides = set(profile[\"overrides\"])\n        if not overrides:\n            return []\n\n        defs = [\n            UISeparatorDef(\"deadline_defs_starts\"),\n        ]\n\n        defs.extend(cls._get_artist_overrides(overrides, profile))\n\n        use_custom_frames = (\n            cls._get_publish_use_custom_frames_value(instance.data) or \"none\"\n        )\n\n        # explicit frames to render - for test renders\n        use_custom_frames_enum_values = [\n            {\"value\": \"none\", \"label\": \"Task Frame Range\"},\n            {\"value\": \"custom_only\", \"label\": \"Custom Frames Only\"},\n            {\"value\": \"reuse_last_version\", \"label\": \"Reuse from Last Version\"}\n        ]\n        defs.append(\n            EnumDef(\n                \"use_custom_frames\",\n                label=\"Use Custom Frames\",\n                default=use_custom_frames,\n                items=use_custom_frames_enum_values,\n            )\n        )\n        custom_frames_visible = cls._is_custom_frames_used(use_custom_frames)\n        defs.append(\n            TextDef(\n                \"frames\",\n                label=\"Custom Frames\",\n                default=\"\",\n                tooltip=\"Explicit frames to be rendered. (1001,1003-1004)(2x)\",\n                visible=custom_frames_visible\n            )\n        )\n\n        defs.append(\n            UISeparatorDef(\"deadline_defs_end\")\n        )\n\n        return defs\n\n    @classmethod\n    def _get_artist_overrides(cls, overrides, profile):\n        \"\"\"Provide list of all possible Defs that could be filled by artist\"\"\"\n        # should be matching to extract_jobinfo_overrides_enum\n        default_values = {}\n        for key in overrides:\n            default_value = profile[key]\n            if key == \"machine_limit\":\n                available_values = {\n                    item[\"value\"]\n                    for item in cls.machines_enum_values\n                }\n                default_value = [\n                    value\n                    for value in default_value\n                    if value in available_values\n                ]\n            elif key == \"limit_groups\":\n                available_values = {\n                    item[\"value\"]\n                    for item in cls.limit_group_enum_values\n                }\n                default_value = [\n                    value\n                    for value in default_value\n                    if value in available_values\n                ]\n            elif key == \"group\":\n                available_values = [\n                    item[\"value\"]\n                    for item in cls.group_enum_values\n                ]\n                if not available_values:\n                    default_value = None\n                elif default_value not in available_values:\n                    default_value = available_values[0]\n            default_values[key] = default_value\n\n        attr_defs = [\n            NumberDef(\n                \"chunk_size\",\n                label=\"Frames Per Task\",\n                default=default_values.get(\"chunk_size\"),\n                decimals=0,\n                minimum=1,\n                maximum=1000\n            ),\n            NumberDef(\n                \"concurrent_tasks\",\n                label=\"Concurrent Tasks\",\n                tooltip=\"Number of concurrent tasks to run per render node\",\n                default=default_values.get(\"concurrent_tasks\"),\n                decimals=0,\n                minimum=1,\n                maximum=1000\n            ),\n            NumberDef(\n                \"priority\",\n                label=\"Priority\",\n                default=default_values.get(\"priority\"),\n                decimals=0\n            ),\n            TextDef(\n                \"department\",\n                label=\"Department\",\n                default=default_values.get(\"department\")\n            ),\n            EnumDef(\n                \"group\",\n                label=\"Group\",\n                default=default_values.get(\"group\"),\n                items=cls.group_enum_values,\n            ),\n            EnumDef(\n                \"limit_groups\",\n                label=\"Limit Groups\",\n                multiselection=True,\n                default=default_values.get(\"limit_groups\"),\n                items=cls.limit_group_enum_values,\n            ),\n            EnumDef(\n                \"primary_pool\",\n                label=\"Primary pool\",\n                default=default_values.get(\"primary_pool\", \"none\"),\n                items=cls.pool_enum_values,\n            ),\n            EnumDef(\n                \"secondary_pool\",\n                label=\"Secondary pool\",\n                default=default_values.get(\"secondary_pool\", \"none\"),\n                items=cls.pool_enum_values,\n            ),\n            EnumDef(\n                \"machine_list\",\n                label=\"Machine list\",\n                multiselection=True,\n                default=default_values.get(\"machine_list\"),\n                items=cls.machines_enum_values,\n            ),\n            BoolDef(\n                \"machine_list_deny\",\n                label=\"Machine List is a Deny\",\n                default=default_values.get(\"machine_list_deny\")\n            ),\n            TextDef(\n                \"job_delay\",\n                label=\"Delay job\",\n                default=default_values.get(\"job_delay\"),\n                tooltip=(\n                    \"Delay job by specified timecode. Format: dd:hh:mm:ss\"\n                ),\n                placeholder=\"00:00:00:00\"\n            ),\n            EnumDef(\n                \"publish_job_state\",\n                label=\"Publish Job State\",\n                default=default_values.get(\"publish_job_state\"),\n                items=[\n                    {\"value\": \"active\", \"label\": \"Active\"},\n                    {\"value\": \"suspended\", \"label\": \"Suspended\"}\n                ]\n            )\n        ]\n\n        return [\n            attr_def\n            for attr_def in attr_defs\n            if attr_def.key in overrides\n        ]\n\n    @classmethod\n    def register_create_context_callbacks(cls, create_context):\n        create_context.add_value_changed_callback(cls.on_values_changed)\n\n    @classmethod\n    def on_values_changed(cls, event):\n        for instance_change in event[\"changes\"]:\n            custom_frame_change = cls._get_publish_use_custom_frames_value(\n                instance_change[\"changes\"]\n            )\n\n            instance = instance_change[\"instance\"]\n            #recalculate only if context changes\n            if (\n                \"task\" not in instance_change\n                and \"folderPath\" not in instance_change\n                and not custom_frame_change\n            ):\n                continue\n\n            if not cls.instance_matches_plugin_families(instance):\n                continue\n\n            new_attrs = cls.get_attr_defs_for_instance(\n                event[\"create_context\"], instance\n            )\n            instance.set_publish_plugin_attr_defs(cls.__name__, new_attrs)\n\n    @classmethod\n    def _is_custom_frames_used(cls, value):\n        return value in [\"custom_only\", \"reuse_last_version\"]\n\n    @classmethod\n    def _get_publish_use_custom_frames_value(cls, instance_data):\n        return (\n            instance_data.get(\"publish_attributes\", {})\n                         .get(\"CollectJobInfo\", {})\n                         .get(\"use_custom_frames\")\n        )\n\n    def _get_jobinfo_defaults(self, instance):\n        \"\"\"Queries project setting for profile with default values\n\n        Args:\n            instance (pyblish.api.Instance): Source instance.\n\n        Returns:\n            (dict)\n        \"\"\"\n        context_data = instance.context.data\n        host_name = context_data[\"hostName\"]\n        task_entity = context_data[\"taskEntity\"]\n\n        task_name = task_type = None\n        if task_entity:\n            task_name = task_entity[\"name\"]\n            task_type = task_entity[\"taskType\"]\n\n        profile = filter_profiles(\n            self.profiles,\n            {\n                \"host_names\": host_name,\n                \"task_types\": task_type,\n                \"task_names\": task_name,\n                # \"product_type\": product_type\n            }\n        )\n        return profile or {}\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_jobinfo.html#client.ayon_deadline.plugins.publish.global.collect_jobinfo.CollectJobInfo.get_attr_defs_for_instance","title":"<code>get_attr_defs_for_instance(create_context, instance)</code>  <code>classmethod</code>","text":"<p>Get list of attr defs that are set in Settings as artist overridable</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>CreatedInstance</code> required <p>Returns:</p> Type Description <p>(list)</p> Source code in <code>client/ayon_deadline/plugins/publish/global/collect_jobinfo.py</code> <pre><code>@classmethod\ndef get_attr_defs_for_instance(cls, create_context, instance):\n    \"\"\"Get list of attr defs that are set in Settings as artist overridable\n\n    Args:\n        create_context (ayon_core.pipeline.create.CreateContext)\n        instance (ayon_core.pipeline.create.CreatedInstance):\n\n    Returns:\n        (list)\n    \"\"\"\n    if not cls.instance_matches_plugin_families(instance):\n        return []\n\n    host_name = create_context.host_name\n\n    task_name = instance[\"task\"]\n    folder_path = instance[\"folderPath\"]\n    task_entity = create_context.get_task_entity(folder_path, task_name)\n\n    task_name = task_type = None\n    if task_entity:\n        task_name = task_entity[\"name\"]\n        task_type = task_entity[\"taskType\"]\n    profile = filter_profiles(\n        cls.profiles,\n        {\n            \"host_names\": host_name,\n            \"task_types\": task_type,\n            \"task_names\": task_name,\n            # \"product_type\": product_type\n        }\n    )\n    if not profile:\n        return []\n    overrides = set(profile[\"overrides\"])\n    if not overrides:\n        return []\n\n    defs = [\n        UISeparatorDef(\"deadline_defs_starts\"),\n    ]\n\n    defs.extend(cls._get_artist_overrides(overrides, profile))\n\n    use_custom_frames = (\n        cls._get_publish_use_custom_frames_value(instance.data) or \"none\"\n    )\n\n    # explicit frames to render - for test renders\n    use_custom_frames_enum_values = [\n        {\"value\": \"none\", \"label\": \"Task Frame Range\"},\n        {\"value\": \"custom_only\", \"label\": \"Custom Frames Only\"},\n        {\"value\": \"reuse_last_version\", \"label\": \"Reuse from Last Version\"}\n    ]\n    defs.append(\n        EnumDef(\n            \"use_custom_frames\",\n            label=\"Use Custom Frames\",\n            default=use_custom_frames,\n            items=use_custom_frames_enum_values,\n        )\n    )\n    custom_frames_visible = cls._is_custom_frames_used(use_custom_frames)\n    defs.append(\n        TextDef(\n            \"frames\",\n            label=\"Custom Frames\",\n            default=\"\",\n            tooltip=\"Explicit frames to be rendered. (1001,1003-1004)(2x)\",\n            visible=custom_frames_visible\n        )\n    )\n\n    defs.append(\n        UISeparatorDef(\"deadline_defs_end\")\n    )\n\n    return defs\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_scene_render_cleanup.html","title":"collect_scene_render_cleanup","text":"<p>Collect persistent environment file to be deleted.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_scene_render_cleanup.html#client.ayon_deadline.plugins.publish.global.collect_scene_render_cleanup.CollectSceneRenderCleanUp","title":"<code>CollectSceneRenderCleanUp</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collect files and directories to be cleaned up</p> Source code in <code>client/ayon_deadline/plugins/publish/global/collect_scene_render_cleanup.py</code> <pre><code>class CollectSceneRenderCleanUp(pyblish.api.InstancePlugin):\n    \"\"\"Collect files and directories to be cleaned up\n    \"\"\"\n\n    order = pyblish.api.CollectorOrder - 0.1\n    label = \"Collect Scene Render Clean Up\"\n    targets = [\"farm\"]\n\n    def process(self, instance):\n        representations : List[Dict] = instance.data.get(\"representations\", [])\n        staging_dirs: List[str] = []\n        files : List[str] = []\n        for repre in representations:\n            staging_dir = repre.get(\"stagingDir\")\n            for filename in os.listdir(staging_dir):\n                base, _ = os.path.splitext(filename)\n                if not base.endswith(\"_tmp\"):\n                    continue\n                staging_dirs.append(staging_dir)\n                files.append(os.path.join(staging_dir, filename))\n\n            # Check for blender temporary dir\n            blender_tmp_dir = os.path.join(staging_dir, \"tmp\")\n            if not os.path.exists(blender_tmp_dir):\n                blender_tmp_dir = os.path.join(\n                    os.path.dirname(staging_dir), \"tmp\")\n                if not os.path.exists(blender_tmp_dir):\n                    continue\n            staging_dirs.append(blender_tmp_dir)\n            for tmp_file in os.listdir(blender_tmp_dir):\n                files.append(os.path.join(blender_tmp_dir, tmp_file))\n\n        instance.context.data[\"cleanupFullPaths\"].extend(files)\n        self.log.debug(f\"Files to clean up: {files}\")\n        instance.context.data[\"cleanupEmptyDirs\"].extend(staging_dirs)\n        self.log.debug(f\"Staging dirs to clean up: {staging_dirs}\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_usd_pinning_env_vars.html","title":"collect_usd_pinning_env_vars","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_user_credentials.html","title":"collect_user_credentials","text":"<p>Collect user credentials</p> Requires <p>context -&gt; project_settings instance.data[\"deadline\"][\"url\"]</p> Provides <p>instance.data[\"deadline\"] -&gt; require_authentication (bool) instance.data[\"deadline\"] -&gt; auth (tuple (str, str)) -     (username, password) or None</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/collect_user_credentials.html#client.ayon_deadline.plugins.publish.global.collect_user_credentials.CollectDeadlineUserCredentials","title":"<code>CollectDeadlineUserCredentials</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collects user name and password for artist if DL requires authentication</p> <p>If Deadline server is marked to require authentication, it looks first for default values in 'Studio Settings', which could be overriden by artist dependent values from 'Site settings`.</p> Source code in <code>client/ayon_deadline/plugins/publish/global/collect_user_credentials.py</code> <pre><code>class CollectDeadlineUserCredentials(pyblish.api.InstancePlugin):\n    \"\"\"Collects user name and password for artist if DL requires authentication\n\n    If Deadline server is marked to require authentication, it looks first for\n    default values in 'Studio Settings', which could be overriden by artist\n    dependent values from 'Site settings`.\n    \"\"\"\n    order = pyblish.api.CollectorOrder + 0.250\n    label = \"Collect Deadline User Credentials\"\n\n    targets = [\"local\"]\n\n    families = FARM_FAMILIES\n\n    def process(self, instance):\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Should not be processed on farm, skipping.\")\n            return\n\n        collected_deadline_url = instance.data[\"deadline\"][\"url\"]\n        if not collected_deadline_url:\n            raise ValueError(\"Instance doesn't have '[deadline][url]'.\")\n        context_data = instance.context.data\n\n        # deadline url might be set directly from instance, need to find\n        # metadata for it\n        deadline_server_name = instance.data[\"deadline\"].get(\"serverName\")\n        dealine_info_by_server_name = {\n            deadline_info[\"name\"]: deadline_info\n            for deadline_info in (\n                context_data[\"project_settings\"][\"deadline\"][\"deadline_urls\"]\n            )\n        }\n        if deadline_server_name is None:\n            self.log.warning(\n                \"DEV WARNING: Instance does not have set\"\n                \" instance['deadline']['serverName'].\"\n            )\n            for deadline_info in dealine_info_by_server_name.values():\n                dl_settings_url = deadline_info[\"value\"].strip().rstrip(\"/\")\n                if dl_settings_url == collected_deadline_url:\n                    deadline_server_name = deadline_info[\"name\"]\n                    break\n\n        if not deadline_server_name:\n            raise ValueError(\n                f\"Collected {collected_deadline_url} doesn't\"\n                \" match any site configured in Studio Settings\"\n            )\n\n        deadline_info = dealine_info_by_server_name[deadline_server_name]\n        instance.data[\"deadline\"][\"require_authentication\"] = (\n            deadline_info[\"require_authentication\"]\n        )\n        instance.data[\"deadline\"][\"auth\"] = None\n\n        instance.data[\"deadline\"][\"verify\"] = (\n            not deadline_info[\"not_verify_ssl\"]\n        )\n\n        if not deadline_info[\"require_authentication\"]:\n            return\n\n        addons_manager = instance.context.data[\"ayonAddonsManager\"]\n        deadline_addon = addons_manager[\"deadline\"]\n\n        default_username = deadline_info[\"default_username\"]\n        default_password = deadline_info[\"default_password\"]\n        if default_username and default_password:\n            self.log.debug(\"Setting credentials from defaults\")\n            instance.data[\"deadline\"][\"auth\"] = (\n                default_username, default_password\n            )\n\n        site_id = os.environ[\"AYON_SITE_ID\"]\n        local_settings = get_addon_site_settings(\n            deadline_addon.name, deadline_addon.version, site_id)\n        local_settings = local_settings[\"local_settings\"]\n        for server_info in local_settings:\n            if deadline_server_name == server_info[\"server_name\"]:\n                if server_info[\"username\"] and server_info[\"password\"]:\n                    self.log.debug(\"Setting credentials from Site Settings\")\n                    instance.data[\"deadline\"][\"auth\"] = \\\n                        (server_info[\"username\"], server_info[\"password\"])\n                    break\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/extract_last_version_files.html","title":"extract_last_version_files","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/extract_last_version_files.html#client.ayon_deadline.plugins.publish.global.extract_last_version_files.ExtractLastVersionFiles","title":"<code>ExtractLastVersionFiles</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Copies files of last version to fill gaps.</p> <p>This functionality allows to render and replace only selected frames. It produces new version with newly rendered frames and rest of them is used from last version (if available).</p> Source code in <code>client/ayon_deadline/plugins/publish/global/extract_last_version_files.py</code> <pre><code>class ExtractLastVersionFiles(pyblish.api.InstancePlugin):\n    \"\"\"Copies files of last version to fill gaps.\n\n    This functionality allows to render and replace only selected frames.\n    It produces new version with newly rendered frames and rest of them is used\n    from last version (if available).\n    \"\"\"\n\n    label = \"Copy Last Version Files\"\n    order = pyblish.api.ExtractorOrder\n    families = [\"render\"]\n    targets = [\"deadline\"]\n    settings_category = \"deadline\"\n\n    def process(self, instance):\n        \"\"\"Process all the nodes in the instance\"\"\"\n        if not instance.data.get(\"reuseLastVersion\"):\n            return\n\n        frame_start = instance.data[\"frameStart\"]\n        frame_end = instance.data[\"frameEnd\"]\n\n        for repre in instance.data[\"representations\"]:\n            files = repre[\"files\"]\n\n            is_image_sequence = (\n                f\".{repre['ext']}\" in IMAGE_EXTENSIONS and\n                isinstance(files, list)\n            )\n            if not is_image_sequence:\n                self.log.debug(\n                    f\"Representation '{repre['ext']}' is not image sequence\"\n                )\n                continue\n\n            collections = clique.assemble(\n                files,\n            )[0]\n            if len(collections) != 1:\n                raise KnownPublishError(\n                    \"Multiple collections {} found.\".format(collections)\n                )\n\n            collection = collections[0]\n\n            used_version_entity, last_version_copied_files = (\n                fill_sequence_gaps_with_previous_version(\n                    collection=collection,\n                    staging_dir=repre[\"stagingDir\"],\n                    instance=instance,\n                    current_repre_name=repre[\"name\"],\n                    start_frame=frame_start,\n                    end_frame=frame_end,\n                )\n            )\n            if not last_version_copied_files:\n                raise KnownPublishError(\"Couldn't copy last version files.\")\n\n            added_file_names = [\n                os.path.basename(file_path)\n                for file_path in last_version_copied_files.values()\n            ]\n            repre[\"files\"].extend(added_file_names)\n\n            # reset representation/instance to original length\n            repre[\"frameStart\"] = used_version_entity[\"attrib\"][\"frameStart\"]\n            repre[\"frameEnd\"] = used_version_entity[\"attrib\"][\"frameEnd\"]\n            instance.data.pop(\"hasExplicitFrames\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/extract_last_version_files.html#client.ayon_deadline.plugins.publish.global.extract_last_version_files.ExtractLastVersionFiles.process","title":"<code>process(instance)</code>","text":"<p>Process all the nodes in the instance</p> Source code in <code>client/ayon_deadline/plugins/publish/global/extract_last_version_files.py</code> <pre><code>def process(self, instance):\n    \"\"\"Process all the nodes in the instance\"\"\"\n    if not instance.data.get(\"reuseLastVersion\"):\n        return\n\n    frame_start = instance.data[\"frameStart\"]\n    frame_end = instance.data[\"frameEnd\"]\n\n    for repre in instance.data[\"representations\"]:\n        files = repre[\"files\"]\n\n        is_image_sequence = (\n            f\".{repre['ext']}\" in IMAGE_EXTENSIONS and\n            isinstance(files, list)\n        )\n        if not is_image_sequence:\n            self.log.debug(\n                f\"Representation '{repre['ext']}' is not image sequence\"\n            )\n            continue\n\n        collections = clique.assemble(\n            files,\n        )[0]\n        if len(collections) != 1:\n            raise KnownPublishError(\n                \"Multiple collections {} found.\".format(collections)\n            )\n\n        collection = collections[0]\n\n        used_version_entity, last_version_copied_files = (\n            fill_sequence_gaps_with_previous_version(\n                collection=collection,\n                staging_dir=repre[\"stagingDir\"],\n                instance=instance,\n                current_repre_name=repre[\"name\"],\n                start_frame=frame_start,\n                end_frame=frame_end,\n            )\n        )\n        if not last_version_copied_files:\n            raise KnownPublishError(\"Couldn't copy last version files.\")\n\n        added_file_names = [\n            os.path.basename(file_path)\n            for file_path in last_version_copied_files.values()\n        ]\n        repre[\"files\"].extend(added_file_names)\n\n        # reset representation/instance to original length\n        repre[\"frameStart\"] = used_version_entity[\"attrib\"][\"frameStart\"]\n        repre[\"frameEnd\"] = used_version_entity[\"attrib\"][\"frameEnd\"]\n        instance.data.pop(\"hasExplicitFrames\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/submit_publish_job.html","title":"submit_publish_job","text":"<p>Submit publishing job to farm.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/submit_publish_job.html#client.ayon_deadline.plugins.publish.global.submit_publish_job.ProcessSubmittedJobOnFarm","title":"<code>ProcessSubmittedJobOnFarm</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>AYONPyblishPluginMixin</code>, <code>ColormanagedPyblishPluginMixin</code></p> <p>Process Job submitted on farm.</p> <p>These jobs are dependent on a deadline job submission prior to this plug-in.</p> <p>It creates dependent job on farm publishing rendered image sequence.</p> <p>Options in instance.data:     - deadlineSubmissionJob (dict, Required): The returned .json       data from the job submission to deadline.</p> <pre><code>- outputDir (str, Required): The output directory where the metadata\n    file should be generated. It's assumed that this will also be\n    final folder containing the output files.\n\n- ext (str, Optional): The extension (including `.`) that is required\n    in the output filename to be picked up for image sequence\n    publishing.\n\n- expectedFiles (list or dict): explained below\n</code></pre> Source code in <code>client/ayon_deadline/plugins/publish/global/submit_publish_job.py</code> <pre><code>class ProcessSubmittedJobOnFarm(pyblish.api.InstancePlugin,\n                                publish.AYONPyblishPluginMixin,\n                                publish.ColormanagedPyblishPluginMixin):\n    \"\"\"Process Job submitted on farm.\n\n    These jobs are dependent on a deadline job\n    submission prior to this plug-in.\n\n    It creates dependent job on farm publishing rendered image sequence.\n\n    Options in instance.data:\n        - deadlineSubmissionJob (dict, Required): The returned .json\n          data from the job submission to deadline.\n\n        - outputDir (str, Required): The output directory where the metadata\n            file should be generated. It's assumed that this will also be\n            final folder containing the output files.\n\n        - ext (str, Optional): The extension (including `.`) that is required\n            in the output filename to be picked up for image sequence\n            publishing.\n\n        - expectedFiles (list or dict): explained below\n\n    \"\"\"\n\n    label = \"Submit Image Publishing job to Deadline\"\n    order = pyblish.api.IntegratorOrder + 0.2\n    icon = \"tractor\"\n\n    targets = [\"local\"]\n\n    families = [\"deadline.submit.publish.job\"]\n    settings_category = \"deadline\"\n\n    aov_filter = [\n        {\n            \"name\": \"maya\",\n            \"value\": [r\".*([Bb]eauty).*\"]\n        },\n        {\n            \"name\": \"blender\",\n            \"value\": [r\".*([Bb]eauty).*\"]\n        },\n        {\n            # for everything from AE\n            \"name\": \"aftereffects\",\n            \"value\": [r\".*\"]\n        },\n        {\n            \"name\": \"harmony\",\n            \"value\": [r\".*\"]\n        },\n        {\n            \"name\": \"celaction\",\n            \"value\": [r\".*\"]\n        },\n        {\n            \"name\": \"max\",\n            \"value\": [r\".*\"]\n        },\n    ]\n\n    # custom deadline attributes\n    deadline_department = \"\"\n    deadline_pool = \"\"\n    deadline_group = \"\"\n    deadline_priority = None\n\n    # regex for finding frame number in string\n    R_FRAME_NUMBER = re.compile(r'.+\\.(?P&lt;frame&gt;[0-9]+)\\..+')\n\n    # mapping of instance properties to be transferred to new instance\n    #     for every specified family\n    instance_transfer = {\n        \"slate\": [\"slateFrames\", \"slate\"],\n        \"review\": [\"lutPath\"],\n        \"render2d\": [\"bakingNukeScripts\", \"version\"],\n        \"renderlayer\": [\"convertToScanline\"]\n    }\n\n    # list of family names to transfer to new family if present\n    families_transfer = [\"render3d\", \"render2d\", \"slate\"]\n\n    # poor man exclusion\n    skip_integration_repre_list = []\n\n    add_rendered_dependencies = False\n\n\n    def _submit_deadline_post_job(\n        self, instance, render_job, instances, rootless_metadata_path\n    ):\n        \"\"\"Submit publish job to Deadline.\n\n        Returns:\n            (str): deadline_publish_job_id\n        \"\"\"\n        data = instance.data.copy()\n        product_name = data[\"productName\"]\n        job_name = \"Publish - {}\".format(product_name)\n\n        context = instance.context\n        anatomy = context.data[\"anatomy\"]\n\n        # instance.data.get(\"productName\") != instances[0][\"productName\"]\n        # 'Main' vs 'renderMain'\n        override_version = None\n        instance_version = instance.data.get(\"version\")  # take this if exists\n        if instance_version != 1:\n            override_version = instance_version\n\n        output_dir = self._get_publish_folder(\n            anatomy,\n            deepcopy(instance.data[\"anatomyData\"]),\n            instance.data.get(\"folderEntity\"),\n            instances[0][\"productName\"],\n            context,\n            instances[0][\"productType\"],\n            override_version\n        )\n\n        environment = get_instance_job_envs(instance)\n        environment.update(JobType.PUBLISH.get_job_env())\n\n        priority = (\n            self.deadline_priority\n            or instance.data.get(\"priority\", 50)\n        )\n\n        batch_name = self._get_batch_name(instance, render_job)\n        username = self._get_username(instance, render_job)\n        dependency_ids = self._get_dependency_ids(instance, render_job)\n\n        args = [\n            \"--headless\",\n            \"publish\",\n            rootless_metadata_path,\n            \"--targets\", \"deadline\",\n            \"--targets\", \"farm\",\n        ]\n        # TODO remove settings variant handling when not needed anymore\n        #   which should be when package.py defines 'core&gt;1.1.1' .\n        settings_variant = os.environ[\"AYON_DEFAULT_SETTINGS_VARIANT\"]\n        if settings_variant == \"staging\":\n            args.append(\"--use-staging\")\n        elif settings_variant != \"production\":\n            args.extend([\"--bundle\", settings_variant])\n\n        server_name = instance.data[\"deadline\"][\"serverName\"]\n        self.log.debug(\"Submitting Deadline publish job ...\")\n\n        deadline_addon: DeadlineAddon = (\n            context.data[\"ayonAddonsManager\"][\"deadline\"]\n        )\n\n        job_info = instance.data[\"deadline\"][\"job_info\"]\n        job_info = DeadlineJobInfo(\n            Name=job_name,\n            BatchName=batch_name,\n            Department=self.deadline_department,\n            Priority=priority,\n            InitialStatus=job_info.publish_job_state,\n            Group=self.deadline_group,\n            Pool=self.deadline_pool or None,\n            JobDependencies=dependency_ids,\n            UserName=username,\n            Comment=context.data.get(\"comment\"),\n        )\n        if output_dir:\n            job_info.OutputDirectory.append(output_dir)\n\n        job_info.EnvironmentKeyValue.update(environment)\n\n        if self.add_rendered_dependencies:\n            self._add_rendered_dependencies(anatomy, instances, job_info)\n\n        return deadline_addon.submit_ayon_plugin_job(\n            server_name,\n            args,\n            job_info\n        )[\"response\"][\"_id\"]\n\n    def _get_batch_name(self, instance, render_job):\n        batch_name = instance.data.get(\"jobBatchName\")\n        if not batch_name and render_job:\n            batch_name = render_job[\"Props\"][\"Batch\"]\n\n        if not batch_name:\n            batch_name = os.path.splitext(os.path.basename(\n                instance.context.data[\"currentFile\"]\n            ))[0]\n        return batch_name\n\n    def _get_username(self, instance, render_job):\n        username = None\n        if render_job:\n            username = render_job[\"Props\"][\"User\"]\n\n        if not username:\n            username = instance.context.data.get(\n                \"deadlineUser\", getpass.getuser()\n            )\n        return username\n\n    def _get_dependency_ids(self, instance, render_job):\n        # Collect dependent jobs\n        if instance.data.get(\"tileRendering\"):\n            self.log.info(\"Adding tile assembly jobs as dependencies...\")\n            return instance.data.get(\"assemblySubmissionJobs\")\n\n        if instance.data.get(\"bakingSubmissionJobs\"):\n            self.log.info(\n                \"Adding baking submission jobs as dependencies...\"\n            )\n            return instance.data[\"bakingSubmissionJobs\"]\n\n        if render_job and render_job.get(\"_id\"):\n            return [render_job[\"_id\"]]\n        return None\n\n    def process(self, instance):\n        # type: (pyblish.api.Instance) -&gt; None\n        \"\"\"Process plugin.\n\n        Detect type of render farm submission and create and post dependent\n        job in case of Deadline. It creates json file with metadata needed for\n        publishing in directory of render.\n\n        Args:\n            instance (pyblish.api.Instance): Instance data.\n\n        \"\"\"\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Skipping local instance.\")\n            return\n\n        anatomy = instance.context.data[\"anatomy\"]\n\n        instance_skeleton_data = create_skeleton_instance(\n            instance, families_transfer=self.families_transfer,\n            instance_transfer=self.instance_transfer)\n        \"\"\"\n        if content of `expectedFiles` list are dictionaries, we will handle\n        it as list of AOVs, creating instance for every one of them.\n\n        Example:\n        --------\n\n        expectedFiles = [\n            {\n                \"beauty\": [\n                    \"foo_v01.0001.exr\",\n                    \"foo_v01.0002.exr\"\n                ],\n\n                \"Z\": [\n                    \"boo_v01.0001.exr\",\n                    \"boo_v01.0002.exr\"\n                ]\n            }\n        ]\n\n        This will create instances for `beauty` and `Z` product\n        adding those files to their respective representations.\n\n        If we have only list of files, we collect all file sequences.\n        More then one doesn't probably make sense, but we'll handle it\n        like creating one instance with multiple representations.\n\n        Example:\n        --------\n\n        expectedFiles = [\n            \"foo_v01.0001.exr\",\n            \"foo_v01.0002.exr\",\n            \"xxx_v01.0001.exr\",\n            \"xxx_v01.0002.exr\"\n        ]\n\n        This will result in one instance with two representations:\n        `foo` and `xxx`\n        \"\"\"\n        do_not_add_review = False\n        if instance.data.get(\"review\") is False:\n            self.log.debug(\"Instance has review explicitly disabled.\")\n            do_not_add_review = True\n\n        aov_filter = {\n            item[\"name\"]: item[\"value\"]\n            for item in self.aov_filter\n        }\n        if isinstance(instance.data.get(\"expectedFiles\")[0], dict):\n            instances = create_instances_for_aov(\n                instance, instance_skeleton_data,\n                aov_filter,\n                self.skip_integration_repre_list,\n                do_not_add_review,\n                instance.data[\"deadline\"][\"job_info\"].Frames\n            )\n        else:\n            representations = prepare_representations(\n                instance_skeleton_data,\n                instance.data.get(\"expectedFiles\"),\n                anatomy,\n                aov_filter,\n                self.skip_integration_repre_list,\n                do_not_add_review,\n                instance.context,\n                self,\n                instance.data[\"deadline\"][\"job_info\"].Frames\n            )\n\n            if \"representations\" not in instance_skeleton_data.keys():\n                instance_skeleton_data[\"representations\"] = []\n\n            # add representation\n            instance_skeleton_data[\"representations\"] += representations\n            instances = [instance_skeleton_data]\n\n        # attach instances to product\n        if instance.data.get(\"attachTo\"):\n            instances = attach_instances_to_product(\n                instance.data.get(\"attachTo\"), instances\n            )\n\n        r''' SUBMiT PUBLiSH JOB 2 D34DLiN3\n          ____\n        '     '            .---.  .---. .--. .---. .--..--..--..--. .---.\n        |     |   --= \\   |  .  \\/   _|/    \\|  .  \\  ||  ||   \\  |/   _|\n        | JOB |   --= /   |  |  ||  __|  ..  |  |  |  |;_ ||  \\   ||  __|\n        |     |           |____./ \\.__|._||_.|___./|_____|||__|\\__|\\.___|\n        ._____.\n\n        '''\n\n        render_job = instance.data.pop(\"deadlineSubmissionJob\", None)\n        if not render_job and instance.data.get(\"tileRendering\") is False:\n            raise AssertionError(\n                \"Cannot continue without valid Deadline submission.\"\n            )\n\n        # Transfer the environment from the original job to this dependent\n        # job so they use the same environment\n        metadata_path, rootless_metadata_path = create_metadata_path(\n            instance, anatomy\n        )\n\n        deadline_publish_job_id = self._submit_deadline_post_job(\n            instance, render_job, instances, rootless_metadata_path\n        )\n\n        # Inject deadline url to instances to query DL for job id for overrides\n        for inst in instances:\n            inst[\"deadline\"] = deepcopy(instance.data[\"deadline\"])\n            inst[\"deadline\"].pop(\"job_info\")\n\n        # publish job file\n        publish_job = {\n            \"folderPath\": instance_skeleton_data[\"folderPath\"],\n            \"frameStart\": instance_skeleton_data[\"frameStart\"],\n            \"frameEnd\": instance_skeleton_data[\"frameEnd\"],\n            \"fps\": instance_skeleton_data[\"fps\"],\n            \"source\": instance_skeleton_data[\"source\"],\n            \"user\": instance.context.data[\"user\"],\n            \"intent\": instance.context.data.get(\"intent\"),\n            \"comment\": instance.context.data.get(\"comment\"),\n            \"job\": render_job or {},\n            \"instances\": instances\n        }\n\n        # Note that a version of 0 is a valid version number,\n        # so we explicitly check for `None` value\n        # instance override version\n        collected_version = instance.data.get(\"version\")\n        if collected_version is None:\n            # workfile version\n            collected_version = instance.context.data.get(\"version\")\n        if collected_version is not None:\n            publish_job[\"version\"] = collected_version\n\n        if deadline_publish_job_id:\n            publish_job[\"deadline_publish_job_id\"] = deadline_publish_job_id\n\n        # add audio to metadata file if available\n        audio_file = instance.context.data.get(\"audioFile\")\n        if audio_file and os.path.isfile(audio_file):\n            publish_job.update({\"audio\": audio_file})\n\n        self.log.debug(f\"Writing metadata json to '{metadata_path}'\")\n        with open(metadata_path, \"w\") as f:\n            json.dump(publish_job, f, indent=4, sort_keys=True)\n\n    def _get_publish_folder(\n        self,\n        anatomy,\n        template_data,\n        folder_entity,\n        product_name,\n        context,\n        product_type,\n        version=None\n    ):\n        \"\"\"\n            Extracted logic to pre-calculate real publish folder, which is\n            calculated in IntegrateNew inside of Deadline process.\n            This should match logic in:\n                'collect_anatomy_instance_data' - to\n                    get correct anatomy, family, version for product name and\n                'collect_resources_path'\n                    get publish_path\n\n        Args:\n            anatomy (ayon_core.pipeline.anatomy.Anatomy):\n            template_data (dict): pre-calculated collected data for process\n            folder_entity (dict[str, Any]): Folder entity.\n            product_name (string): Product name (actually group name\n                of product)\n            product_type (string): for current deadline process it's always\n                'render'\n                TODO - for generic use family needs to be dynamically\n                    calculated like IntegrateNew does\n            version (int): override version from instance if exists\n\n        Returns:\n            Optional[str]: publish folder where rendered and published files\n                will be stored based on 'publish' template\n\n        \"\"\"\n        project_name = context.data[\"projectName\"]\n        host_name = context.data[\"hostName\"]\n        if not version:\n            version_entity = None\n            if folder_entity:\n                version_entity = ayon_api.get_last_version_by_product_name(\n                    project_name,\n                    product_name,\n                    folder_entity[\"id\"]\n                )\n\n            if version_entity:\n                version = int(version_entity[\"version\"]) + 1\n            else:\n                version = get_versioning_start(\n                    project_name,\n                    host_name,\n                    task_name=template_data[\"task\"][\"name\"],\n                    task_type=template_data[\"task\"][\"type\"],\n                    product_type=\"render\",\n                    product_name=product_name,\n                    project_settings=context.data[\"project_settings\"]\n                )\n\n        host_name = context.data[\"hostName\"]\n        task_info = template_data.get(\"task\") or {}\n\n        template_name = publish.get_publish_template_name(\n            project_name,\n            host_name,\n            product_type,\n            task_info.get(\"name\"),\n            task_info.get(\"type\"),\n        )\n\n        template_data[\"version\"] = version\n        template_data[\"subset\"] = product_name\n        template_data[\"family\"] = product_type\n        template_data[\"product\"] = {\n            \"name\": product_name,\n            \"type\": product_type,\n        }\n\n        render_dir_template = anatomy.get_template_item(\n            \"publish\", template_name, \"directory\"\n        )\n        try:\n            return (\n                render_dir_template\n                .format_strict(template_data)\n                .replace(\"\\\\\", \"/\")\n            )\n\n        except TemplateUnsolved:\n            self.log.error(\n                \"Publish directory template is unsolved for: \"\n                f\"{template_name} in anatomy. Output directory won't be set.\"\n            )\n\n    def _add_rendered_dependencies(\n        self,\n        anatomy: Anatomy,\n        instances: List[dict[str, Any]],\n        job_info: DeadlineJobInfo,\n    ) -&gt; None:\n        \"\"\"Adds all expected rendered files as Job dependencies.\n\n        This should help when DL file system is still synchronizing rendered\n        files, but publish job starts prematurely.\n        \"\"\"\n        for instance in instances:\n            for representation in instance[\"representations\"]:\n                if isinstance(representation[\"files\"], str):\n                    files = [representation[\"files\"]]\n                else:\n                    files = representation[\"files\"]\n                for file_name in files:\n                    full_path = os.path.join(\n                        representation[\"stagingDir\"], file_name\n                    )\n                    full_path = anatomy.fill_root(full_path)\n                    job_info.AssetDependency += full_path\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/submit_publish_job.html#client.ayon_deadline.plugins.publish.global.submit_publish_job.ProcessSubmittedJobOnFarm.process","title":"<code>process(instance)</code>","text":"<p>Process plugin.</p> <p>Detect type of render farm submission and create and post dependent job in case of Deadline. It creates json file with metadata needed for publishing in directory of render.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>Instance</code> <p>Instance data.</p> required Source code in <code>client/ayon_deadline/plugins/publish/global/submit_publish_job.py</code> <pre><code>def process(self, instance):\n    # type: (pyblish.api.Instance) -&gt; None\n    \"\"\"Process plugin.\n\n    Detect type of render farm submission and create and post dependent\n    job in case of Deadline. It creates json file with metadata needed for\n    publishing in directory of render.\n\n    Args:\n        instance (pyblish.api.Instance): Instance data.\n\n    \"\"\"\n    if not instance.data.get(\"farm\"):\n        self.log.debug(\"Skipping local instance.\")\n        return\n\n    anatomy = instance.context.data[\"anatomy\"]\n\n    instance_skeleton_data = create_skeleton_instance(\n        instance, families_transfer=self.families_transfer,\n        instance_transfer=self.instance_transfer)\n    \"\"\"\n    if content of `expectedFiles` list are dictionaries, we will handle\n    it as list of AOVs, creating instance for every one of them.\n\n    Example:\n    --------\n\n    expectedFiles = [\n        {\n            \"beauty\": [\n                \"foo_v01.0001.exr\",\n                \"foo_v01.0002.exr\"\n            ],\n\n            \"Z\": [\n                \"boo_v01.0001.exr\",\n                \"boo_v01.0002.exr\"\n            ]\n        }\n    ]\n\n    This will create instances for `beauty` and `Z` product\n    adding those files to their respective representations.\n\n    If we have only list of files, we collect all file sequences.\n    More then one doesn't probably make sense, but we'll handle it\n    like creating one instance with multiple representations.\n\n    Example:\n    --------\n\n    expectedFiles = [\n        \"foo_v01.0001.exr\",\n        \"foo_v01.0002.exr\",\n        \"xxx_v01.0001.exr\",\n        \"xxx_v01.0002.exr\"\n    ]\n\n    This will result in one instance with two representations:\n    `foo` and `xxx`\n    \"\"\"\n    do_not_add_review = False\n    if instance.data.get(\"review\") is False:\n        self.log.debug(\"Instance has review explicitly disabled.\")\n        do_not_add_review = True\n\n    aov_filter = {\n        item[\"name\"]: item[\"value\"]\n        for item in self.aov_filter\n    }\n    if isinstance(instance.data.get(\"expectedFiles\")[0], dict):\n        instances = create_instances_for_aov(\n            instance, instance_skeleton_data,\n            aov_filter,\n            self.skip_integration_repre_list,\n            do_not_add_review,\n            instance.data[\"deadline\"][\"job_info\"].Frames\n        )\n    else:\n        representations = prepare_representations(\n            instance_skeleton_data,\n            instance.data.get(\"expectedFiles\"),\n            anatomy,\n            aov_filter,\n            self.skip_integration_repre_list,\n            do_not_add_review,\n            instance.context,\n            self,\n            instance.data[\"deadline\"][\"job_info\"].Frames\n        )\n\n        if \"representations\" not in instance_skeleton_data.keys():\n            instance_skeleton_data[\"representations\"] = []\n\n        # add representation\n        instance_skeleton_data[\"representations\"] += representations\n        instances = [instance_skeleton_data]\n\n    # attach instances to product\n    if instance.data.get(\"attachTo\"):\n        instances = attach_instances_to_product(\n            instance.data.get(\"attachTo\"), instances\n        )\n\n    r''' SUBMiT PUBLiSH JOB 2 D34DLiN3\n      ____\n    '     '            .---.  .---. .--. .---. .--..--..--..--. .---.\n    |     |   --= \\   |  .  \\/   _|/    \\|  .  \\  ||  ||   \\  |/   _|\n    | JOB |   --= /   |  |  ||  __|  ..  |  |  |  |;_ ||  \\   ||  __|\n    |     |           |____./ \\.__|._||_.|___./|_____|||__|\\__|\\.___|\n    ._____.\n\n    '''\n\n    render_job = instance.data.pop(\"deadlineSubmissionJob\", None)\n    if not render_job and instance.data.get(\"tileRendering\") is False:\n        raise AssertionError(\n            \"Cannot continue without valid Deadline submission.\"\n        )\n\n    # Transfer the environment from the original job to this dependent\n    # job so they use the same environment\n    metadata_path, rootless_metadata_path = create_metadata_path(\n        instance, anatomy\n    )\n\n    deadline_publish_job_id = self._submit_deadline_post_job(\n        instance, render_job, instances, rootless_metadata_path\n    )\n\n    # Inject deadline url to instances to query DL for job id for overrides\n    for inst in instances:\n        inst[\"deadline\"] = deepcopy(instance.data[\"deadline\"])\n        inst[\"deadline\"].pop(\"job_info\")\n\n    # publish job file\n    publish_job = {\n        \"folderPath\": instance_skeleton_data[\"folderPath\"],\n        \"frameStart\": instance_skeleton_data[\"frameStart\"],\n        \"frameEnd\": instance_skeleton_data[\"frameEnd\"],\n        \"fps\": instance_skeleton_data[\"fps\"],\n        \"source\": instance_skeleton_data[\"source\"],\n        \"user\": instance.context.data[\"user\"],\n        \"intent\": instance.context.data.get(\"intent\"),\n        \"comment\": instance.context.data.get(\"comment\"),\n        \"job\": render_job or {},\n        \"instances\": instances\n    }\n\n    # Note that a version of 0 is a valid version number,\n    # so we explicitly check for `None` value\n    # instance override version\n    collected_version = instance.data.get(\"version\")\n    if collected_version is None:\n        # workfile version\n        collected_version = instance.context.data.get(\"version\")\n    if collected_version is not None:\n        publish_job[\"version\"] = collected_version\n\n    if deadline_publish_job_id:\n        publish_job[\"deadline_publish_job_id\"] = deadline_publish_job_id\n\n    # add audio to metadata file if available\n    audio_file = instance.context.data.get(\"audioFile\")\n    if audio_file and os.path.isfile(audio_file):\n        publish_job.update({\"audio\": audio_file})\n\n    self.log.debug(f\"Writing metadata json to '{metadata_path}'\")\n    with open(metadata_path, \"w\") as f:\n        json.dump(publish_job, f, indent=4, sort_keys=True)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/submit_publish_job.html#client.ayon_deadline.plugins.publish.global.submit_publish_job.get_resource_files","title":"<code>get_resource_files(resources, frame_range=None)</code>","text":"<p>Get resource files at given path.</p> <p>If <code>frame_range</code> is specified those outside will be removed.</p> <p>Parameters:</p> Name Type Description Default <code>resources</code> <code>list</code> <p>List of resources</p> required <code>frame_range</code> <code>list</code> <p>Frame range to apply override</p> <code>None</code> <p>Returns:</p> Type Description <p>list of str: list of collected resources</p> Source code in <code>client/ayon_deadline/plugins/publish/global/submit_publish_job.py</code> <pre><code>def get_resource_files(resources, frame_range=None):\n    \"\"\"Get resource files at given path.\n\n    If `frame_range` is specified those outside will be removed.\n\n    Arguments:\n        resources (list): List of resources\n        frame_range (list): Frame range to apply override\n\n    Returns:\n        list of str: list of collected resources\n\n    \"\"\"\n    res_collections, _ = clique.assemble(resources)\n    assert len(res_collections) == 1, \"Multiple collections found\"\n    res_collection = res_collections[0]\n\n    # Remove any frames\n    if frame_range is not None:\n        for frame in frame_range:\n            if frame not in res_collection.indexes:\n                continue\n            res_collection.indexes.remove(frame)\n\n    return list(res_collection)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_deadline_connection.html","title":"validate_deadline_connection","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_deadline_connection.html#client.ayon_deadline.plugins.publish.global.validate_deadline_connection.ValidateDeadlineConnection","title":"<code>ValidateDeadlineConnection</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Validate Deadline Web Service is running</p> Source code in <code>client/ayon_deadline/plugins/publish/global/validate_deadline_connection.py</code> <pre><code>class ValidateDeadlineConnection(pyblish.api.InstancePlugin):\n    \"\"\"Validate Deadline Web Service is running\"\"\"\n\n    label = \"Validate Deadline Web Service\"\n    order = pyblish.api.ValidatorOrder\n    families = FARM_FAMILIES\n    targets = [\"local\"]\n\n    # cache\n    responses = {}\n\n    def process(self, instance):\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Should not be processed on farm, skipping.\")\n            return\n\n        deadline_url = instance.data[\"deadline\"][\"url\"]\n        assert deadline_url, \"Requires Deadline Webservice URL\"\n\n        kwargs = {\n            \"verify\": instance.data[\"deadline\"][\"verify\"]\n        }\n\n        if instance.data[\"deadline\"][\"require_authentication\"]:\n            auth = instance.data[\"deadline\"][\"auth\"]\n            kwargs[\"auth\"] = auth\n\n            if not auth[0]:\n                raise PublishXmlValidationError(\n                    self,\n                    \"Deadline requires authentication. \"\n                    \"At least username is required to be set in \"\n                    \"Site Settings.\")\n\n        if deadline_url not in self.responses:\n            self.responses[deadline_url] = requests_get(deadline_url, **kwargs)\n\n        response = self.responses[deadline_url]\n        if response.status_code == 401:\n            raise PublishXmlValidationError(\n                self,\n                \"Deadline requires authentication. \"\n                \"Provided credentials are not working. \"\n                \"Please change them in Site Settings\")\n        assert response.ok, \"Response must be ok\"\n        assert response.text.startswith(\"Deadline Web Service \"), (\n            \"Web service did not respond with 'Deadline Web Service'\"\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_deadline_jobinfo.html","title":"validate_deadline_jobinfo","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_deadline_jobinfo.html#client.ayon_deadline.plugins.publish.global.validate_deadline_jobinfo.ValidateDeadlineJobInfo","title":"<code>ValidateDeadlineJobInfo</code>","text":"<p>               Bases: <code>OptionalPyblishPluginMixin</code>, <code>InstancePlugin</code></p> <p>Validate collected values for JobInfo section in Deadline submission</p> Source code in <code>client/ayon_deadline/plugins/publish/global/validate_deadline_jobinfo.py</code> <pre><code>class ValidateDeadlineJobInfo(\n    OptionalPyblishPluginMixin,\n    pyblish.api.InstancePlugin\n):\n    \"\"\"Validate collected values for JobInfo section in Deadline submission\n\n    \"\"\"\n\n    label = \"Validate Deadline JobInfo\"\n    order = pyblish.api.ValidatorOrder\n    families = FARM_FAMILIES\n    optional = True\n    targets = [\"local\"]\n\n    # cache\n    pools_by_url = {}\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Skipping local instance.\")\n            return\n\n        priority = instance.data[\"deadline\"][\"job_info\"].Priority\n        if priority &lt; 0 or priority &gt; 100:\n            raise PublishValidationError(\n                f\"Priority:'{priority}' must be between 0-100\")\n\n        custom_frames = instance.data[\"deadline\"][\"job_info\"].Frames\n        if not custom_frames:\n            return\n\n        frame_start = (\n            instance.data.get(\"frameStart\")\n            or instance.context.data.get(\"frameStart\")\n        )\n        frame_end = (\n            instance.data.get(\"frameEnd\")\n            or instance.context.data.get(\"frameEnd\")\n        )\n        if not frame_start or not frame_end:\n            self.log.info(\"Unable to get frame range, skip validation.\")\n            return\n\n        frames_to_render = convert_frames_str_to_list(custom_frames)\n\n        if (\n            min(frames_to_render) &lt; frame_start\n            or max(frames_to_render) &gt; frame_end\n        ):\n            raise PublishValidationError(\n                f\"Custom frames '{custom_frames}' are outside of \"\n                f\"expected frame range '{frame_start}'-'{frame_end}'\"\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_deadline_pools.html","title":"validate_deadline_pools","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_deadline_pools.html#client.ayon_deadline.plugins.publish.global.validate_deadline_pools.ValidateDeadlinePools","title":"<code>ValidateDeadlinePools</code>","text":"<p>               Bases: <code>OptionalPyblishPluginMixin</code>, <code>InstancePlugin</code></p> <p>Validate primaryPool and secondaryPool on instance.</p> <p>Values are on instance based on value insertion when Creating instance or by Settings in CollectDeadlinePools.</p> Source code in <code>client/ayon_deadline/plugins/publish/global/validate_deadline_pools.py</code> <pre><code>class ValidateDeadlinePools(OptionalPyblishPluginMixin,\n                            pyblish.api.InstancePlugin):\n    \"\"\"Validate primaryPool and secondaryPool on instance.\n\n    Values are on instance based on value insertion when Creating instance or\n    by Settings in CollectDeadlinePools.\n    \"\"\"\n\n    label = \"Validate Deadline Pools\"\n    order = pyblish.api.ValidatorOrder\n    families = FARM_FAMILIES\n    optional = True\n    targets = [\"local\"]\n\n    # cache\n    pools_by_url = {}\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Skipping local instance.\")\n            return\n\n        deadline_url = instance.data[\"deadline\"][\"url\"]\n        addons_manager = instance.context.data[\"ayonAddonsManager\"]\n        deadline_addon = addons_manager[\"deadline\"]\n        pools = self.get_pools(\n            deadline_addon,\n            deadline_url,\n            instance.data[\"deadline\"].get(\"auth\"),\n            instance.data[\"deadline\"][\"verify\"]\n        )\n\n        invalid_pools = {}\n        job_info = instance.data[\"deadline\"][\"job_info\"]\n        primary_pool = job_info.Pool\n        if primary_pool and primary_pool not in pools:\n            invalid_pools[\"primary\"] = primary_pool\n\n        secondary_pool = job_info.SecondaryPool\n        if secondary_pool and secondary_pool not in pools:\n            invalid_pools[\"secondary\"] = secondary_pool\n\n        if invalid_pools:\n            message = \"\\n\".join(\n                \"{} pool '{}' not available on Deadline\".format(key.title(),\n                                                                pool)\n                for key, pool in invalid_pools.items()\n            )\n            raise PublishXmlValidationError(\n                plugin=self,\n                message=message,\n                formatting_data={\"pools_str\": \", \".join(pools)}\n            )\n\n    def get_pools(self, deadline_addon, deadline_url, auth, verify):\n        if deadline_url not in self.pools_by_url:\n            self.log.debug(\n                \"Querying available pools for Deadline url: {}\".format(\n                    deadline_url)\n            )\n            pools = get_deadline_pools(\n                deadline_url, auth=auth, log=self.log, verify=verify\n            )\n            # some DL return \"none\" as a pool name\n            if \"none\" not in pools:\n                pools.append(\"none\")\n            self.log.info(\"Available pools: {}\".format(pools))\n            self.pools_by_url[deadline_url] = pools\n\n        return self.pools_by_url[deadline_url]\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_expected_and_rendered_files.html","title":"validate_expected_and_rendered_files","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_expected_and_rendered_files.html#client.ayon_deadline.plugins.publish.global.validate_expected_and_rendered_files.ValidateExpectedFiles","title":"<code>ValidateExpectedFiles</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Compare rendered and expected files</p> Source code in <code>client/ayon_deadline/plugins/publish/global/validate_expected_and_rendered_files.py</code> <pre><code>class ValidateExpectedFiles(pyblish.api.InstancePlugin):\n    \"\"\"Compare rendered and expected files\"\"\"\n\n    label = \"Validate rendered files from Deadline\"\n    order = pyblish.api.ValidatorOrder\n    families = [\"render\"]\n    targets = [\"deadline\"]\n    settings_category = \"deadline\"\n\n    # check if actual frame range on render job wasn't different\n    # case when artists wants to render only subset of frames\n    allow_user_override = True\n\n    def process(self, instance):\n        \"\"\"Process all the nodes in the instance\"\"\"\n        if instance.data.get(\"hasExplicitFrames\"):\n            self.log.debug(\"Explicit frames rendered, skipping check\")\n            return\n\n        # get dependency jobs ids for retrieving frame list\n        dependent_job_ids = self._get_dependent_job_ids(instance)\n\n        if not dependent_job_ids:\n            self.log.warning(\"No dependent jobs found for instance: {}\"\n                             \"\".format(instance))\n            return\n\n        # get list of frames from dependent jobs\n        frame_list = self._get_dependent_jobs_frames(\n            instance, dependent_job_ids)\n\n        for repre in instance.data[\"representations\"]:\n            expected_files = self._get_expected_files(repre)\n\n            staging_dir = repre[\"stagingDir\"]\n            self.log.debug(f\"Validating files in directory: {staging_dir}\")\n            existing_files = self._get_existing_files(staging_dir)\n\n            is_image = f'.{repre[\"ext\"]}' in IMAGE_EXTENSIONS\n            if self.allow_user_override and is_image:\n                expected_files = self._recalculate_expected_files(\n                    expected_files, frame_list, repre)\n\n            # We don't use set.difference because we do allow other existing\n            # files to be in the folder that we might not want to use.\n            missing = expected_files - existing_files\n            if missing:\n                raise RuntimeError(\n                    \"Missing expected files: {}\\n\"\n                    \"Expected files: {}\\n\"\n                    \"Existing files: {}\".format(\n                        sorted(missing),\n                        sorted(expected_files),\n                        sorted(existing_files)\n                    )\n                )\n\n    def _recalculate_expected_files(self, expected_files, frame_list, repre):\n        # We always check for user override because the user might have\n        # also overridden the Job frame list to be longer than the\n        # originally submitted frame range\n        # todo: We should first check if Job frame range was overridden\n        #       at all so we don't unnecessarily override anything\n        collection_or_filename = self._get_collection(expected_files)\n        job_expected_files = self._get_job_expected_files(\n            collection_or_filename, frame_list)\n\n        job_files_diff = job_expected_files.difference(expected_files)\n        if job_files_diff:\n            self.log.debug(\n                \"Detected difference in expected output files from \"\n                \"Deadline job. Assuming an updated frame list by the \"\n                \"user. Difference: {}\".format(sorted(job_files_diff))\n            )\n\n            # Update the representation expected files\n            self.log.info(\"Update range from actual job range \"\n                          \"to frame list: {}\".format(frame_list))\n            # single item files must be string not list\n            repre[\"files\"] = (sorted(job_expected_files)\n                              if len(job_expected_files) &gt; 1 else\n                              list(job_expected_files)[0])\n\n            # Update the expected files\n            expected_files = job_expected_files\n        return expected_files\n\n    def _get_dependent_job_ids(self, instance):\n        \"\"\"Returns list of dependent job ids from instance metadata.json\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n\n        Returns:\n            (list): list of dependent job ids\n\n        \"\"\"\n        dependent_job_ids = []\n\n        # job_id collected from metadata.json\n        original_job_id = instance.data[\"render_job_id\"]\n\n        dependent_job_ids_env = os.environ.get(\"RENDER_JOB_IDS\")\n        if dependent_job_ids_env:\n            dependent_job_ids = dependent_job_ids_env.split(',')\n        elif original_job_id:\n            dependent_job_ids = [original_job_id]\n\n        return dependent_job_ids\n\n    def _get_dependent_jobs_frames(self, instance, dependent_job_ids):\n        \"\"\"Returns list of frame ranges from all render job.\n\n        Render job might be re-submitted so job_id in metadata.json could be\n        invalid. GlobalJobPreload injects current job id to RENDER_JOB_IDS.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n            dependent_job_ids (list): list of dependent job ids\n        Returns:\n            (list)\n        \"\"\"\n        all_frame_lists = []\n\n        for job_id in dependent_job_ids:\n            job_info = self._get_job_info(instance, job_id)\n            frame_list = job_info[\"Props\"].get(\"Frames\")\n            if frame_list:\n                all_frame_lists.extend(frame_list.split(','))\n\n        return all_frame_lists\n\n    def _get_job_expected_files(self,\n                                collection_or_filename,\n                                frame_list):\n        \"\"\"Calculates list of names of expected rendered files.\n\n        Might be different from expected files from submission if user\n        explicitly and manually changed the frame list on the Deadline job.\n\n        Returns:\n            set: Set of expected file names in the staging directory.\n\n        \"\"\"\n        # no frames in file name at all, eg 'renderCompositingMain.withLut.mov'\n        # so it is a single file\n        if isinstance(collection_or_filename, str):\n            return {collection_or_filename}\n\n        # Define all frames from the frame list\n        all_frames = set()\n        for frames in frame_list:\n            if '-' not in frames:  # single frame\n                frames = \"{}-{}\".format(frames, frames)\n\n            start, end = frames.split('-')\n            all_frames.update(iter(range(int(start), int(end) + 1)))\n\n        # Return all filename for the collection with the new frames\n        collection: clique.Collection = collection_or_filename\n        collection.indexes.clear()\n        collection.indexes.update(all_frames)\n        return set(collection)  # return list of filenames\n\n    def _get_collection(self, files) -&gt; \"Iterable[str]\":\n        \"\"\"Returns sequence collection or a single filepath.\n\n        Arguments:\n            files (Iterable[str]): Filenames to retrieve the collection from.\n                If not a sequence detected it will return the single file path.\n\n        Returns:\n            clique.Collection | str: Sequence collection or single file path\n        \"\"\"\n        # todo: we may need this pattern to stay in sync with the\n        #  implementation in `ayon_core.lib.collect_frames`\n        # clique.PATTERNS[\"frames\"] supports only `.1001.exr` not `_1001.exr`\n        # so we use a customized pattern.\n        pattern = \"[_.](?P&lt;index&gt;(?P&lt;padding&gt;0*)\\\\d+)\\\\.\\\\D+\\\\d?$\"\n        patterns = [pattern]\n        collections, remainder = clique.assemble(\n            files, minimum_items=1, patterns=patterns)\n        if collections:\n            return collections[0]\n        else:\n            # No sequence detected, we assume single frame\n            return remainder[0]\n\n    def _get_job_info(self, instance, job_id):\n        \"\"\"Calls DL for actual job info for 'job_id'\n\n        Might be different than job info saved in metadata.json if user\n        manually changes job pre/during rendering.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n            job_id (str): Deadline job id\n\n        Returns:\n            (dict): Job info from Deadline\n\n        \"\"\"\n        server_name = instance.data[\"deadline\"][\"serverName\"]\n        if not server_name:\n            raise PublishValidationError(\n                \"Deadline server name is not filled.\"\n            )\n\n        addons_manager = instance.context.data[\"ayonAddonsManager\"]\n        deadline_addon = addons_manager[\"deadline\"]\n        return deadline_addon.get_job_info(server_name, job_id)\n\n    def _get_existing_files(self, staging_dir):\n        \"\"\"Returns set of existing file names from 'staging_dir'\"\"\"\n        existing_files = set()\n        for file_name in os.listdir(staging_dir):\n            existing_files.add(file_name)\n        return existing_files\n\n    def _get_expected_files(self, repre):\n        \"\"\"Returns set of file names in representation['files']\n\n        The representations are collected from `CollectRenderedFiles` using\n        the metadata.json file submitted along with the render job.\n\n        Args:\n            repre (dict): The representation containing 'files'\n\n        Returns:\n            set: Set of expected file_names in the staging directory.\n\n        \"\"\"\n        expected_files = set()\n\n        files = repre[\"files\"]\n        if not isinstance(files, list):\n            files = [files]\n\n        for file_name in files:\n            expected_files.add(file_name)\n        return expected_files\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/global/validate_expected_and_rendered_files.html#client.ayon_deadline.plugins.publish.global.validate_expected_and_rendered_files.ValidateExpectedFiles.process","title":"<code>process(instance)</code>","text":"<p>Process all the nodes in the instance</p> Source code in <code>client/ayon_deadline/plugins/publish/global/validate_expected_and_rendered_files.py</code> <pre><code>def process(self, instance):\n    \"\"\"Process all the nodes in the instance\"\"\"\n    if instance.data.get(\"hasExplicitFrames\"):\n        self.log.debug(\"Explicit frames rendered, skipping check\")\n        return\n\n    # get dependency jobs ids for retrieving frame list\n    dependent_job_ids = self._get_dependent_job_ids(instance)\n\n    if not dependent_job_ids:\n        self.log.warning(\"No dependent jobs found for instance: {}\"\n                         \"\".format(instance))\n        return\n\n    # get list of frames from dependent jobs\n    frame_list = self._get_dependent_jobs_frames(\n        instance, dependent_job_ids)\n\n    for repre in instance.data[\"representations\"]:\n        expected_files = self._get_expected_files(repre)\n\n        staging_dir = repre[\"stagingDir\"]\n        self.log.debug(f\"Validating files in directory: {staging_dir}\")\n        existing_files = self._get_existing_files(staging_dir)\n\n        is_image = f'.{repre[\"ext\"]}' in IMAGE_EXTENSIONS\n        if self.allow_user_override and is_image:\n            expected_files = self._recalculate_expected_files(\n                expected_files, frame_list, repre)\n\n        # We don't use set.difference because we do allow other existing\n        # files to be in the folder that we might not want to use.\n        missing = expected_files - existing_files\n        if missing:\n            raise RuntimeError(\n                \"Missing expected files: {}\\n\"\n                \"Expected files: {}\\n\"\n                \"Existing files: {}\".format(\n                    sorted(missing),\n                    sorted(expected_files),\n                    sorted(existing_files)\n                )\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/index.html","title":"harmony","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html","title":"submit_harmony_deadline","text":"<p>Submitting render job to Deadline.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.HarmonySubmitDeadline","title":"<code>HarmonySubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code></p> <p>Submit render write of Harmony scene to Deadline.</p> <p>Renders are submitted to a Deadline Web Service as supplied via the environment variable <code>DEADLINE_REST_URL</code>.</p> <p>Harmony workfile is <code>.zip</code> file that needs to be unzipped for Deadline first (DL expects unzipped folder). In case of use of published workfile, <code>.zip</code> file is copied to <code>work/../renders</code> and unzipped there.</p> Note <p>If Deadline configuration is not detected, this plugin will be disabled.</p> <p>Attributes:</p> Name Type Description <code>use_published</code> <code>bool</code> <p>Use published scene to render instead of the one in work area.</p> Source code in <code>client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.py</code> <pre><code>class HarmonySubmitDeadline(\n    abstract_submit_deadline.AbstractSubmitDeadline\n):\n    \"\"\"Submit render write of Harmony scene to Deadline.\n\n    Renders are submitted to a Deadline Web Service as\n    supplied via the environment variable ``DEADLINE_REST_URL``.\n\n    Harmony workfile is `.zip` file that needs to be unzipped for Deadline\n    first (DL expects unzipped folder). In case of use of published workfile,\n    `.zip` file is copied to `work/../renders` and unzipped there.\n\n    Note:\n        If Deadline configuration is not detected, this plugin will\n        be disabled.\n\n    Attributes:\n        use_published (bool): Use published scene to render instead of the\n            one in work area.\n\n    \"\"\"\n\n    label = \"Submit to Deadline\"\n    order = pyblish.api.IntegratorOrder + 0.1\n    hosts = [\"harmony\"]\n    families = [\"render.farm\"]\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    def get_job_info(self, job_info=None):\n        job_info.Plugin = \"HarmonyAYON\"\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            job_info.Frames = \"{}-{}\".format(\n                self._instance.data[\"frameStartHandle\"],\n                self._instance.data[\"frameEndHandle\"]\n            )\n\n        return job_info\n\n    def _unzip_scene_file(self, published_scene: Path) -&gt; Path:\n        \"\"\"Unzip scene zip file to its directory.\n\n        Unzip scene file (if it is zip file) to work area if dir if available,\n        if not to its current directory and\n        return path to xstage file there. Xstage file is determined by its\n        name.\n\n        Args:\n            published_scene (Path): path to zip file.\n\n        Returns:\n            Path: The path to unzipped xstage.\n        \"\"\"\n        # if not zip, bail out.\n        if \"zip\" not in published_scene.suffix or not is_zipfile(\n            published_scene.as_posix()\n        ):\n            self.log.error(\"Published scene is not in zip.\")\n            self.log.error(published_scene)\n            raise AssertionError(\"invalid scene format\")\n\n        # TODO eventually replace with registered_host().work_root or similar\n        workdir = os.environ.get(\"AYON_WORKDIR\")\n        if workdir and os.path.exists(workdir):\n            renders_path = os.path.join(workdir, \"renders\", \"harmony\")\n            os.makedirs(renders_path, exist_ok=True)\n\n            self.log.info(f\"Copying '{published_scene}' -&gt; '{renders_path}'\")\n            shutil.copy(published_scene.as_posix(), renders_path)\n            published_scene = Path(\n                os.path.join(renders_path), published_scene.name)\n            (self._instance.context.data[\"cleanupFullPaths\"].\n             append(published_scene))\n\n        xstage_path = (\n            published_scene.parent\n            / published_scene.stem\n            / f\"{published_scene.stem}.xstage\"\n        )\n        unzip_dir = (published_scene.parent / published_scene.stem)\n        with _ZipFile(published_scene, \"r\") as zip_ref:\n            # UNC path (//?/) added to minimalize risk with extracting\n            # to large file paths\n            zip_ref.extractall(\"//?/\" + str(unzip_dir.as_posix()))\n\n        # find any xstage files in directory, prefer the one with the same name\n        # as directory (plus extension)\n        xstage_files = []\n        for scene in unzip_dir.iterdir():\n            if scene.suffix == \".xstage\":\n                xstage_files.append(scene)\n\n        # there must be at least one (but maybe not more?) xstage file\n        if not xstage_files:\n            self.log.error(\"No xstage files found in zip\")\n            raise AssertionError(\"Invalid scene archive\")\n\n        ideal_scene = False\n        # find the one with the same name as zip. In case there can be more\n        # then one xtage file.\n        for scene in xstage_files:\n            # if /foo/bar/baz.zip == /foo/bar/baz/baz.xstage\n            #             ^^^                     ^^^\n            if scene.stem == published_scene.stem:\n                xstage_path = scene\n                ideal_scene = True\n\n        # but sometimes xstage file has different name then zip - in that case\n        # use that one.\n        if not ideal_scene:\n            xstage_path = xstage_files[0]\n        return xstage_path\n\n    def get_plugin_info(self):\n        # this is path to published scene workfile _ZIP_. Before\n        # rendering, we need to unzip it.\n        published_scene = Path(\n            self.from_published_scene(False))\n        self.log.debug(f\"Processing {published_scene.as_posix()}\")\n        xstage_path = self._unzip_scene_file(published_scene)\n        render_path = xstage_path.parent / \"renders\"\n\n        # for submit_publish job to create .json file in\n        self._instance.data[\"outputDir\"] = render_path\n        # to let DL Explore Output\n        # TODO update this when #79 is fixed\n        self.job_info.OutputDirectory[0] = render_path.as_posix()\n        new_expected_files = []\n        render_path_str = str(render_path.as_posix())\n        for file in self._instance.data[\"expectedFiles\"]:\n            _file = str(Path(file).as_posix())\n            expected_dir_str = os.path.dirname(_file)\n            new_expected_files.append(\n                _file.replace(expected_dir_str, render_path_str)\n            )\n        audio_file = self._instance.data.get(\"audioFile\")\n        if audio_file:\n            abs_path = xstage_path.parent / audio_file\n            self._instance.context.data[\"audioFile\"] = str(abs_path)\n\n        self._instance.data[\"source\"] = str(published_scene.as_posix())\n        self._instance.data[\"expectedFiles\"] = new_expected_files\n        harmony_plugin_info = PluginInfo(\n            SceneFile=xstage_path.as_posix(),\n            Version=(\n                self._instance.context.data[\"harmonyVersion\"].split(\".\")[0]),\n            FieldOfView=self._instance.context.data[\"FOV\"],\n            ResolutionX=self._instance.data[\"resolutionWidth\"],\n            ResolutionY=self._instance.data[\"resolutionHeight\"]\n        )\n\n        leading_zeros = str(self._instance.data[\"leadingZeros\"])\n        frames_and_ext_pattern = f\"0{{{leading_zeros}}}[1-9]\\\\.[a-zA-Z]{{3}}\"\n        render_prefix = re.sub(frames_and_ext_pattern, \"\",\n                               self._instance.data[\"expectedFiles\"][0])\n        harmony_plugin_info.set_output(\n            self._instance.data[\"setMembers\"][0],\n            self._instance.data[\"outputFormat\"],\n            render_prefix,\n            self._instance.data[\"outputType\"],\n            self._instance.data[\"leadingZeros\"],\n            self._instance.data[\"outputStartFrame\"]\n        )\n\n        all_write_nodes = self._instance.context.data[\"all_write_nodes\"]\n        disable_nodes = []\n        for node in all_write_nodes:\n            # disable all other write nodes\n            if node != self._instance.data[\"setMembers\"][0]:\n                disable_nodes.append(\"node.setEnable('{}', false)\"\n                                     .format(node))\n        harmony_plugin_info.PreRenderInlineScript = ';'.join(disable_nodes)\n\n        return harmony_plugin_info.serialize()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo","title":"<code>PluginInfo</code>","text":"<p>               Bases: <code>object</code></p> <p>Plugin info structure for Harmony Deadline plugin.</p> Source code in <code>client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.py</code> <pre><code>@attr.s\nclass PluginInfo(object):\n    \"\"\"Plugin info structure for Harmony Deadline plugin.\"\"\"\n\n    SceneFile = attr.ib()\n    # Harmony version\n    Version = attr.ib()\n\n    Camera = attr.ib(default=\"\")\n    FieldOfView = attr.ib(default=41.11)\n    IsDatabase = attr.ib(default=False)\n    ResolutionX = attr.ib(default=1920)\n    ResolutionY = attr.ib(default=1080)\n\n    # Resolution name preset, default\n    UsingResPreset = attr.ib(default=False)\n    ResolutionName = attr.ib(default=\"HDTV_1080p24\")\n\n    PreRenderInlineScript = attr.ib(default=None)\n\n    # --------------------------------------------------\n    _outputNode = attr.ib(factory=list)\n\n    @property\n    def OutputNode(self):  # noqa: N802\n        \"\"\"Return all output nodes formatted for Deadline.\n\n        Returns:\n            dict: as `{'Output0Node', 'Top/renderFarmDefault'}`\n\n        \"\"\"\n        out = {}\n        for index, v in enumerate(self._outputNode):\n            out[\"Output{}Node\".format(index)] = v\n        return out\n\n    @OutputNode.setter\n    def OutputNode(self, val):  # noqa: N802\n        self._outputNode.append(val)\n\n    # --------------------------------------------------\n    _outputType = attr.ib(factory=list)\n\n    @property\n    def OutputType(self):  # noqa: N802\n        \"\"\"Return output nodes type formatted for Deadline.\n\n        Returns:\n            dict: as `{'Output0Type', 'Image'}`\n\n        \"\"\"\n        out = {}\n        for index, v in enumerate(self._outputType):\n            out[\"Output{}Type\".format(index)] = v\n        return out\n\n    @OutputType.setter\n    def OutputType(self, val):  # noqa: N802\n        self._outputType.append(val)\n\n    # --------------------------------------------------\n    _outputLeadingZero = attr.ib(factory=list)\n\n    @property\n    def OutputLeadingZero(self):  # noqa: N802\n        \"\"\"Return output nodes type formatted for Deadline.\n\n        Returns:\n            dict: as `{'Output0LeadingZero', '3'}`\n\n        \"\"\"\n        out = {}\n        for index, v in enumerate(self._outputLeadingZero):\n            out[\"Output{}LeadingZero\".format(index)] = v\n        return out\n\n    @OutputLeadingZero.setter\n    def OutputLeadingZero(self, val):  # noqa: N802\n        self._outputLeadingZero.append(val)\n\n    # --------------------------------------------------\n    _outputFormat = attr.ib(factory=list)\n\n    @property\n    def OutputFormat(self):  # noqa: N802\n        \"\"\"Return output nodes format formatted for Deadline.\n\n        Returns:\n            dict: as `{'Output0Type', 'PNG4'}`\n\n        \"\"\"\n        out = {}\n        for index, v in enumerate(self._outputFormat):\n            out[\"Output{}Format\".format(index)] = v\n        return out\n\n    @OutputFormat.setter\n    def OutputFormat(self, val):  # noqa: N802\n        self._outputFormat.append(val)\n\n    # --------------------------------------------------\n    _outputStartFrame = attr.ib(factory=list)\n\n    @property\n    def OutputStartFrame(self):  # noqa: N802\n        \"\"\"Return start frame for output nodes formatted for Deadline.\n\n        Returns:\n            dict: as `{'Output0StartFrame', '1'}`\n\n        \"\"\"\n        out = {}\n        for index, v in enumerate(self._outputStartFrame):\n            out[\"Output{}StartFrame\".format(index)] = v\n        return out\n\n    @OutputStartFrame.setter\n    def OutputStartFrame(self, val):  # noqa: N802\n        self._outputStartFrame.append(val)\n\n    # --------------------------------------------------\n    _outputPath = attr.ib(factory=list)\n\n    @property\n    def OutputPath(self):  # noqa: N802\n        \"\"\"Return output paths for nodes formatted for Deadline.\n\n        Returns:\n            dict: as `{'Output0Path', '/output/path'}`\n\n        \"\"\"\n        out = {}\n        for index, v in enumerate(self._outputPath):\n            out[\"Output{}Path\".format(index)] = v\n        return out\n\n    @OutputPath.setter\n    def OutputPath(self, val):  # noqa: N802\n        self._outputPath.append(val)\n\n    def set_output(self, node, image_format, output,\n                   output_type=\"Image\", zeros=3, start_frame=1):\n        \"\"\"Helper to set output.\n\n        This should be used instead of setting properties individually\n        as so index remain consistent.\n\n        Args:\n            node (str): harmony write node name\n            image_format (str): format of output (PNG4, TIF, ...)\n            output (str): output path\n            output_type (str, optional): \"Image\" or \"Movie\" (not supported).\n            zeros (int, optional): Leading zeros (for 0001 = 3)\n            start_frame (int, optional): Sequence offset.\n\n        \"\"\"\n\n        self.OutputNode = node\n        self.OutputFormat = image_format\n        self.OutputPath = output\n        self.OutputType = output_type\n        self.OutputLeadingZero = zeros\n        self.OutputStartFrame = start_frame\n\n    def serialize(self):\n        \"\"\"Return all data serialized as dictionary.\n\n        Returns:\n            OrderedDict: all serialized data.\n\n        \"\"\"\n        def filter_data(a, v):\n            if a.name.startswith(\"_\"):\n                return False\n            if v is None:\n                return False\n            return True\n\n        serialized = attr.asdict(\n            self, dict_factory=OrderedDict, filter=filter_data)\n        serialized.update(self.OutputNode)\n        serialized.update(self.OutputFormat)\n        serialized.update(self.OutputPath)\n        serialized.update(self.OutputType)\n        serialized.update(self.OutputLeadingZero)\n        serialized.update(self.OutputStartFrame)\n\n        return serialized\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo.OutputFormat","title":"<code>OutputFormat</code>  <code>property</code> <code>writable</code>","text":"<p>Return output nodes format formatted for Deadline.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>as <code>{'Output0Type', 'PNG4'}</code></p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo.OutputLeadingZero","title":"<code>OutputLeadingZero</code>  <code>property</code> <code>writable</code>","text":"<p>Return output nodes type formatted for Deadline.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>as <code>{'Output0LeadingZero', '3'}</code></p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo.OutputNode","title":"<code>OutputNode</code>  <code>property</code> <code>writable</code>","text":"<p>Return all output nodes formatted for Deadline.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>as <code>{'Output0Node', 'Top/renderFarmDefault'}</code></p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo.OutputPath","title":"<code>OutputPath</code>  <code>property</code> <code>writable</code>","text":"<p>Return output paths for nodes formatted for Deadline.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>as <code>{'Output0Path', '/output/path'}</code></p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo.OutputStartFrame","title":"<code>OutputStartFrame</code>  <code>property</code> <code>writable</code>","text":"<p>Return start frame for output nodes formatted for Deadline.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>as <code>{'Output0StartFrame', '1'}</code></p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo.OutputType","title":"<code>OutputType</code>  <code>property</code> <code>writable</code>","text":"<p>Return output nodes type formatted for Deadline.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>as <code>{'Output0Type', 'Image'}</code></p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo.serialize","title":"<code>serialize()</code>","text":"<p>Return all data serialized as dictionary.</p> <p>Returns:</p> Name Type Description <code>OrderedDict</code> <p>all serialized data.</p> Source code in <code>client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.py</code> <pre><code>def serialize(self):\n    \"\"\"Return all data serialized as dictionary.\n\n    Returns:\n        OrderedDict: all serialized data.\n\n    \"\"\"\n    def filter_data(a, v):\n        if a.name.startswith(\"_\"):\n            return False\n        if v is None:\n            return False\n        return True\n\n    serialized = attr.asdict(\n        self, dict_factory=OrderedDict, filter=filter_data)\n    serialized.update(self.OutputNode)\n    serialized.update(self.OutputFormat)\n    serialized.update(self.OutputPath)\n    serialized.update(self.OutputType)\n    serialized.update(self.OutputLeadingZero)\n    serialized.update(self.OutputStartFrame)\n\n    return serialized\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.html#client.ayon_deadline.plugins.publish.harmony.submit_harmony_deadline.PluginInfo.set_output","title":"<code>set_output(node, image_format, output, output_type='Image', zeros=3, start_frame=1)</code>","text":"<p>Helper to set output.</p> <p>This should be used instead of setting properties individually as so index remain consistent.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>harmony write node name</p> required <code>image_format</code> <code>str</code> <p>format of output (PNG4, TIF, ...)</p> required <code>output</code> <code>str</code> <p>output path</p> required <code>output_type</code> <code>str</code> <p>\"Image\" or \"Movie\" (not supported).</p> <code>'Image'</code> <code>zeros</code> <code>int</code> <p>Leading zeros (for 0001 = 3)</p> <code>3</code> <code>start_frame</code> <code>int</code> <p>Sequence offset.</p> <code>1</code> Source code in <code>client/ayon_deadline/plugins/publish/harmony/submit_harmony_deadline.py</code> <pre><code>def set_output(self, node, image_format, output,\n               output_type=\"Image\", zeros=3, start_frame=1):\n    \"\"\"Helper to set output.\n\n    This should be used instead of setting properties individually\n    as so index remain consistent.\n\n    Args:\n        node (str): harmony write node name\n        image_format (str): format of output (PNG4, TIF, ...)\n        output (str): output path\n        output_type (str, optional): \"Image\" or \"Movie\" (not supported).\n        zeros (int, optional): Leading zeros (for 0001 = 3)\n        start_frame (int, optional): Sequence offset.\n\n    \"\"\"\n\n    self.OutputNode = node\n    self.OutputFormat = image_format\n    self.OutputPath = output\n    self.OutputType = output_type\n    self.OutputLeadingZero = zeros\n    self.OutputStartFrame = start_frame\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/index.html","title":"houdini","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/submit_houdini_cache_deadline.html","title":"submit_houdini_cache_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/submit_houdini_cache_deadline.html#client.ayon_deadline.plugins.publish.houdini.submit_houdini_cache_deadline.HoudiniCacheSubmitDeadline","title":"<code>HoudiniCacheSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code>, <code>AYONPyblishPluginMixin</code></p> <p>Submit Houdini scene to perform a local publish in Deadline.</p> <p>Publishing in Deadline can be helpful for scenes that publish very slow. This way it can process in the background on another machine without the Artist having to wait for the publish to finish on their local machine.</p> Source code in <code>client/ayon_deadline/plugins/publish/houdini/submit_houdini_cache_deadline.py</code> <pre><code>class HoudiniCacheSubmitDeadline(abstract_submit_deadline.AbstractSubmitDeadline,   # noqa\n                                 AYONPyblishPluginMixin):\n    \"\"\"Submit Houdini scene to perform a local publish in Deadline.\n\n    Publishing in Deadline can be helpful for scenes that publish very slow.\n    This way it can process in the background on another machine without the\n    Artist having to wait for the publish to finish on their local machine.\n    \"\"\"\n\n    label = \"Submit Scene to Deadline\"\n    order = pyblish.api.IntegratorOrder\n    hosts = [\"houdini\"]\n    families = [\"publish.hou\"]\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    def get_job_info(self, job_info=None):\n        instance = self._instance\n        context = instance.context\n        assert all(\n            result[\"success\"] for result in context.data[\"results\"]\n        ), \"Errors found, aborting integration..\"\n\n        project_name = instance.context.data[\"projectName\"]\n        filepath = context.data[\"currentFile\"]\n        scenename = os.path.basename(filepath)\n        job_name = \"{scene} - {instance} [PUBLISH]\".format(\n            scene=scenename, instance=instance.name)\n        batch_name = f\"{project_name} - {scenename}\"\n        if is_in_tests():\n            batch_name += datetime.now().strftime(\"%d%m%Y%H%M%S\")\n\n        job_info.Name = job_name\n        job_info.BatchName = batch_name\n        job_info.Plugin = instance.data.get(\"plugin\", \"Houdini\")\n\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            frames = \"{start}-{end}x{step}\".format(\n                start=int(instance.data[\"frameStart\"]),\n                end=int(instance.data[\"frameEnd\"]),\n                step=int(instance.data[\"byFrameStep\"]),\n            )\n\n            job_info.Frames = frames\n\n        # When `frames` instance data is a string, it indicates that\n        #  the output is a single file.\n        # Set the chunk size to a large number because multiple\n        #  machines cannot render to the same file.\n        if isinstance(instance.data.get(\"frames\"), str):\n            job_info.ChunkSize = 99999999\n\n        return job_info\n\n    def get_plugin_info(self):\n        # Not all hosts can import this module.\n        import hou\n\n        instance = self._instance\n        version = hou.applicationVersionString()\n        version = \".\".join(version.split(\".\")[:2])\n        rop = self.get_rop_node(instance)\n        plugin_info = HoudiniPluginInfo(\n            Build=None,\n            IgnoreInputs=True,\n            ScriptJob=True,\n            SceneFile=self.scene_path,\n            SaveFile=True,\n            OutputDriver=rop.path(),\n            Version=version,\n            ProjectPath=os.path.dirname(self.scene_path)\n        )\n\n        plugin_payload = asdict(plugin_info)\n\n        return plugin_payload\n\n    def process(self, instance):\n        super(HoudiniCacheSubmitDeadline, self).process(instance)\n        output_dir = os.path.dirname(instance.data[\"files\"][0])\n        instance.data[\"outputDir\"] = output_dir\n        instance.data[\"toBeRenderedOn\"] = \"deadline\"\n\n    def get_rop_node(self, instance):\n        # Not all hosts can import this module.\n        import hou\n\n        rop = instance.data.get(\"instance_node\")\n        rop_node = hou.node(rop)\n\n        return rop_node\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/submit_houdini_render_deadline.html","title":"submit_houdini_render_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/submit_houdini_render_deadline.html#client.ayon_deadline.plugins.publish.houdini.submit_houdini_render_deadline.HoudiniSubmitDeadline","title":"<code>HoudiniSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code>, <code>AYONPyblishPluginMixin</code></p> <p>Submit Render ROPs to Deadline.</p> <p>Renders are submitted to a Deadline Web Service as supplied via the environment variable AVALON_DEADLINE.</p> <p>Target \"local\":     Even though this does not render locally this is seen as     a 'local' submission as it is the regular way of submitting     a Houdini render locally.</p> Source code in <code>client/ayon_deadline/plugins/publish/houdini/submit_houdini_render_deadline.py</code> <pre><code>class HoudiniSubmitDeadline(\n    abstract_submit_deadline.AbstractSubmitDeadline,\n    AYONPyblishPluginMixin\n):\n    \"\"\"Submit Render ROPs to Deadline.\n\n    Renders are submitted to a Deadline Web Service as\n    supplied via the environment variable AVALON_DEADLINE.\n\n    Target \"local\":\n        Even though this does *not* render locally this is seen as\n        a 'local' submission as it is the regular way of submitting\n        a Houdini render locally.\n\n    \"\"\"\n\n    label = \"Submit Render to Deadline\"\n    order = pyblish.api.IntegratorOrder\n    hosts = [\"houdini\"]\n    families = [\"redshift_rop\",\n                \"arnold_rop\",\n                \"mantra_rop\",\n                \"karma_rop\",\n                \"vray_rop\"]\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    # presets\n    export_priority = 50\n    export_chunk_size = 10\n    export_group = \"\"\n    export_limits = \"\"\n    export_machine_limit = 0\n\n    @classmethod\n    def get_attribute_defs(cls):\n        return [\n            NumberDef(\n                \"export_priority\",\n                label=\"Export Priority\",\n                default=cls.export_priority,\n                decimals=0\n            ),\n            NumberDef(\n                \"export_chunk\",\n                label=\"Export Frames Per Task\",\n                default=cls.export_chunk_size,\n                decimals=0,\n                minimum=1,\n                maximum=1000\n            ),\n            TextDef(\n                \"export_group\",\n                default=cls.export_group,\n                label=\"Export Group Name\"\n            ),\n            TextDef(\n                \"export_limits\",\n                default=cls.export_limits,\n                label=\"Export Limit Groups\",\n                placeholder=\"value1,value2\",\n                tooltip=\"Enter a comma separated list of limit groups.\"\n            ),\n            NumberDef(\n                \"export_machine_limit\",\n                default=cls.export_machine_limit,\n                label=\"Export Machine Limit\",\n                tooltip=\"maximum number of machines for this job.\"\n            ),\n        ]\n\n    def get_job_info(self, dependency_job_ids=None, job_info=None):\n\n        instance = self._instance\n        context = instance.context\n\n        # Whether Deadline render submission is being split in two\n        # (extract + render)\n        split_render_job = instance.data.get(\"splitRender\")\n\n        # If there's some dependency job ids we can assume this is a render job\n        # and not an export job\n        is_export_job = True\n        if dependency_job_ids:\n            is_export_job = False\n\n        job_type = \"[RENDER]\"\n        if split_render_job and not is_export_job:\n            families = self._get_families(instance)\n            family_to_render_plugin = {\n                \"arnold_rop\": \"Arnold\",\n                \"karma_rop\": \"Karma\",\n                \"mantra_rop\": \"Mantra\",\n                \"redshift_rop\": \"Redshift\",\n                \"usdrender\": \"HuskStandalone\",\n                \"vray_rop\": \"Vray\",\n            }\n            for family, render_plugin in family_to_render_plugin.items():\n                if family in families:\n                    plugin = render_plugin\n                    break\n            else:\n                plugin = \"Render\"\n                self.log.warning(\n                    f\"No matching render plugin found for families: {families}\"\n                )\n        else:\n            plugin = \"Houdini\"\n            if split_render_job:\n                export_file = instance.data[\"ifdFile\"]\n                extension = os.path.splitext(export_file)[-1] or \"SCENE\"\n                job_type = f\"[EXPORT {extension.upper()}]\"\n\n        job_info.Plugin = plugin\n\n        filepath = context.data[\"currentFile\"]\n        filename = os.path.basename(filepath)\n        job_info.Name = \"{} - {} {}\".format(filename, instance.name, job_type)\n        job_info.BatchName = filename\n\n        if is_in_tests():\n            job_info.BatchName += datetime.now().strftime(\"%d%m%Y%H%M%S\")\n\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            # Deadline requires integers in frame range\n            start = instance.data[\"frameStartHandle\"]\n            end = instance.data[\"frameEndHandle\"]\n            frames = \"{start}-{end}x{step}\".format(\n                start=int(start),\n                end=int(end),\n                step=int(instance.data[\"byFrameStep\"]),\n            )\n            job_info.Frames = frames\n\n        # Make sure we make job frame dependent so render tasks pick up a soon\n        # as export tasks are done\n        if split_render_job and not is_export_job:\n            job_info.IsFrameDependent = bool(instance.data.get(\n                \"splitRenderFrameDependent\", True))\n\n        attribute_values = self.get_attr_values_from_data(instance.data)\n        if split_render_job and is_export_job:\n            job_info.Priority = attribute_values.get(\n                \"export_priority\", self.export_priority\n            )\n            job_info.ChunkSize = attribute_values.get(\n                \"export_chunk\", self.export_chunk_size\n            )\n            job_info.Group = attribute_values.get(\n                \"export_group\", self.export_group\n            )\n            job_info.LimitGroups = attribute_values.get(\n                \"export_limits\", self.export_limits\n            )\n            job_info.MachineLimit = attribute_values.get(\n                \"export_machine_limit\", self.export_machine_limit\n            )\n\n        # TODO change to expectedFiles??\n        for i, filepath in enumerate(instance.data[\"files\"]):\n            dirname = os.path.dirname(filepath)\n            fname = os.path.basename(filepath)\n            job_info.OutputDirectory += dirname.replace(\"\\\\\", \"/\")\n            job_info.OutputFilename += fname\n\n        # Add dependencies if given\n        if dependency_job_ids:\n            job_info.JobDependencies = dependency_job_ids\n\n        return job_info\n\n    def get_plugin_info(self, job_type=None):\n        # Not all hosts can import this module.\n        import hou\n\n        instance = self._instance\n        context = instance.context\n\n        hou_major_minor = hou.applicationVersionString().rsplit(\".\", 1)[0]\n\n        # Output driver to render\n        if job_type == \"render\":\n            families = self._get_families(instance)\n            if \"arnold_rop\" in families:\n                plugin_info = ArnoldRenderDeadlinePluginInfo(\n                    InputFile=instance.data[\"ifdFile\"]\n                )\n            elif \"mantra_rop\" in families:\n                plugin_info = MantraRenderDeadlinePluginInfo(\n                    SceneFile=instance.data[\"ifdFile\"],\n                    Version=hou_major_minor,\n                )\n            elif \"vray_rop\" in families:\n                plugin_info = VrayRenderPluginInfo(\n                    InputFilename=instance.data[\"ifdFile\"],\n                )\n            elif \"redshift_rop\" in families:\n                plugin_info = RedshiftRenderPluginInfo(\n                    SceneFile=instance.data[\"ifdFile\"]\n                )\n                # Note: To use different versions of Redshift on Deadline\n                #       set the `REDSHIFT_VERSION` env variable in the Tools\n                #       settings in the AYON Application plugin. You will also\n                #       need to set that version in `Redshift.param` file\n                #       of the Redshift Deadline plugin:\n                #           [Redshift_Executable_*]\n                #           where * is the version number.\n                if os.getenv(\"REDSHIFT_VERSION\"):\n                    plugin_info.Version = os.getenv(\"REDSHIFT_VERSION\")\n                else:\n                    self.log.warning((\n                        \"REDSHIFT_VERSION env variable is not set\"\n                        \" - using version configured in Deadline\"\n                    ))\n\n            elif \"usdrender\" in families:\n                plugin_info = self._get_husk_standalone_plugin_info(\n                    instance, hou_major_minor)\n\n            else:\n                self.log.error(\n                    \"Render Product Type does not support to split render \"\n                    f\"job. Matched product types against: {families}\"\n                )\n                return\n        else:\n            driver = hou.node(instance.data[\"instance_node\"])\n            plugin_info = DeadlinePluginInfo(\n                SceneFile=context.data[\"currentFile\"],\n                OutputDriver=driver.path(),\n                Version=hou_major_minor,\n                IgnoreInputs=True\n            )\n\n        return asdict(plugin_info)\n\n    def process(self, instance):\n        if not instance.data[\"farm\"]:\n            self.log.debug(\"Render on farm is disabled. \"\n                           \"Skipping deadline submission.\")\n            return\n\n        super(HoudiniSubmitDeadline, self).process(instance)\n\n        # TODO: Avoid the need for this logic here, needed for submit publish\n        # Store output dir for unified publisher (filesequence)\n        output_dir = os.path.dirname(instance.data[\"files\"][0])\n        instance.data[\"outputDir\"] = output_dir\n\n    def _get_husk_standalone_plugin_info(self, instance, hou_major_minor):\n        # Not all hosts can import this module.\n        import hou\n\n        # Supply additional parameters from the USD Render ROP\n        # to the Husk Standalone Render Plug-in\n        rop_node = hou.node(instance.data[\"instance_node\"])\n        snapshot_interval = -1\n        if rop_node.evalParm(\"dosnapshot\"):\n            snapshot_interval = rop_node.evalParm(\"snapshotinterval\")\n\n        restart_delegate = 0\n        if rop_node.evalParm(\"husk_restartdelegate\"):\n            restart_delegate = rop_node.evalParm(\"husk_restartdelegateframes\")\n\n        rendersettings = (\n            rop_node.evalParm(\"rendersettings\")\n            or \"/Render/rendersettings\"\n        )\n\n        # Get SlapComps\n        # Instance data comes from `CollectSlapComps` plugin in Houdini addon.\n        slapcomps: \"list[str]\" = instance.data.get(\"slapComp\", [])\n\n        return HuskStandalonePluginInfo(\n            SceneFile=instance.data[\"ifdFile\"],\n            Renderer=rop_node.evalParm(\"renderer\"),\n            RenderSettings=rendersettings,\n            Purpose=rop_node.evalParm(\"husk_purpose\"),\n            Complexity=rop_node.evalParm(\"husk_complexity\"),\n            Snapshot=snapshot_interval,\n            PreRender=rop_node.evalParm(\"husk_prerender\"),\n            PreFrame=rop_node.evalParm(\"husk_preframe\"),\n            PostFrame=rop_node.evalParm(\"husk_postframe\"),\n            PostRender=rop_node.evalParm(\"husk_postrender\"),\n            RestartDelegate=restart_delegate,\n            Version=hou_major_minor,\n            SlapCompSources=\"\\n\".join(slapcomps)\n        )\n\n    def _get_families(self, instance: pyblish.api.Instance) -&gt; \"set[str]\":\n        families = set(instance.data.get(\"families\", []))\n        families.add(instance.data.get(\"productType\"))\n        return families\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/submit_houdini_render_deadline.html#client.ayon_deadline.plugins.publish.houdini.submit_houdini_render_deadline.HuskStandalonePluginInfo","title":"<code>HuskStandalonePluginInfo</code>  <code>dataclass</code>","text":"<p>Requires Deadline Husk Standalone Plugin. See Deadline Plug-in:     https://github.com/BigRoy/HuskStandaloneSubmitter Also see Husk options here:     https://www.sidefx.com/docs/houdini/ref/utils/husk.html</p> Source code in <code>client/ayon_deadline/plugins/publish/houdini/submit_houdini_render_deadline.py</code> <pre><code>@dataclass\nclass HuskStandalonePluginInfo:\n    \"\"\"Requires Deadline Husk Standalone Plugin.\n    See Deadline Plug-in:\n        https://github.com/BigRoy/HuskStandaloneSubmitter\n    Also see Husk options here:\n        https://www.sidefx.com/docs/houdini/ref/utils/husk.html\n    \"\"\"\n    SceneFile: str = field()\n    # TODO: Below parameters are only supported by custom version of the plugin\n    Renderer: str = field(default=None)\n    RenderSettings: str = field(default=\"/Render/rendersettings\")\n    Purpose: str = field(default=\"geometry,render\")\n    Complexity: str = field(default=\"veryhigh\")\n    Snapshot: int = field(default=-1)\n    LogLevel: str = field(default=\"2\")\n    PreRender: str = field(default=\"\")\n    PreFrame: str = field(default=\"\")\n    PostFrame: str = field(default=\"\")\n    PostRender: str = field(default=\"\")\n    RestartDelegate: str = field(default=\"\")\n    Version: str = field(default=\"\")\n    SlapCompSources: str = field(default=\"\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/submit_publish_cache_job.html","title":"submit_publish_cache_job","text":"<p>Submit publishing job to farm.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/submit_publish_cache_job.html#client.ayon_deadline.plugins.publish.houdini.submit_publish_cache_job.ProcessSubmittedCacheJobOnFarm","title":"<code>ProcessSubmittedCacheJobOnFarm</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>AYONPyblishPluginMixin</code>, <code>ColormanagedPyblishPluginMixin</code></p> <p>Process Cache Job submitted on farm This is replicated version of submit publish job specifically for cache(s).</p> <p>These jobs are dependent on a deadline job submission prior to this plug-in.</p> <ul> <li>In case of Deadline, it creates dependent job on farm publishing   rendered image sequence.</li> </ul> <p>Options in instance.data:     - deadlineSubmissionJob (dict, Required): The returned .json       data from the job submission to deadline.</p> <pre><code>- outputDir (str, Required): The output directory where the metadata\n    file should be generated. It's assumed that this will also be\n    final folder containing the output files.\n\n- ext (str, Optional): The extension (including `.`) that is required\n    in the output filename to be picked up for image sequence\n    publishing.\n\n- expectedFiles (list or dict): explained below\n</code></pre> Source code in <code>client/ayon_deadline/plugins/publish/houdini/submit_publish_cache_job.py</code> <pre><code>class ProcessSubmittedCacheJobOnFarm(pyblish.api.InstancePlugin,\n                                     publish.AYONPyblishPluginMixin,\n                                     publish.ColormanagedPyblishPluginMixin):\n    \"\"\"Process Cache Job submitted on farm\n    This is replicated version of submit publish job\n    specifically for cache(s).\n\n    These jobs are dependent on a deadline job\n    submission prior to this plug-in.\n\n    - In case of Deadline, it creates dependent job on farm publishing\n      rendered image sequence.\n\n    Options in instance.data:\n        - deadlineSubmissionJob (dict, Required): The returned .json\n          data from the job submission to deadline.\n\n        - outputDir (str, Required): The output directory where the metadata\n            file should be generated. It's assumed that this will also be\n            final folder containing the output files.\n\n        - ext (str, Optional): The extension (including `.`) that is required\n            in the output filename to be picked up for image sequence\n            publishing.\n\n        - expectedFiles (list or dict): explained below\n\n    \"\"\"\n\n    label = \"Submit cache jobs to Deadline\"\n    order = pyblish.api.IntegratorOrder + 0.2\n    icon = \"tractor\"\n    settings_category = \"deadline\"\n\n    targets = [\"local\"]\n\n    hosts = [\"houdini\"]\n\n    families = [\"publish.hou\"]\n\n    # custom deadline attributes\n    deadline_department = \"\"\n    deadline_pool = \"\"\n    deadline_group = \"\"\n    deadline_priority = None\n\n    # regex for finding frame number in string\n    R_FRAME_NUMBER = re.compile(r'.+\\.(?P&lt;frame&gt;[0-9]+)\\..+')\n\n    def _submit_deadline_post_job(self, instance, job):\n        \"\"\"Submit publish job to Deadline.\n\n        Returns:\n            (str): deadline_publish_job_id\n        \"\"\"\n        data = instance.data.copy()\n        product_name = data[\"productName\"]\n        job_name = \"Publish - {}\".format(product_name)\n\n        context = instance.context\n        anatomy = context.data[\"anatomy\"]\n\n        # instance.data.get(\"productName\") != instances[0][\"productName\"]\n        # 'Main' vs 'renderMain'\n        override_version = None\n        instance_version = instance.data.get(\"version\")  # take this if exists\n        if instance_version != 1:\n            override_version = instance_version\n\n        output_dir = self._get_publish_folder(\n            anatomy,\n            deepcopy(instance.data[\"anatomyData\"]),\n            instance.data.get(\"folderEntity\"),\n            instance.data[\"productName\"],\n            context,\n            instance.data[\"productType\"],\n            override_version\n        )\n\n        # Transfer the environment from the original job to this dependent\n        # job so they use the same environment\n        metadata_path, rootless_metadata_path = \\\n            create_metadata_path(instance, anatomy)\n\n        environment = get_instance_job_envs(instance)\n        environment.update(JobType.PUBLISH.get_job_env())\n\n        priority = self.deadline_priority or instance.data.get(\"priority\", 50)\n\n        args = [\n            \"--headless\",\n            'publish',\n            rootless_metadata_path,\n            \"--targets\", \"deadline\",\n            \"--targets\", \"farm\"\n        ]\n\n        dependency_ids = []\n        if job.get(\"_id\"):\n            dependency_ids.append(job[\"_id\"])\n\n        server_name = instance.data[\"deadline\"][\"serverName\"]\n\n        self.log.debug(\"Submitting Deadline publish job ...\")\n        deadline_addon: DeadlineAddon = (\n            context.data[\"ayonAddonsManager\"][\"deadline\"]\n        )\n\n        job_info = instance.data[\"deadline\"][\"job_info\"]\n        job_info = DeadlineJobInfo(\n            Name=job_name,\n            BatchName=job[\"Props\"][\"Batch\"],\n            Department=self.deadline_department,\n            Priority=priority,\n            InitialStatus=job_info.publish_job_state,\n            Group=self.deadline_group,\n            Pool=self.deadline_pool or None,\n            JobDependencies=dependency_ids,\n            UserName=job[\"Props\"][\"User\"],\n            Comment=context.data.get(\"comment\"),\n        )\n        job_info.OutputDirectory.append(\n            output_dir.replace(\"\\\\\", \"/\")\n        )\n        job_info.EnvironmentKeyValue.update(environment)\n\n        return deadline_addon.submit_ayon_plugin_job(\n            server_name, args, job_info\n        )[\"response\"][\"_id\"]\n\n    def process(self, instance):\n        # type: (pyblish.api.Instance) -&gt; None\n        \"\"\"Process plugin.\n\n        Detect type of render farm submission and create and post dependent\n        job in case of Deadline. It creates json file with metadata needed for\n        publishing in directory of render.\n\n        Args:\n            instance (pyblish.api.Instance): Instance data.\n\n        \"\"\"\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Skipping local instance.\")\n            return\n\n        anatomy = instance.context.data[\"anatomy\"]\n\n        instance_skeleton_data = create_skeleton_instance_cache(instance)\n        \"\"\"\n        if content of `expectedFiles` list are dictionaries, we will handle\n        it as list of AOVs, creating instance for every one of them.\n\n        Example:\n        --------\n\n        expectedFiles = [\n            {\n                \"beauty\": [\n                    \"foo_v01.0001.exr\",\n                    \"foo_v01.0002.exr\"\n                ],\n\n                \"Z\": [\n                    \"boo_v01.0001.exr\",\n                    \"boo_v01.0002.exr\"\n                ]\n            }\n        ]\n\n        This will create instances for `beauty` and `Z` product\n        adding those files to their respective representations.\n\n        If we have only list of files, we collect all file sequences.\n        More then one doesn't probably make sense, but we'll handle it\n        like creating one instance with multiple representations.\n\n        Example:\n        --------\n\n        expectedFiles = [\n            \"foo_v01.0001.exr\",\n            \"foo_v01.0002.exr\",\n            \"xxx_v01.0001.exr\",\n            \"xxx_v01.0002.exr\"\n        ]\n\n        This will result in one instance with two representations:\n        `foo` and `xxx`\n        \"\"\"\n\n        if isinstance(instance.data.get(\"expectedFiles\")[0], dict):\n            instances = create_instances_for_cache(\n                instance, instance_skeleton_data)\n        else:\n            representations = prepare_cache_representations(\n                instance_skeleton_data,\n                instance.data.get(\"expectedFiles\"),\n                anatomy\n            )\n\n            if \"representations\" not in instance_skeleton_data.keys():\n                instance_skeleton_data[\"representations\"] = []\n\n            # add representation\n            instance_skeleton_data[\"representations\"] += representations\n            instances = [instance_skeleton_data]\n\n        # attach instances to product\n        if instance.data.get(\"attachTo\"):\n            instances = attach_instances_to_product(\n                instance.data.get(\"attachTo\"), instances\n            )\n\n        r''' SUBMiT PUBLiSH JOB 2 D34DLiN3\n          ____\n        '     '            .---.  .---. .--. .---. .--..--..--..--. .---.\n        |     |   --= \\   |  .  \\/   _|/    \\|  .  \\  ||  ||   \\  |/   _|\n        | JOB |   --= /   |  |  ||  __|  ..  |  |  |  |;_ ||  \\   ||  __|\n        |     |           |____./ \\.__|._||_.|___./|_____|||__|\\__|\\.___|\n        ._____.\n\n        '''\n\n        render_job = None\n        submission_type = \"\"\n        if instance.data.get(\"toBeRenderedOn\") == \"deadline\":\n            render_job = instance.data.pop(\"deadlineSubmissionJob\", None)\n            submission_type = \"deadline\"\n\n        if not render_job:\n            import getpass\n\n            render_job = {}\n            self.log.debug(\"Faking job data ...\")\n            render_job[\"Props\"] = {}\n            # Render job doesn't exist because we do not have prior submission.\n            # We still use data from it so lets fake it.\n            #\n            # Batch name reflect original scene name\n\n            if instance.data.get(\"assemblySubmissionJobs\"):\n                render_job[\"Props\"][\"Batch\"] = instance.data.get(\n                    \"jobBatchName\")\n            else:\n                batch = os.path.splitext(os.path.basename(\n                    instance.context.data.get(\"currentFile\")))[0]\n                render_job[\"Props\"][\"Batch\"] = batch\n            # User is deadline user\n            render_job[\"Props\"][\"User\"] = instance.context.data.get(\n                \"deadlineUser\", getpass.getuser())\n\n        deadline_publish_job_id = None\n        if submission_type == \"deadline\":\n            self.deadline_url = instance.data[\"deadline\"][\"url\"]\n            assert self.deadline_url, \"Requires Deadline Webservice URL\"\n\n            deadline_publish_job_id = \\\n                self._submit_deadline_post_job(instance, render_job)\n\n            # Inject deadline url to instances.\n            for inst in instances:\n                if \"deadline\" not in inst:\n                    inst[\"deadline\"] = {}\n                inst[\"deadline\"] = instance.data[\"deadline\"]\n                inst[\"deadline\"].pop(\"job_info\")\n\n        # publish job file\n        publish_job = {\n            \"folderPath\": instance_skeleton_data[\"folderPath\"],\n            \"frameStart\": instance_skeleton_data[\"frameStart\"],\n            \"frameEnd\": instance_skeleton_data[\"frameEnd\"],\n            \"fps\": instance_skeleton_data[\"fps\"],\n            \"source\": instance_skeleton_data[\"source\"],\n            \"user\": instance.context.data[\"user\"],\n            \"version\": instance.context.data[\"version\"],  # workfile version\n            \"intent\": instance.context.data.get(\"intent\"),\n            \"comment\": instance.context.data.get(\"comment\"),\n            \"job\": render_job or None,\n            \"instances\": instances\n        }\n\n        if deadline_publish_job_id:\n            publish_job[\"deadline_publish_job_id\"] = deadline_publish_job_id\n\n        metadata_path, rootless_metadata_path = \\\n            create_metadata_path(instance, anatomy)\n\n        with open(metadata_path, \"w\") as f:\n            json.dump(publish_job, f, indent=4, sort_keys=True)\n\n    def _get_publish_folder(self, anatomy, template_data,\n                            folder_entity, product_name, context,\n                            product_type, version=None):\n        \"\"\"\n            Extracted logic to pre-calculate real publish folder, which is\n            calculated in IntegrateNew inside of Deadline process.\n            This should match logic in:\n                'collect_anatomy_instance_data' - to\n                    get correct anatomy, family, version for product and\n                'collect_resources_path'\n                    get publish_path\n\n        Args:\n            anatomy (ayon_core.pipeline.anatomy.Anatomy):\n            template_data (dict): pre-calculated collected data for process\n            folder_entity (dict[str, Any]): Folder entity.\n            product_name (str): Product name (actually group name of product).\n            product_type (str): for current deadline process it's always\n                'render'\n                TODO - for generic use family needs to be dynamically\n                    calculated like IntegrateNew does\n            version (int): override version from instance if exists\n\n        Returns:\n            (string): publish folder where rendered and published files will\n                be stored\n                based on 'publish' template\n        \"\"\"\n\n        project_name = context.data[\"projectName\"]\n        host_name = context.data[\"hostName\"]\n        if not version:\n            version_entity = None\n            if folder_entity:\n                version_entity = ayon_api.get_last_version_by_product_name(\n                    project_name,\n                    product_name,\n                    folder_entity[\"id\"]\n                )\n\n            if version_entity:\n                version = int(version_entity[\"version\"]) + 1\n            else:\n                version = get_versioning_start(\n                    project_name,\n                    host_name,\n                    task_name=template_data[\"task\"][\"name\"],\n                    task_type=template_data[\"task\"][\"type\"],\n                    product_type=\"render\",\n                    product_name=product_name,\n                    project_settings=context.data[\"project_settings\"]\n                )\n\n        task_info = template_data.get(\"task\") or {}\n\n        template_name = publish.get_publish_template_name(\n            project_name,\n            host_name,\n            product_type,\n            task_info.get(\"name\"),\n            task_info.get(\"type\"),\n        )\n\n        template_data[\"subset\"] = product_name\n        template_data[\"family\"] = product_type\n        template_data[\"version\"] = version\n        template_data[\"product\"] = {\n            \"name\": product_name,\n            \"type\": product_type,\n        }\n\n        render_dir_template = anatomy.get_template_item(\n            \"publish\", template_name, \"directory\"\n        )\n        return render_dir_template.format_strict(template_data)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/houdini/submit_publish_cache_job.html#client.ayon_deadline.plugins.publish.houdini.submit_publish_cache_job.ProcessSubmittedCacheJobOnFarm.process","title":"<code>process(instance)</code>","text":"<p>Process plugin.</p> <p>Detect type of render farm submission and create and post dependent job in case of Deadline. It creates json file with metadata needed for publishing in directory of render.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>Instance</code> <p>Instance data.</p> required Source code in <code>client/ayon_deadline/plugins/publish/houdini/submit_publish_cache_job.py</code> <pre><code>def process(self, instance):\n    # type: (pyblish.api.Instance) -&gt; None\n    \"\"\"Process plugin.\n\n    Detect type of render farm submission and create and post dependent\n    job in case of Deadline. It creates json file with metadata needed for\n    publishing in directory of render.\n\n    Args:\n        instance (pyblish.api.Instance): Instance data.\n\n    \"\"\"\n    if not instance.data.get(\"farm\"):\n        self.log.debug(\"Skipping local instance.\")\n        return\n\n    anatomy = instance.context.data[\"anatomy\"]\n\n    instance_skeleton_data = create_skeleton_instance_cache(instance)\n    \"\"\"\n    if content of `expectedFiles` list are dictionaries, we will handle\n    it as list of AOVs, creating instance for every one of them.\n\n    Example:\n    --------\n\n    expectedFiles = [\n        {\n            \"beauty\": [\n                \"foo_v01.0001.exr\",\n                \"foo_v01.0002.exr\"\n            ],\n\n            \"Z\": [\n                \"boo_v01.0001.exr\",\n                \"boo_v01.0002.exr\"\n            ]\n        }\n    ]\n\n    This will create instances for `beauty` and `Z` product\n    adding those files to their respective representations.\n\n    If we have only list of files, we collect all file sequences.\n    More then one doesn't probably make sense, but we'll handle it\n    like creating one instance with multiple representations.\n\n    Example:\n    --------\n\n    expectedFiles = [\n        \"foo_v01.0001.exr\",\n        \"foo_v01.0002.exr\",\n        \"xxx_v01.0001.exr\",\n        \"xxx_v01.0002.exr\"\n    ]\n\n    This will result in one instance with two representations:\n    `foo` and `xxx`\n    \"\"\"\n\n    if isinstance(instance.data.get(\"expectedFiles\")[0], dict):\n        instances = create_instances_for_cache(\n            instance, instance_skeleton_data)\n    else:\n        representations = prepare_cache_representations(\n            instance_skeleton_data,\n            instance.data.get(\"expectedFiles\"),\n            anatomy\n        )\n\n        if \"representations\" not in instance_skeleton_data.keys():\n            instance_skeleton_data[\"representations\"] = []\n\n        # add representation\n        instance_skeleton_data[\"representations\"] += representations\n        instances = [instance_skeleton_data]\n\n    # attach instances to product\n    if instance.data.get(\"attachTo\"):\n        instances = attach_instances_to_product(\n            instance.data.get(\"attachTo\"), instances\n        )\n\n    r''' SUBMiT PUBLiSH JOB 2 D34DLiN3\n      ____\n    '     '            .---.  .---. .--. .---. .--..--..--..--. .---.\n    |     |   --= \\   |  .  \\/   _|/    \\|  .  \\  ||  ||   \\  |/   _|\n    | JOB |   --= /   |  |  ||  __|  ..  |  |  |  |;_ ||  \\   ||  __|\n    |     |           |____./ \\.__|._||_.|___./|_____|||__|\\__|\\.___|\n    ._____.\n\n    '''\n\n    render_job = None\n    submission_type = \"\"\n    if instance.data.get(\"toBeRenderedOn\") == \"deadline\":\n        render_job = instance.data.pop(\"deadlineSubmissionJob\", None)\n        submission_type = \"deadline\"\n\n    if not render_job:\n        import getpass\n\n        render_job = {}\n        self.log.debug(\"Faking job data ...\")\n        render_job[\"Props\"] = {}\n        # Render job doesn't exist because we do not have prior submission.\n        # We still use data from it so lets fake it.\n        #\n        # Batch name reflect original scene name\n\n        if instance.data.get(\"assemblySubmissionJobs\"):\n            render_job[\"Props\"][\"Batch\"] = instance.data.get(\n                \"jobBatchName\")\n        else:\n            batch = os.path.splitext(os.path.basename(\n                instance.context.data.get(\"currentFile\")))[0]\n            render_job[\"Props\"][\"Batch\"] = batch\n        # User is deadline user\n        render_job[\"Props\"][\"User\"] = instance.context.data.get(\n            \"deadlineUser\", getpass.getuser())\n\n    deadline_publish_job_id = None\n    if submission_type == \"deadline\":\n        self.deadline_url = instance.data[\"deadline\"][\"url\"]\n        assert self.deadline_url, \"Requires Deadline Webservice URL\"\n\n        deadline_publish_job_id = \\\n            self._submit_deadline_post_job(instance, render_job)\n\n        # Inject deadline url to instances.\n        for inst in instances:\n            if \"deadline\" not in inst:\n                inst[\"deadline\"] = {}\n            inst[\"deadline\"] = instance.data[\"deadline\"]\n            inst[\"deadline\"].pop(\"job_info\")\n\n    # publish job file\n    publish_job = {\n        \"folderPath\": instance_skeleton_data[\"folderPath\"],\n        \"frameStart\": instance_skeleton_data[\"frameStart\"],\n        \"frameEnd\": instance_skeleton_data[\"frameEnd\"],\n        \"fps\": instance_skeleton_data[\"fps\"],\n        \"source\": instance_skeleton_data[\"source\"],\n        \"user\": instance.context.data[\"user\"],\n        \"version\": instance.context.data[\"version\"],  # workfile version\n        \"intent\": instance.context.data.get(\"intent\"),\n        \"comment\": instance.context.data.get(\"comment\"),\n        \"job\": render_job or None,\n        \"instances\": instances\n    }\n\n    if deadline_publish_job_id:\n        publish_job[\"deadline_publish_job_id\"] = deadline_publish_job_id\n\n    metadata_path, rootless_metadata_path = \\\n        create_metadata_path(instance, anatomy)\n\n    with open(metadata_path, \"w\") as f:\n        json.dump(publish_job, f, indent=4, sort_keys=True)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/max/index.html","title":"max","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/max/submit_max_deadline.html","title":"submit_max_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/max/submit_max_deadline.html#client.ayon_deadline.plugins.publish.max.submit_max_deadline.MaxSubmitDeadline","title":"<code>MaxSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code>, <code>AYONPyblishPluginMixin</code></p> Source code in <code>client/ayon_deadline/plugins/publish/max/submit_max_deadline.py</code> <pre><code>class MaxSubmitDeadline(abstract_submit_deadline.AbstractSubmitDeadline,\n                        AYONPyblishPluginMixin):\n\n    label = \"Submit Render to Deadline\"\n    hosts = [\"max\"]\n    families = [\"maxrender\"]\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    def get_job_info(self, job_info=None):\n\n        instance = self._instance\n        job_info.Plugin = instance.data.get(\"plugin\") or \"3dsmax\"\n\n        job_info.EnableAutoTimeout = True\n        # Deadline requires integers in frame range\n        frames = \"{start}-{end}\".format(\n            start=int(instance.data[\"frameStart\"]),\n            end=int(instance.data[\"frameEnd\"])\n        )\n        job_info.Frames = frames\n\n        # do not add expected files for multiCamera\n        if instance.data.get(\"multiCamera\"):\n            job_info.OutputDirectory.clear()\n            job_info.OutputFilename.clear()\n\n        return job_info\n\n    def get_plugin_info(self):\n        instance = self._instance\n\n        plugin_info = MaxPluginInfo(\n            SceneFile=self.scene_path,\n            Version=instance.data[\"maxversion\"],\n            SaveFile=True,\n            IgnoreInputs=True\n        )\n\n        plugin_payload = asdict(plugin_info)\n\n        return plugin_payload\n\n    def process_submission(self):\n\n        instance = self._instance\n        filepath = instance.context.data[\"currentFile\"]\n\n        files = instance.data[\"expectedFiles\"]\n        if not files:\n            raise KnownPublishError(\"No Render Elements found!\")\n        first_file = next(self._iter_expected_files(files))\n        output_dir = os.path.dirname(first_file)\n        instance.data[\"outputDir\"] = output_dir\n\n        filename = os.path.basename(filepath)\n\n        payload_data = {\n            \"filename\": filename,\n            \"dirname\": output_dir\n        }\n\n        self.log.debug(\"Submitting 3dsMax render..\")\n        project_settings = instance.context.data[\"project_settings\"]\n        auth = self._instance.data[\"deadline\"][\"auth\"]\n        verify = self._instance.data[\"deadline\"][\"verify\"]\n        if instance.data.get(\"multiCamera\"):\n            self.log.debug(\"Submitting jobs for multiple cameras..\")\n            payload = self._use_published_name_for_multiples(\n                payload_data, project_settings)\n            job_infos, plugin_infos = payload\n            for job_info, plugin_info in zip(job_infos, plugin_infos):\n                self.submit(\n                    self.assemble_payload(job_info, plugin_info),\n                    auth=auth,\n                    verify=verify\n                )\n        else:\n            payload = self._use_published_name(payload_data, project_settings)\n            job_info, plugin_info = payload\n            self.submit(\n                self.assemble_payload(job_info, plugin_info),\n                auth=auth,\n                verify=verify\n            )\n\n    def _use_published_name(self, data, project_settings):\n        # Not all hosts can import these modules.\n        from ayon_max.api.lib import (\n            get_current_renderer,\n            get_multipass_setting\n        )\n        instance = self._instance\n        job_info = copy.deepcopy(self.job_info)\n        plugin_info = copy.deepcopy(self.plugin_info)\n        plugin_data = {}\n        renderer = instance.data[\"renderer\"]\n        multipass = get_multipass_setting(renderer, project_settings)\n        if multipass:\n            plugin_data[\"DisableMultipass\"] = 0\n        else:\n            plugin_data[\"DisableMultipass\"] = 1\n\n        files = instance.data.get(\"expectedFiles\")\n        if not files:\n            raise KnownPublishError(\"No render elements found\")\n        first_file = next(self._iter_expected_files(files))\n        old_output_dir = os.path.dirname(first_file)\n\n        # as 3dsmax has version with different languages\n        plugin_data[\"Language\"] = \"ENU\"\n        renderer_class = get_current_renderer()\n\n        renderer = str(renderer_class).split(\":\")[0]\n        plugin_data = self._collect_render_output(\n            renderer, old_output_dir, plugin_data\n        )\n        if renderer == \"Redshift_Renderer\":\n            plugin_data[\"redshift_SeparateAovFiles\"] = instance.data.get(\n                \"separateAovFiles\")\n        if instance.data[\"cameras\"]:\n            camera = instance.data[\"cameras\"][0]\n            plugin_info[\"Camera0\"] = camera\n            plugin_info[\"Camera\"] = camera\n            plugin_info[\"Camera1\"] = camera\n\n        self.log.debug(\"plugin data:{}\".format(plugin_data))\n        plugin_info.update(plugin_data)\n\n        return job_info, plugin_info\n\n    def get_job_info_through_camera(self, camera):\n        \"\"\"Get the job parameters for deadline submission when\n        multi-camera is enabled.\n        Args:\n            infos(dict): a dictionary with job info.\n        \"\"\"\n        instance = self._instance\n        context = instance.context\n        job_info = copy.deepcopy(self.job_info)\n        exp = instance.data.get(\"expectedFiles\")\n\n        src_filepath = context.data[\"currentFile\"]\n        src_filename = os.path.basename(src_filepath)\n        job_info.Name = \"%s - %s - %s\" % (\n            src_filename, instance.name, camera)\n        for filepath in self._iter_expected_files(exp):\n            if camera not in filepath:\n                continue\n            job_info.OutputDirectory += os.path.dirname(filepath)\n            job_info.OutputFilename += os.path.basename(filepath)\n\n        return job_info\n        # set the output filepath with the relative camera\n\n    def get_plugin_info_through_camera(self, camera):\n        \"\"\"Get the plugin parameters for deadline submission when\n        multi-camera is enabled.\n        Args:\n            infos(dict): a dictionary with plugin info.\n        \"\"\"\n        instance = self._instance\n        # set the target camera\n        plugin_info = copy.deepcopy(self.plugin_info)\n\n        plugin_data = {}\n        # set the output filepath with the relative camera\n        if instance.data.get(\"multiCamera\"):\n            scene_filepath = instance.context.data[\"currentFile\"]\n            scene_filename = os.path.basename(scene_filepath)\n            scene_directory = os.path.dirname(scene_filepath)\n            current_filename, ext = os.path.splitext(scene_filename)\n            camera_name = camera.replace(\":\", \"_\")\n            camera_scene_name = f\"{current_filename}_{camera_name}{ext}\"\n            camera_scene_filepath = os.path.join(\n                scene_directory, f\"_{current_filename}\", camera_scene_name)\n            plugin_data[\"SceneFile\"] = camera_scene_filepath\n\n        files = instance.data.get(\"expectedFiles\")\n        if not files:\n            raise KnownPublishError(\"No render elements found\")\n        first_file = next(self._iter_expected_files(files))\n        old_output_dir = os.path.dirname(first_file)\n        renderer_class = get_current_renderer()\n\n        renderer = str(renderer_class).split(\":\")[0]\n        plugin_data = self._collect_render_output(\n            renderer, old_output_dir, plugin_data\n        )\n\n        if camera:\n            # set the default camera and target camera\n            # (weird parameters from max)\n            plugin_data[\"Camera\"] = camera\n            plugin_data[\"Camera1\"] = camera\n            plugin_data[\"Camera0\"] = None\n\n        plugin_info.update(plugin_data)\n        return plugin_info\n\n    def _use_published_name_for_multiples(self, data, project_settings):\n        \"\"\"Process the parameters submission for deadline when\n            user enables multi-cameras option.\n        Args:\n            job_info_list (list): A list of multiple job infos\n            plugin_info_list (list): A list of multiple plugin infos\n        \"\"\"\n        job_info_list = []\n        plugin_info_list = []\n        instance = self._instance\n        cameras = instance.data.get(\"cameras\", [])\n        renderer = instance.data[\"renderer\"]\n        plugin_data = {}\n        multipass = get_multipass_setting(renderer, project_settings)\n        if multipass:\n            plugin_data[\"DisableMultipass\"] = 0\n        else:\n            plugin_data[\"DisableMultipass\"] = 1\n        for cam in cameras:\n            job_info = self.get_job_info_through_camera(cam)\n            plugin_info = self.get_plugin_info_through_camera(cam)\n            plugin_info.update(plugin_data)\n            job_info_list.append(job_info)\n            plugin_info_list.append(plugin_info)\n\n        return job_info_list, plugin_info_list\n\n    def from_published_scene(self, replace_in_path=True):\n        instance = self._instance\n        renderer = instance.data[\"renderer\"]\n        if renderer == \"Redshift_Renderer\" or (\n            renderer.startswith(\"V_Ray_\")\n        ):\n            self.log.debug(\n                f\"Using {renderer}...published scene wont be used..\"\n            )\n            replace_in_path = False\n        return replace_with_published_scene_path(\n            instance, replace_in_path)\n\n    @staticmethod\n    def _collect_render_output(renderer, dir, plugin_data):\n        \"\"\"Collects render output and render element paths based on\n        renderer type.\n        Args:\n            renderer (str): The name of the current renderer.\n            dir (str): The directory where render outputs should be saved.\n            plugin_data (dict): The dictionary to populate with output paths.\n        Returns:\n            dict: Updated plugin_data with render output paths.\n\n        \"\"\"\n        from pymxs import runtime as rt\n        from ayon_max.api.lib_rendersettings import is_supported_renderer\n        # Handle render elements\n        if is_supported_renderer(renderer):\n            render_elem_list = RenderSettings().get_render_element()\n            for i, element in enumerate(render_elem_list):\n                elem_bname = os.path.basename(element)\n                new_elem_path = os.path.join(dir, elem_bname)\n                plugin_data[f\"RenderElementOutputFilename{i}\"] = new_elem_path\n\n        # Handle main render output\n        if renderer.startswith(\"V_Ray_\"):\n            plugin_data[\"RenderOutput\"] = \"\"\n        else:\n            render_output = rt.rendOutputFilename\n            plugin_data[\"RenderOutput\"] = render_output.replace(\"\\\\\", \"/\")\n\n        return plugin_data\n\n    @staticmethod\n    def _iter_expected_files(exp):\n        if isinstance(exp[0], dict):\n            for _aov, files in exp[0].items():\n                for file in files:\n                    yield file\n        else:\n            for file in exp:\n                yield file\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/max/submit_max_deadline.html#client.ayon_deadline.plugins.publish.max.submit_max_deadline.MaxSubmitDeadline.get_job_info_through_camera","title":"<code>get_job_info_through_camera(camera)</code>","text":"<p>Get the job parameters for deadline submission when multi-camera is enabled. Args:     infos(dict): a dictionary with job info.</p> Source code in <code>client/ayon_deadline/plugins/publish/max/submit_max_deadline.py</code> <pre><code>def get_job_info_through_camera(self, camera):\n    \"\"\"Get the job parameters for deadline submission when\n    multi-camera is enabled.\n    Args:\n        infos(dict): a dictionary with job info.\n    \"\"\"\n    instance = self._instance\n    context = instance.context\n    job_info = copy.deepcopy(self.job_info)\n    exp = instance.data.get(\"expectedFiles\")\n\n    src_filepath = context.data[\"currentFile\"]\n    src_filename = os.path.basename(src_filepath)\n    job_info.Name = \"%s - %s - %s\" % (\n        src_filename, instance.name, camera)\n    for filepath in self._iter_expected_files(exp):\n        if camera not in filepath:\n            continue\n        job_info.OutputDirectory += os.path.dirname(filepath)\n        job_info.OutputFilename += os.path.basename(filepath)\n\n    return job_info\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/max/submit_max_deadline.html#client.ayon_deadline.plugins.publish.max.submit_max_deadline.MaxSubmitDeadline.get_plugin_info_through_camera","title":"<code>get_plugin_info_through_camera(camera)</code>","text":"<p>Get the plugin parameters for deadline submission when multi-camera is enabled. Args:     infos(dict): a dictionary with plugin info.</p> Source code in <code>client/ayon_deadline/plugins/publish/max/submit_max_deadline.py</code> <pre><code>def get_plugin_info_through_camera(self, camera):\n    \"\"\"Get the plugin parameters for deadline submission when\n    multi-camera is enabled.\n    Args:\n        infos(dict): a dictionary with plugin info.\n    \"\"\"\n    instance = self._instance\n    # set the target camera\n    plugin_info = copy.deepcopy(self.plugin_info)\n\n    plugin_data = {}\n    # set the output filepath with the relative camera\n    if instance.data.get(\"multiCamera\"):\n        scene_filepath = instance.context.data[\"currentFile\"]\n        scene_filename = os.path.basename(scene_filepath)\n        scene_directory = os.path.dirname(scene_filepath)\n        current_filename, ext = os.path.splitext(scene_filename)\n        camera_name = camera.replace(\":\", \"_\")\n        camera_scene_name = f\"{current_filename}_{camera_name}{ext}\"\n        camera_scene_filepath = os.path.join(\n            scene_directory, f\"_{current_filename}\", camera_scene_name)\n        plugin_data[\"SceneFile\"] = camera_scene_filepath\n\n    files = instance.data.get(\"expectedFiles\")\n    if not files:\n        raise KnownPublishError(\"No render elements found\")\n    first_file = next(self._iter_expected_files(files))\n    old_output_dir = os.path.dirname(first_file)\n    renderer_class = get_current_renderer()\n\n    renderer = str(renderer_class).split(\":\")[0]\n    plugin_data = self._collect_render_output(\n        renderer, old_output_dir, plugin_data\n    )\n\n    if camera:\n        # set the default camera and target camera\n        # (weird parameters from max)\n        plugin_data[\"Camera\"] = camera\n        plugin_data[\"Camera1\"] = camera\n        plugin_data[\"Camera0\"] = None\n\n    plugin_info.update(plugin_data)\n    return plugin_info\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/maya/index.html","title":"maya","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/maya/submit_maya_cache_deadline.html","title":"submit_maya_cache_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/maya/submit_maya_cache_deadline.html#client.ayon_deadline.plugins.publish.maya.submit_maya_cache_deadline.MayaCacheSubmitDeadline","title":"<code>MayaCacheSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code>, <code>AYONPyblishPluginMixin</code></p> <p>Submit Maya scene to perform a local publish in Deadline.</p> <p>Publishing in Deadline can be helpful for scenes that publish very slow. This way it can process in the background on another machine without the Artist having to wait for the publish to finish on their local machine.</p> Source code in <code>client/ayon_deadline/plugins/publish/maya/submit_maya_cache_deadline.py</code> <pre><code>class MayaCacheSubmitDeadline(abstract_submit_deadline.AbstractSubmitDeadline,   # noqa\n                              AYONPyblishPluginMixin):\n    \"\"\"Submit Maya scene to perform a local publish in Deadline.\n\n    Publishing in Deadline can be helpful for scenes that publish very slow.\n    This way it can process in the background on another machine without the\n    Artist having to wait for the publish to finish on their local machine.\n    \"\"\"\n\n    label = \"Submit Scene to Deadline (Maya)\"\n    order = pyblish.api.IntegratorOrder\n    hosts = [\"maya\"]\n    families = [\"remote_publish_on_farm\"]\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    def get_job_info(self, job_info=None):\n        instance = self._instance\n        context = instance.context\n\n        project_name = instance.context.data[\"projectName\"]\n        filepath = context.data[\"currentFile\"]\n        scenename = os.path.basename(filepath)\n        job_name = \"{scene} - {instance} [PUBLISH]\".format(\n            scene=scenename, instance=instance.name)\n        batch_name = f\"{project_name} - {scenename}\"\n        if is_in_tests():\n            batch_name += datetime.now().strftime(\"%d%m%Y%H%M%S\")\n\n        job_info.Name = job_name\n        job_info.BatchName = batch_name\n        job_info.Plugin = \"MayaBatch\"\n        job_info.ChunkSize = 99999999\n\n        job_info.EnvironmentKeyValue[\"INSTANCE_IDS\"] = instance.name\n        job_info.EnvironmentKeyValue[\"AYON_REMOTE_PUBLISH\"] = \"1\"\n        return job_info\n\n    def get_plugin_info(self):\n        # Not all hosts can import this module.\n        from maya import cmds\n        instance = self._instance\n        scene_file = instance.context.data[\"currentFile\"]\n\n        plugin_info = MayaPluginInfo(\n            ScriptJob=True,\n            SceneFile=scene_file,\n            ScriptFilename=remote_publish.__file__.replace(\".pyc\", \".py\"),\n            Version=cmds.about(version=True),\n            ProjectPath=cmds.workspace(query=True,\n                                       rootDirectory=True)\n        )\n\n        plugin_payload = asdict(plugin_info)\n\n        return plugin_payload\n\n    def from_published_scene(self, replace_in_path=False):\n        return super().from_published_scene(False)\n\n    def process(self, instance):\n        super(MayaCacheSubmitDeadline, self).process(instance)\n        instance.data[\"toBeRenderedOn\"] = \"deadline\"\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/maya/submit_maya_deadline.html","title":"submit_maya_deadline","text":"<p>Submitting render job to Deadline.</p> <p>This module is taking care of submitting job from Maya to Deadline. It creates job and set correct environments. Its behavior is controlled by <code>DEADLINE_REST_URL</code> environment variable - pointing to Deadline Web Service and :data:<code>PublishDeadlineJobInfo.use_published</code> property telling Deadline to use published scene workfile or not.</p> <p>If <code>vrscene</code> or <code>assscene</code> are detected in families, it will first submit job to export these files and then dependent job to render them.</p> <p>Attributes:</p> Name Type Description <code>payload_skeleton</code> <code>dict</code> <p>Skeleton payload data sent as job to Deadline. Default values are for <code>MayaBatch</code> plugin.</p>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/maya/submit_maya_deadline.html#client.ayon_deadline.plugins.publish.maya.submit_maya_deadline.MayaSubmitDeadline","title":"<code>MayaSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code>, <code>AYONPyblishPluginMixin</code></p> Source code in <code>client/ayon_deadline/plugins/publish/maya/submit_maya_deadline.py</code> <pre><code>class MayaSubmitDeadline(abstract_submit_deadline.AbstractSubmitDeadline,\n                         AYONPyblishPluginMixin):\n\n    label = \"Submit Render to Deadline\"\n    hosts = [\"maya\"]\n    families = [\"renderlayer\"]\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    strict_error_checking = False\n\n    tile_assembler_plugin = \"DraftTileAssembler\"\n    tile_priority = 50\n\n    @classmethod\n    def get_attribute_defs(cls):\n        return [\n            NumberDef(\n                \"tile_priority\",\n                label=\"Tile Assembler Priority\",\n                decimals=0,\n                default=cls.tile_priority\n            ),\n            BoolDef(\n                \"strict_error_checking\",\n                label=\"Strict Error Checking\",\n                default=cls.strict_error_checking\n            ),\n        ]\n\n    def get_job_info(self, job_info=None):\n        instance = self._instance\n\n        job_info.Plugin = instance.data.get(\"mayaRenderPlugin\", \"MayaBatch\")\n\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            # Deadline requires integers in frame range\n            frames = \"{start}-{end}x{step}\".format(\n                start=int(instance.data[\"frameStartHandle\"]),\n                end=int(instance.data[\"frameEndHandle\"]),\n                step=int(instance.data[\"byFrameStep\"]),\n            )\n            job_info.Frames = frames\n\n        return job_info\n\n    def get_plugin_info(self):\n        # Not all hosts can import this module.\n        from maya import cmds\n\n        instance = self._instance\n        context = instance.context\n\n        # Set it to default Maya behaviour if it cannot be determined\n        # from instance (but it should be, by the Collector).\n\n        default_rs_include_lights = (\n            instance.context.data['project_settings']\n                                 ['maya']\n                                 ['render_settings']\n                                 ['enable_all_lights']\n        )\n\n        rs_include_lights = instance.data.get(\n            \"renderSetupIncludeLights\", default_rs_include_lights)\n        if rs_include_lights not in {\"1\", \"0\", True, False}:\n            rs_include_lights = default_rs_include_lights\n\n        attr_values = self.get_attr_values_from_data(instance.data)\n        strict_error_checking = attr_values.get(\"strict_error_checking\",\n                                                self.strict_error_checking)\n        plugin_info = MayaPluginInfo(\n            SceneFile=self.scene_path,\n            Version=cmds.about(version=True),\n            RenderLayer=instance.data['setMembers'],\n            Renderer=instance.data[\"renderer\"],\n            RenderSetupIncludeLights=rs_include_lights,  # noqa\n            ProjectPath=context.data[\"workspaceDir\"],\n            UsingRenderLayers=True,\n            StrictErrorChecking=strict_error_checking\n        )\n\n        plugin_payload = asdict(plugin_info)\n\n        return plugin_payload\n\n    def process_submission(self):\n        from maya import cmds\n        instance = self._instance\n\n        filepath = self.scene_path  # publish if `use_publish` else workfile\n\n        # TODO: Avoid the need for this logic here, needed for submit publish\n        # Store output dir for unified publisher (filesequence)\n        expected_files = instance.data[\"expectedFiles\"]\n        first_file = next(iter_expected_files(expected_files))\n        output_dir = os.path.dirname(first_file)\n        instance.data[\"outputDir\"] = output_dir\n\n        # Patch workfile (only when 'use_published' is enabled)\n        if self.job_info.use_published:\n            self._patch_workfile()\n\n        # Gather needed data ------------------------------------------------\n        filename = os.path.basename(filepath)\n        dirname = os.path.join(\n            cmds.workspace(query=True, rootDirectory=True),\n            cmds.workspace(fileRuleEntry=\"images\")\n        )\n\n        # Fill in common data to payload ------------------------------------\n        # TODO: Replace these with collected data from CollectRender\n        payload_data = {\n            \"filename\": filename,\n            \"dirname\": dirname,\n        }\n\n        # Submit preceding export jobs -------------------------------------\n        export_job = None\n        assert not all(x in instance.data[\"families\"]\n                       for x in ['vrayscene', 'assscene']), (\n            \"Vray Scene and Ass Scene options are mutually exclusive\")\n\n        auth = self._instance.data[\"deadline\"][\"auth\"]\n        verify = self._instance.data[\"deadline\"][\"verify\"]\n        if \"vrayscene\" in instance.data[\"families\"]:\n            self.log.debug(\"Submitting V-Ray scene render..\")\n            vray_export_payload = self._get_vray_export_payload(payload_data)\n            export_job = self.submit(vray_export_payload,\n                                     auth=auth,\n                                     verify=verify)\n\n            payload = self._get_vray_render_payload(payload_data)\n\n        else:\n            self.log.debug(\"Submitting MayaBatch render..\")\n            payload = self._get_maya_payload(payload_data)\n\n        # Add export job as dependency --------------------------------------\n        if export_job:\n            job_info, _ = payload\n            job_info.JobDependencies.append(export_job)\n\n        if instance.data.get(\"tileRendering\"):\n            # Prepare tiles data\n            self._tile_render(payload)\n        else:\n            # Submit main render job\n            job_info, plugin_info = payload\n            self.submit(self.assemble_payload(job_info, plugin_info),\n                        auth=auth,\n                        verify=verify)\n\n    def _tile_render(self, payload):\n        \"\"\"Submit as tile render per frame with dependent assembly jobs.\"\"\"\n\n        # As collected by super process()\n        instance = self._instance\n\n        payload_job_info, payload_plugin_info = payload\n        job_info = copy.deepcopy(payload_job_info)\n        plugin_info = copy.deepcopy(payload_plugin_info)\n\n        # Force plugin reload for vray cause the region does not get flushed\n        # between tile renders.\n        if plugin_info[\"Renderer\"] == \"vray\":\n            job_info.ForceReloadPlugin = True\n\n        # if we have sequence of files, we need to create tile job for\n        # every frame\n        job_info.TileJob = True\n        job_info.TileJobTilesInX = instance.data.get(\"tilesX\")\n        job_info.TileJobTilesInY = instance.data.get(\"tilesY\")\n\n        tiles_count = job_info.TileJobTilesInX * job_info.TileJobTilesInY\n\n        plugin_info[\"ImageHeight\"] = instance.data.get(\"resolutionHeight\")\n        plugin_info[\"ImageWidth\"] = instance.data.get(\"resolutionWidth\")\n        plugin_info[\"RegionRendering\"] = True\n\n        R_FRAME_NUMBER = re.compile(\n            r\".+\\.(?P&lt;frame&gt;[0-9]+)\\..+\")  # noqa: N806, E501\n        REPL_FRAME_NUMBER = re.compile(\n            r\"(.+\\.)([0-9]+)(\\..+)\")  # noqa: N806, E501\n\n        exp = instance.data[\"expectedFiles\"]\n        if isinstance(exp[0], dict):\n            # we have aovs and we need to iterate over them\n            # get files from `beauty`\n            files = exp[0].get(\"beauty\")\n            # assembly files are used for assembly jobs as we need to put\n            # together all AOVs\n            assembly_files = list(\n                itertools.chain.from_iterable(\n                    [f for _, f in exp[0].items()]))\n            if not files:\n                # if beauty doesn't exist, use first aov we found\n                files = exp[0].get(list(exp[0].keys())[0])\n        else:\n            files = exp\n            assembly_files = files\n\n        auth = instance.data[\"deadline\"][\"auth\"]\n        verify = instance.data[\"deadline\"][\"verify\"]\n\n        # Define frame tile jobs\n        frame_file_hash = {}\n        frame_payloads = {}\n        file_index = 1\n        for file in files:\n            frame = re.search(R_FRAME_NUMBER, file).group(\"frame\")\n\n            new_job_info = copy.deepcopy(job_info)\n            new_job_info.Name += \" (Frame {} - {} tiles)\".format(frame,\n                                                                 tiles_count)\n            new_job_info.TileJobFrame = frame\n\n            new_plugin_info = copy.deepcopy(plugin_info)\n\n            # Add tile data into job info and plugin info\n            tiles_data = _format_tiles(\n                file, 0,\n                instance.data.get(\"tilesX\"),\n                instance.data.get(\"tilesY\"),\n                instance.data.get(\"resolutionWidth\"),\n                instance.data.get(\"resolutionHeight\"),\n                payload_plugin_info[\"OutputFilePrefix\"]\n            )[0]\n\n            new_job_info.update(tiles_data[\"JobInfo\"])\n            new_plugin_info.update(tiles_data[\"PluginInfo\"])\n\n            self.log.debug(\"hashing {} - {}\".format(file_index, file))\n            job_hash = hashlib.sha256(\n                (\"{}_{}\".format(file_index, file)).encode(\"utf-8\"))\n\n            file_hash = job_hash.hexdigest()\n            frame_file_hash[frame] = file_hash\n\n            new_job_info.ExtraInfo[0] = file_hash\n            new_job_info.ExtraInfo[1] = file\n\n            frame_payloads[frame] = self.assemble_payload(\n                job_info=new_job_info,\n                plugin_info=new_plugin_info\n            )\n            file_index += 1\n\n        self.log.debug(\n            \"Submitting tile job(s) [{}] ...\".format(len(frame_payloads)))\n\n        # Submit frame tile jobs\n        frame_tile_job_id = {}\n        for frame, tile_job_payload in frame_payloads.items():\n            job_id = self.submit(\n                tile_job_payload, auth, verify)\n            frame_tile_job_id[frame] = job_id\n\n        # Define assembly payloads\n        assembly_job_info = copy.deepcopy(job_info)\n        assembly_job_info.Plugin = self.tile_assembler_plugin\n        assembly_job_info.Name += \" - Tile Assembly Job\"\n        assembly_job_info.Frames = 1\n        assembly_job_info.MachineLimit = 1\n\n        attr_values = self.get_attr_values_from_data(instance.data)\n        assembly_job_info.Priority = attr_values.get(\"tile_priority\",\n                                                     self.tile_priority)\n        assembly_job_info.TileJob = False\n\n        assembly_job_info.Pool = self.job_info.Pool\n\n        assembly_plugin_info = {\n            \"CleanupTiles\": 1,\n            \"ErrorOnMissing\": True,\n            \"Renderer\": self._instance.data[\"renderer\"]\n        }\n\n        assembly_payloads = []\n        output_dir = self.job_info.OutputDirectory[0]\n        config_files = []\n        for file in assembly_files:\n            frame = re.search(R_FRAME_NUMBER, file).group(\"frame\")\n\n            frame_assembly_job_info = copy.deepcopy(assembly_job_info)\n            frame_assembly_job_info.Name += \" (Frame {})\".format(frame)\n            frame_assembly_job_info.OutputFilename[0] = re.sub(\n                REPL_FRAME_NUMBER,\n                \"\\\\1{}\\\\3\".format(\"#\" * len(frame)), file)\n\n            file_hash = frame_file_hash[frame]\n            tile_job_id = frame_tile_job_id[frame]\n\n            frame_assembly_job_info.ExtraInfo[0] = file_hash\n            frame_assembly_job_info.ExtraInfo[1] = file\n            frame_assembly_job_info.JobDependencies.append(tile_job_id)\n            frame_assembly_job_info.Frames = frame\n\n            # write assembly job config files\n            config_file = os.path.join(\n                output_dir,\n                \"{}_config_{}.txt\".format(\n                    os.path.splitext(file)[0],\n                    datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n                )\n            )\n            config_files.append(config_file)\n            try:\n                if not os.path.isdir(output_dir):\n                    os.makedirs(output_dir)\n            except OSError:\n                # directory is not available\n                self.log.warning(\"Path is unreachable: \"\n                                 \"`{}`\".format(output_dir))\n\n            with open(config_file, \"w\") as cf:\n                print(\"TileCount={}\".format(tiles_count), file=cf)\n                print(\"ImageFileName={}\".format(file), file=cf)\n                print(\"ImageWidth={}\".format(\n                    instance.data.get(\"resolutionWidth\")), file=cf)\n                print(\"ImageHeight={}\".format(\n                    instance.data.get(\"resolutionHeight\")), file=cf)\n\n            reversed_y = False\n            if plugin_info[\"Renderer\"] == \"arnold\":\n                reversed_y = True\n\n            with open(config_file, \"a\") as cf:\n                # Need to reverse the order of the y tiles, because image\n                # coordinates are calculated from bottom left corner.\n                tiles = _format_tiles(\n                    file, 0,\n                    instance.data.get(\"tilesX\"),\n                    instance.data.get(\"tilesY\"),\n                    instance.data.get(\"resolutionWidth\"),\n                    instance.data.get(\"resolutionHeight\"),\n                    payload_plugin_info[\"OutputFilePrefix\"],\n                    reversed_y=reversed_y\n                )[1]\n                for k, v in sorted(tiles.items()):\n                    print(\"{}={}\".format(k, v), file=cf)\n\n            assembly_payloads.append(\n                self.assemble_payload(\n                    job_info=frame_assembly_job_info,\n                    plugin_info=assembly_plugin_info.copy(),\n                    # This would fail if the client machine and webserice are\n                    # using different storage paths.\n                    aux_files=[config_file]\n                )\n            )\n\n        # Submit assembly jobs\n        assembly_job_ids = []\n        num_assemblies = len(assembly_payloads)\n        for i, payload in enumerate(assembly_payloads):\n            self.log.debug(\n                \"submitting assembly job {} of {}\".format(i + 1,\n                                                          num_assemblies)\n            )\n            assembly_job_id = self.submit(\n                payload,\n                auth=auth,\n                verify=verify\n            )\n            assembly_job_ids.append(assembly_job_id)\n\n        instance.data[\"assemblySubmissionJobs\"] = assembly_job_ids\n\n        # Remove config files to avoid confusion about where data is coming\n        # from in Deadline.\n        for config_file in config_files:\n            os.remove(config_file)\n\n    def _get_maya_payload(self, data):\n\n        job_info = copy.deepcopy(self.job_info)\n        if not is_in_tests() and self.job_info.use_asset_dependencies:\n            # Asset dependency to wait for at least the scene file to sync.\n            job_info.AssetDependency += self.scene_path\n\n        # Get layer prefix\n        renderlayer = self._instance.data[\"setMembers\"]\n        renderer = self._instance.data[\"renderer\"]\n        layer_prefix_attr = RenderSettings.get_image_prefix_attr(renderer)\n        layer_prefix = get_attr_in_layer(layer_prefix_attr, layer=renderlayer)\n\n        plugin_info = copy.deepcopy(self.plugin_info)\n        plugin_info.update({\n            # Output directory and filename\n            \"OutputFilePath\": data[\"dirname\"].replace(\"\\\\\", \"/\"),\n            \"OutputFilePrefix\": layer_prefix,\n        })\n\n        # This hack is here because of how Deadline handles Renderman version.\n        # it considers everything with `renderman` set as version older than\n        # Renderman 22, and so if we are using renderman &gt; 21 we need to set\n        # renderer string on the job to `renderman22`. We will have to change\n        # this when Deadline releases new version handling this.\n        renderer = self._instance.data[\"renderer\"]\n        if renderer == \"renderman\":\n            try:\n                from rfm2.config import cfg  # noqa\n            except ImportError:\n                raise Exception(\"Cannot determine renderman version\")\n\n            rman_version = cfg().build_info.version()  # type: str\n            if int(rman_version.split(\".\")[0]) &gt; 22:\n                renderer = \"renderman22\"\n\n            plugin_info[\"Renderer\"] = renderer\n\n            # this is needed because renderman plugin in Deadline\n            # handles directory and file prefixes separately\n            plugin_info[\"OutputFilePath\"] = job_info.OutputDirectory[0]\n\n        return job_info, plugin_info\n\n    def _get_vray_export_payload(self, data):\n\n        job_info = copy.deepcopy(self.job_info)\n        job_info.Name = self._job_info_label(\"Export\")\n\n        # Get V-Ray settings info to compute output path\n        vray_scene = self.format_vray_output_filename()\n\n        plugin_info = {\n            \"Renderer\": \"vray\",\n            \"SkipExistingFrames\": True,\n            \"UseLegacyRenderLayers\": True,\n            \"OutputFilePath\": os.path.dirname(vray_scene)\n        }\n\n        return job_info, asdict(plugin_info)\n\n    def _get_vray_render_payload(self, data):\n\n        # Job Info\n        job_info = copy.deepcopy(self.job_info)\n        job_info.Name = self._job_info_label(\"Render\")\n        job_info.Plugin = \"Vray\"\n        job_info.OverrideTaskExtraInfoNames = False\n\n        # Plugin Info\n        plugin_info = VRayPluginInfo(\n            InputFilename=self.format_vray_output_filename(),\n            SeparateFilesPerFrame=False,\n            VRayEngine=\"V-Ray\",\n            Width=self._instance.data[\"resolutionWidth\"],\n            Height=self._instance.data[\"resolutionHeight\"],\n            OutputFilePath=job_info.OutputDirectory[0],\n            OutputFileName=job_info.OutputFilename[0]\n        )\n\n        return job_info, asdict(plugin_info)\n\n    def _get_arnold_render_payload(self, data):\n        # Job Info\n        job_info = copy.deepcopy(self.job_info)\n        job_info.Name = self._job_info_label(\"Render\")\n        job_info.Plugin = \"Arnold\"\n        job_info.OverrideTaskExtraInfoNames = False\n\n        # Plugin Info\n        ass_file, _ = os.path.splitext(data[\"output_filename_0\"])\n        ass_filepath = ass_file + \".ass\"\n\n        plugin_info = ArnoldPluginInfo(\n            ArnoldFile=ass_filepath\n        )\n\n        return job_info, asdict(plugin_info)\n\n    def format_vray_output_filename(self):\n        \"\"\"Format the expected output file of the Export job.\n\n        Example:\n            &lt;Scene&gt;/&lt;Scene&gt;_&lt;Layer&gt;/&lt;Layer&gt;\n            \"shot010_v006/shot010_v006_CHARS/CHARS_0001.vrscene\"\n        Returns:\n            str\n\n        \"\"\"\n        from maya import cmds\n        # \"vrayscene/&lt;Scene&gt;/&lt;Scene&gt;_&lt;Layer&gt;/&lt;Layer&gt;\"\n        vray_settings = cmds.ls(type=\"VRaySettingsNode\")\n        node = vray_settings[0]\n        template = cmds.getAttr(\"{}.vrscene_filename\".format(node))\n        scene, _ = os.path.splitext(self.scene_path)\n\n        def smart_replace(string, key_values):\n            new_string = string\n            for key, value in key_values.items():\n                new_string = new_string.replace(key, value)\n            return new_string\n\n        # Get workfile scene path without extension to format vrscene_filename\n        scene_filename = os.path.basename(self.scene_path)\n        scene_filename_no_ext, _ = os.path.splitext(scene_filename)\n\n        layer = self._instance.data['setMembers']\n\n        # Reformat without tokens\n        output_path = smart_replace(\n            template,\n            {\"&lt;Scene&gt;\": scene_filename_no_ext,\n             \"&lt;Layer&gt;\": layer})\n\n\n        start_frame = convert_frames_str_to_list(self.job_info.Frames)[0]\n        workspace = self._instance.context.data[\"workspace\"]\n        filename_zero = \"{}_{:04d}.vrscene\".format(output_path, start_frame)\n        filepath_zero = os.path.join(workspace, filename_zero)\n\n        return filepath_zero.replace(\"\\\\\", \"/\")\n\n    def _patch_workfile(self):\n        \"\"\"Patch Maya scene.\n\n        This will take list of patches (lines to add) and apply them to\n        *published* Maya  scene file (that is used later for rendering).\n\n        Patches are dict with following structure::\n            {\n                \"name\": \"Name of patch\",\n                \"regex\": \"regex of line before patch\",\n                \"line\": \"line to insert\"\n            }\n\n        \"\"\"\n        project_settings = self._instance.context.data[\"project_settings\"]\n        patches = (\n            project_settings.get(\n                \"deadline\", {}).get(\n                \"publish\", {}).get(\n                \"MayaSubmitDeadline\", {}).get(\n                \"scene_patches\", {})\n        )\n        if not patches:\n            return\n\n        if os.path.splitext(self.scene_path)[1].lower() != \".ma\":\n            self.log.debug(\"Skipping workfile patch since workfile is not \"\n                           \".ma file\")\n            return\n\n        compiled_regex = [re.compile(p[\"regex\"]) for p in patches]\n        with open(self.scene_path, \"r+\") as pf:\n            scene_data = pf.readlines()\n            for ln, line in enumerate(scene_data):\n                for i, r in enumerate(compiled_regex):\n                    if re.match(r, line):\n                        scene_data.insert(ln + 1, patches[i][\"line\"])\n                        pf.seek(0)\n                        pf.writelines(scene_data)\n                        pf.truncate()\n                        self.log.info(\"Applied {} patch to scene.\".format(\n                            patches[i][\"name\"]\n                        ))\n\n    def _job_info_label(self, label):\n        frames = convert_frames_str_to_list(self.job_info.Frames)\n        start_frame = frames[0]\n        end_frame = frames[-1]\n        return \"{label} {job.Name} [{start}-{end}]\".format(\n            label=label,\n            job=self.job_info,\n            start=start_frame,\n            end=end_frame,\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/maya/submit_maya_deadline.html#client.ayon_deadline.plugins.publish.maya.submit_maya_deadline.MayaSubmitDeadline.format_vray_output_filename","title":"<code>format_vray_output_filename()</code>","text":"<p>Format the expected output file of the Export job.</p> Example <p>/_/ \"shot010_v006/shot010_v006_CHARS/CHARS_0001.vrscene\" <p>Returns:     str</p> Source code in <code>client/ayon_deadline/plugins/publish/maya/submit_maya_deadline.py</code> <pre><code>def format_vray_output_filename(self):\n    \"\"\"Format the expected output file of the Export job.\n\n    Example:\n        &lt;Scene&gt;/&lt;Scene&gt;_&lt;Layer&gt;/&lt;Layer&gt;\n        \"shot010_v006/shot010_v006_CHARS/CHARS_0001.vrscene\"\n    Returns:\n        str\n\n    \"\"\"\n    from maya import cmds\n    # \"vrayscene/&lt;Scene&gt;/&lt;Scene&gt;_&lt;Layer&gt;/&lt;Layer&gt;\"\n    vray_settings = cmds.ls(type=\"VRaySettingsNode\")\n    node = vray_settings[0]\n    template = cmds.getAttr(\"{}.vrscene_filename\".format(node))\n    scene, _ = os.path.splitext(self.scene_path)\n\n    def smart_replace(string, key_values):\n        new_string = string\n        for key, value in key_values.items():\n            new_string = new_string.replace(key, value)\n        return new_string\n\n    # Get workfile scene path without extension to format vrscene_filename\n    scene_filename = os.path.basename(self.scene_path)\n    scene_filename_no_ext, _ = os.path.splitext(scene_filename)\n\n    layer = self._instance.data['setMembers']\n\n    # Reformat without tokens\n    output_path = smart_replace(\n        template,\n        {\"&lt;Scene&gt;\": scene_filename_no_ext,\n         \"&lt;Layer&gt;\": layer})\n\n\n    start_frame = convert_frames_str_to_list(self.job_info.Frames)[0]\n    workspace = self._instance.context.data[\"workspace\"]\n    filename_zero = \"{}_{:04d}.vrscene\".format(output_path, start_frame)\n    filepath_zero = os.path.join(workspace, filename_zero)\n\n    return filepath_zero.replace(\"\\\\\", \"/\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/nuke/index.html","title":"nuke","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/nuke/submit_nuke_deadline.html","title":"submit_nuke_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/nuke/submit_nuke_deadline.html#client.ayon_deadline.plugins.publish.nuke.submit_nuke_deadline.NukeSubmitDeadline","title":"<code>NukeSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code>, <code>AYONPyblishPluginMixin</code></p> <p>Submit write to Deadline</p> <p>Renders are submitted to a Deadline Web Service as supplied via settings key \"DEADLINE_REST_URL\".</p> Source code in <code>client/ayon_deadline/plugins/publish/nuke/submit_nuke_deadline.py</code> <pre><code>class NukeSubmitDeadline(\n    abstract_submit_deadline.AbstractSubmitDeadline,\n    AYONPyblishPluginMixin\n):\n    \"\"\"Submit write to Deadline\n\n    Renders are submitted to a Deadline Web Service as\n    supplied via settings key \"DEADLINE_REST_URL\".\n\n    \"\"\"\n\n    label = \"Submit Nuke to Deadline\"\n    order = pyblish.api.IntegratorOrder + 0.1\n    hosts = [\"nuke\"]\n    families = [\"render\", \"prerender\"]\n    optional = True\n    targets = [\"local\"]\n    settings_category = \"deadline\"\n\n    use_gpu = None\n    node_class_limit_groups = {}\n\n    def process(self, instance):\n        \"\"\"Plugin entry point.\"\"\"\n        if not instance.data.get(\"farm\"):\n            self.log.debug(\"Should not be processed on farm, skipping.\")\n            return\n\n        self._instance = instance\n\n        context = instance.context\n        self._deadline_url = instance.data[\"deadline\"][\"url\"]\n        assert self._deadline_url, \"Requires Deadline Webservice URL\"\n\n        # adding expected files to instance.data\n        write_node = instance.data[\"transientData\"][\"node\"]\n        render_path = instance.data[\"path\"]\n        start_frame = int(instance.data[\"frameStartHandle\"])\n        end_frame = int(instance.data[\"frameEndHandle\"])\n        self._expected_files(\n            instance,\n            render_path,\n            start_frame,\n            end_frame\n        )\n\n        job_info = self.get_generic_job_info(instance)\n        self.job_info = self.get_job_info(job_info=job_info)\n\n        self._set_scene_path(\n            context.data[\"currentFile\"],\n            job_info.use_published,\n            instance.data.get(\"stagingDir_is_custom\", False)\n        )\n\n        self._append_job_output_paths(\n            instance,\n            self.job_info\n        )\n\n        self.plugin_info = self.get_plugin_info(\n            scene_path=self.scene_path,\n            render_path=render_path,\n            write_node_name=write_node.name()\n        )\n\n        self.aux_files = self.get_aux_files()\n\n        plugin_info_data = instance.data[\"deadline\"][\"plugin_info_data\"]\n        if plugin_info_data:\n            self.apply_additional_plugin_info(plugin_info_data)\n\n        if instance.data[\"render_target\"] != \"frames_farm\":\n            job_id = self.process_submission()\n            self.log.info(\"Submitted job to Deadline: {}.\".format(job_id))\n\n            render_path = instance.data[\"path\"]\n            instance.data[\"outputDir\"] = os.path.dirname(\n                render_path).replace(\"\\\\\", \"/\")\n\n        if instance.data.get(\"bakingNukeScripts\"):\n            for baking_script in instance.data[\"bakingNukeScripts\"]:\n                self.job_info = copy.deepcopy(self.job_info)\n                self.job_info.JobType = \"Normal\"\n\n                response_data = instance.data.get(\"deadlineSubmissionJob\", {})\n                # frames_farm instance doesn't have render submission\n                if response_data.get(\"_id\"):\n                    self.job_info.BatchName = response_data[\"Props\"][\"Batch\"]\n                    self.job_info.JobDependencies.append(response_data[\"_id\"])\n\n                render_path = baking_script[\"bakeRenderPath\"]\n                scene_path = baking_script[\"bakeScriptPath\"]\n                write_node_name = baking_script[\"bakeWriteNodeName\"]\n\n                self.job_info.Name = os.path.basename(render_path)\n\n                # baking job shouldn't be split\n                self.job_info.ChunkSize = 999999\n\n                self.job_info.Frames = f\"{start_frame}-{end_frame}\"\n\n                self.plugin_info = self.get_plugin_info(\n                    scene_path=scene_path,\n                    render_path=render_path,\n                    write_node_name=write_node_name\n                )\n                job_id = self.process_submission()\n                self.log.info(\n                    \"Submitted baking job to Deadline: {}.\".format(job_id))\n\n                # add to list of job Id\n                if not instance.data.get(\"bakingSubmissionJobs\"):\n                    instance.data[\"bakingSubmissionJobs\"] = []\n\n                instance.data[\"bakingSubmissionJobs\"].append(job_id)\n\n    def get_job_info(self, job_info=None, **kwargs):\n        instance = self._instance\n\n        job_info.Plugin = \"Nuke\"\n\n        start_frame = int(instance.data[\"frameStartHandle\"])\n        end_frame = int(instance.data[\"frameEndHandle\"])\n        # already collected explicit values for rendered Frames\n        if not job_info.Frames:\n            job_info.Frames = \"{start}-{end}\".format(\n                start=start_frame,\n                end=end_frame\n            )\n        limit_groups = self._get_limit_groups(self.node_class_limit_groups)\n        job_info.LimitGroups.extend(limit_groups)\n\n        render_path = instance.data[\"path\"]\n        job_info.Name = os.path.basename(render_path)\n\n        return job_info\n\n    def get_plugin_info(\n            self, scene_path=None, render_path=None, write_node_name=None):\n        instance = self._instance\n        context = instance.context\n        version = re.search(r\"\\d+\\.\\d+\", context.data.get(\"hostVersion\"))\n\n        attribute_values = self.get_attr_values_from_data(instance.data)\n\n        render_dir = os.path.dirname(render_path)\n        plugin_info = NukePluginInfo(\n            SceneFile=scene_path,\n            Version=version.group(),\n            OutputFilePath=render_dir.replace(\"\\\\\", \"/\"),\n            ProjectPath=scene_path,\n            UseGpu=attribute_values[\"use_gpu\"],\n            WriteNode=write_node_name\n        )\n\n        plugin_payload: dict = asdict(plugin_info)\n        return plugin_payload\n\n    @classmethod\n    def get_attribute_defs(cls):\n        return [\n            BoolDef(\n                \"use_gpu\",\n                label=\"Use GPU\",\n                default=cls.use_gpu,\n            ),\n        ]\n\n    def _get_limit_groups(self, limit_groups):\n        \"\"\"Search for limit group nodes and return group name.\n        Limit groups will be defined as pairs in Nuke deadline submitter\n        presents where the key will be name of limit group and value will be\n        a list of plugin's node class names. Thus, when a plugin uses more\n        than one node, these will be captured and the triggered process\n        will add the appropriate limit group to the payload jobinfo attributes.\n        Returning:\n            list: captured groups list\n        \"\"\"\n        # Not all hosts can import this module.\n        import nuke\n\n        captured_groups = []\n        for limit_group in limit_groups:\n            lg_name = limit_group[\"name\"]\n\n            for node_class in limit_group[\"value\"]:\n                for node in nuke.allNodes(recurseGroups=True):\n                    # ignore all nodes not member of defined class\n                    if node.Class() not in node_class:\n                        continue\n                    # ignore all disabled nodes\n                    if node[\"disable\"].value():\n                        continue\n                    # add group name if not already added\n                    if lg_name not in captured_groups:\n                        captured_groups.append(lg_name)\n        return captured_groups\n\n    def _expected_files(\n        self,\n        instance,\n        filepath,\n        start_frame,\n        end_frame\n    ):\n        \"\"\" Create expected files in instance data\n        \"\"\"\n        if instance.data[\"render_target\"] == \"frames_farm\":\n            self.log.debug(\n                \"Expected files already collected for 'frames_farm', skipping.\"\n            )\n            return\n\n        if not instance.data.get(\"expectedFiles\"):\n            instance.data[\"expectedFiles\"] = []\n\n        dirname = os.path.dirname(filepath)\n        file = os.path.basename(filepath)\n\n        # since some files might be already tagged as publish_on_farm\n        # we need to avoid adding them to expected files since those would be\n        # duplicated into metadata.json file\n        representations = instance.data.get(\"representations\", [])\n        # check if file is not in representations with publish_on_farm tag\n        for repre in representations:\n            # Skip if 'publish_on_farm' not available\n            if \"publish_on_farm\" not in repre.get(\"tags\", []):\n                continue\n\n            # in case where single file (video, image) is already in\n            # representation file. Will be added to expected files via\n            # submit_publish_job.py\n            if file in repre.get(\"files\", []):\n                self.log.debug(\n                    \"Skipping expected file: {}\".format(filepath))\n                return\n\n        # in case path is hashed sequence expression\n        # (e.g. /path/to/file.####.png)\n        if \"#\" in file:\n            pparts = file.split(\"#\")\n            padding = \"%0{}d\".format(len(pparts) - 1)\n            file = pparts[0] + padding + pparts[-1]\n\n        # in case input path was single file (video or image)\n        if \"%\" not in file:\n            instance.data[\"expectedFiles\"].append(filepath)\n            return\n\n        # shift start frame by 1 if slate is present\n        if instance.data.get(\"slate\"):\n            start_frame -= 1\n\n        # add sequence files to expected files\n        for i in range(start_frame, (end_frame + 1)):\n            instance.data[\"expectedFiles\"].append(\n                os.path.join(dirname, (file % i)).replace(\"\\\\\", \"/\"))\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/nuke/submit_nuke_deadline.html#client.ayon_deadline.plugins.publish.nuke.submit_nuke_deadline.NukeSubmitDeadline.process","title":"<code>process(instance)</code>","text":"<p>Plugin entry point.</p> Source code in <code>client/ayon_deadline/plugins/publish/nuke/submit_nuke_deadline.py</code> <pre><code>def process(self, instance):\n    \"\"\"Plugin entry point.\"\"\"\n    if not instance.data.get(\"farm\"):\n        self.log.debug(\"Should not be processed on farm, skipping.\")\n        return\n\n    self._instance = instance\n\n    context = instance.context\n    self._deadline_url = instance.data[\"deadline\"][\"url\"]\n    assert self._deadline_url, \"Requires Deadline Webservice URL\"\n\n    # adding expected files to instance.data\n    write_node = instance.data[\"transientData\"][\"node\"]\n    render_path = instance.data[\"path\"]\n    start_frame = int(instance.data[\"frameStartHandle\"])\n    end_frame = int(instance.data[\"frameEndHandle\"])\n    self._expected_files(\n        instance,\n        render_path,\n        start_frame,\n        end_frame\n    )\n\n    job_info = self.get_generic_job_info(instance)\n    self.job_info = self.get_job_info(job_info=job_info)\n\n    self._set_scene_path(\n        context.data[\"currentFile\"],\n        job_info.use_published,\n        instance.data.get(\"stagingDir_is_custom\", False)\n    )\n\n    self._append_job_output_paths(\n        instance,\n        self.job_info\n    )\n\n    self.plugin_info = self.get_plugin_info(\n        scene_path=self.scene_path,\n        render_path=render_path,\n        write_node_name=write_node.name()\n    )\n\n    self.aux_files = self.get_aux_files()\n\n    plugin_info_data = instance.data[\"deadline\"][\"plugin_info_data\"]\n    if plugin_info_data:\n        self.apply_additional_plugin_info(plugin_info_data)\n\n    if instance.data[\"render_target\"] != \"frames_farm\":\n        job_id = self.process_submission()\n        self.log.info(\"Submitted job to Deadline: {}.\".format(job_id))\n\n        render_path = instance.data[\"path\"]\n        instance.data[\"outputDir\"] = os.path.dirname(\n            render_path).replace(\"\\\\\", \"/\")\n\n    if instance.data.get(\"bakingNukeScripts\"):\n        for baking_script in instance.data[\"bakingNukeScripts\"]:\n            self.job_info = copy.deepcopy(self.job_info)\n            self.job_info.JobType = \"Normal\"\n\n            response_data = instance.data.get(\"deadlineSubmissionJob\", {})\n            # frames_farm instance doesn't have render submission\n            if response_data.get(\"_id\"):\n                self.job_info.BatchName = response_data[\"Props\"][\"Batch\"]\n                self.job_info.JobDependencies.append(response_data[\"_id\"])\n\n            render_path = baking_script[\"bakeRenderPath\"]\n            scene_path = baking_script[\"bakeScriptPath\"]\n            write_node_name = baking_script[\"bakeWriteNodeName\"]\n\n            self.job_info.Name = os.path.basename(render_path)\n\n            # baking job shouldn't be split\n            self.job_info.ChunkSize = 999999\n\n            self.job_info.Frames = f\"{start_frame}-{end_frame}\"\n\n            self.plugin_info = self.get_plugin_info(\n                scene_path=scene_path,\n                render_path=render_path,\n                write_node_name=write_node_name\n            )\n            job_id = self.process_submission()\n            self.log.info(\n                \"Submitted baking job to Deadline: {}.\".format(job_id))\n\n            # add to list of job Id\n            if not instance.data.get(\"bakingSubmissionJobs\"):\n                instance.data[\"bakingSubmissionJobs\"] = []\n\n            instance.data[\"bakingSubmissionJobs\"].append(job_id)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/unreal/index.html","title":"unreal","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/unreal/submit_unreal_deadline.html","title":"submit_unreal_deadline","text":""},{"location":"autoapi/client/ayon_deadline/plugins/publish/unreal/submit_unreal_deadline.html#client.ayon_deadline.plugins.publish.unreal.submit_unreal_deadline.UnrealSubmitDeadline","title":"<code>UnrealSubmitDeadline</code>","text":"<p>               Bases: <code>AbstractSubmitDeadline</code></p> <p>Supports direct rendering of prepared Unreal project on Deadline (<code>render</code> product must be created with flag for Farm publishing) OR Perforce assisted rendering.</p> <p>For this Ayon server must contain <code>ayon-perforce</code> addon and provide configuration for it (P4 credentials etc.)!</p> Source code in <code>client/ayon_deadline/plugins/publish/unreal/submit_unreal_deadline.py</code> <pre><code>class UnrealSubmitDeadline(\n    abstract_submit_deadline.AbstractSubmitDeadline\n):\n    \"\"\"Supports direct rendering of prepared Unreal project on Deadline\n    (`render` product must be created with flag for Farm publishing) OR\n    Perforce assisted rendering.\n\n    For this Ayon server must contain `ayon-perforce` addon and provide\n    configuration for it (P4 credentials etc.)!\n    \"\"\"\n\n    label = \"Submit Unreal to Deadline\"\n    order = pyblish.api.IntegratorOrder + 0.1\n    hosts = [\"unreal\"]\n    families = [\"render.farm\"]  # cannot be \"render' as that is integrated\n    targets = [\"local\"]\n\n    def get_job_info(self, job_info=None):\n        instance = self._instance\n\n        job_info.BatchName = self._get_batch_name()\n        job_info.Plugin = \"UnrealEngine5\"\n\n        # already collected explicit values for rendered Frames\n        if (\n            not job_info.Frames\n            and instance.data[\"frameEnd\"] &gt; instance.data[\"frameStart\"]\n        ):\n            # Deadline requires integers in frame range\n            frame_range = \"{}-{}\".format(\n                int(round(instance.data[\"frameStart\"])),\n                int(round(instance.data[\"frameEnd\"])))\n            job_info.Frames = frame_range\n\n        return job_info\n\n    def get_plugin_info(self):\n        deadline_plugin_info = DeadlinePluginInfo()\n\n        render_path = self._instance.data[\"expectedFiles\"][0]\n        self._instance.data[\"outputDir\"] = os.path.dirname(render_path)\n        self._instance.context.data[\"version\"] = 1  #TODO\n\n        render_dir = os.path.dirname(render_path)\n        file_name = self._instance.data[\"file_names\"][0]\n        render_path = os.path.join(render_dir, file_name)\n\n        deadline_plugin_info.ProjectFile = self.scene_path\n        deadline_plugin_info.Output = render_path.replace(\"\\\\\", \"/\")\n\n        deadline_plugin_info.EditorExecutableName = \"UnrealEditor-Cmd.exe\"\n        deadline_plugin_info.EngineVersion = self._instance.data[\"app_version\"]\n        master_level = self._instance.data[\"master_level\"]\n        render_queue_path = self._instance.data[\"render_queue_path\"]\n        cmd_args = [\n            master_level,\n            \"-game\",\n            f\"-MoviePipelineConfig={render_queue_path}\",\n            \"-windowed\",\n            \"-Log\",\n            \"-StdOut\",\n            \"-allowStdOutLogVerbosity\",\n            \"-Unattended\",\n        ]\n        self.log.debug(f\"cmd-args::{cmd_args}\")\n        deadline_plugin_info.CommandLineArguments = \" \".join(cmd_args)\n\n        # if Perforce - triggered by active `changelist_metadata` instance!!\n        collected_perforce = self._get_perforce_info()\n        if collected_perforce:\n            perforce_data = (\n                self._instance.context.data.get(\"perforce\")\n                or self._instance.context.data.get(\"version_control\")\n            )\n            workspace_dir = perforce_data[\"workspace_dir\"]\n            stream = perforce_data[\"stream\"]\n            self._update_perforce_data(\n                self.scene_path,\n                workspace_dir,\n                stream,\n                collected_perforce[\"change_info\"][\"change\"],\n                deadline_plugin_info,\n            )\n\n        return asdict(deadline_plugin_info)\n\n    def from_published_scene(self, replace_in_path=True):\n        \"\"\" Do not overwrite expected files.\n\n            Use published is set to True, so rendering will be triggered\n            from published scene (in 'publish' folder). Default implementation\n            of abstract class renames expected (eg. rendered) files accordingly\n            which is not needed here.\n        \"\"\"\n        return super().from_published_scene(False)\n\n    def _get_batch_name(self):\n        \"\"\"Returns value that differentiate jobs in DL.\n\n        For automatic tests it adds timestamp, for Perforce driven change list\n        \"\"\"\n        batch_name = os.path.basename(self._instance.data[\"source\"])\n        if is_in_tests():\n            batch_name += datetime.now().strftime(\"%d%m%Y%H%M%S\")\n        collected_perforce = self._get_perforce_info()\n        if collected_perforce:\n            change = (collected_perforce[\"change_info\"][\"change\"])\n            batch_name = f\"{batch_name}_{change}\"\n        return batch_name\n\n    def _get_perforce_info(self):\n        \"\"\"Look if changelist_metadata is published to get change list info.\n\n        Context perforce dict contains universal connection info, instance\n        perforce contains detail about change list.\n        \"\"\"\n        change_list_version = {}\n        for inst in self._instance.context:\n            # get change info from `changelist_metadata` instance\n            inst_data = inst.data\n            change_list_version = (\n                inst_data.get(\"perforce\")\n                or inst_data.get(\"version_control\")  # backward compatibility\n            )\n            if change_list_version:\n                context_version = (\n                    self._instance.context.data.get(\"perforce\")\n                    or self._instance.context.data.get(\"version_control\")\n                )\n                change_list_version.update(context_version)\n                break\n        return change_list_version\n\n    def _update_perforce_data(\n        self,\n        scene_path,\n        workspace_dir,\n        stream,\n        change_list_id,\n        deadline_plugin_info,\n    ):\n        \"\"\"Adds Perforce metadata which causes DL pre job to sync to change.\n\n        It triggers only in presence of activated `changelist_metadata`\n        instance, which materialize info about commit. Artists could return\n        to any published commit and re-render if they choose.\n        `changelist_metadata` replaces `workfile` as there are no versioned\n        Unreal projects (because of size).\n        \"\"\"\n        # normalize paths, c:/ vs C:/\n        scene_path = str(Path(scene_path).resolve())\n        workspace_dir = str(Path(workspace_dir).resolve())\n\n        unreal_project_file_name = os.path.basename(scene_path)\n\n        unreal_project_hierarchy = self.scene_path.replace(workspace_dir, \"\")\n        unreal_project_hierarchy = (\n            unreal_project_hierarchy.replace(unreal_project_file_name, \"\"))\n        # relative path from workspace dir to last folder\n        unreal_project_hierarchy = unreal_project_hierarchy.strip(\"\\\\\")\n\n        deadline_plugin_info.ProjectFile = unreal_project_file_name\n\n        deadline_plugin_info.PerforceStream = stream\n        deadline_plugin_info.PerforceChangelist = change_list_id\n        deadline_plugin_info.PerforceGamePath = unreal_project_hierarchy\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/plugins/publish/unreal/submit_unreal_deadline.html#client.ayon_deadline.plugins.publish.unreal.submit_unreal_deadline.UnrealSubmitDeadline.from_published_scene","title":"<code>from_published_scene(replace_in_path=True)</code>","text":"<p>Do not overwrite expected files.</p> <p>Use published is set to True, so rendering will be triggered from published scene (in 'publish' folder). Default implementation of abstract class renames expected (eg. rendered) files accordingly which is not needed here.</p> Source code in <code>client/ayon_deadline/plugins/publish/unreal/submit_unreal_deadline.py</code> <pre><code>def from_published_scene(self, replace_in_path=True):\n    \"\"\" Do not overwrite expected files.\n\n        Use published is set to True, so rendering will be triggered\n        from published scene (in 'publish' folder). Default implementation\n        of abstract class renames expected (eg. rendered) files accordingly\n        which is not needed here.\n    \"\"\"\n    return super().from_published_scene(False)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/index.html","title":"repository","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/index.html","title":"custom","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/index.html","title":"plugins","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html","title":"GlobalJobPreLoad","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.OpenPypeVersion","title":"<code>OpenPypeVersion</code>","text":"<p>Fake semver version class for OpenPype version purposes.</p> <p>The version</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>class OpenPypeVersion:\n    \"\"\"Fake semver version class for OpenPype version purposes.\n\n    The version\n    \"\"\"\n    def __init__(self, major, minor, patch, prerelease, origin=None):\n        self.major = major\n        self.minor = minor\n        self.patch = patch\n        self.prerelease = prerelease\n\n        is_valid = True\n        if major is None or minor is None or patch is None:\n            is_valid = False\n        self.is_valid = is_valid\n\n        if origin is None:\n            base = \"{}.{}.{}\".format(str(major), str(minor), str(patch))\n            if not prerelease:\n                origin = base\n            else:\n                origin = \"{}-{}\".format(base, str(prerelease))\n\n        self.origin = origin\n\n    @classmethod\n    def from_string(cls, version):\n        \"\"\"Create an object of version from string.\n\n        Args:\n            version (str): Version as a string.\n\n        Returns:\n            Union[OpenPypeVersion, None]: Version object if input is nonempty\n                string otherwise None.\n        \"\"\"\n\n        if not version:\n            return None\n        valid_parts = VERSION_REGEX.findall(version)\n        if len(valid_parts) != 1:\n            # Return invalid version with filled 'origin' attribute\n            return cls(None, None, None, None, origin=str(version))\n\n        # Unpack found version\n        major, minor, patch, pre, post = valid_parts[0]\n        prerelease = pre\n        # Post release is not important anymore and should be considered as\n        #   part of prerelease\n        # - comparison is implemented to find suitable build and builds should\n        #       never contain prerelease part so \"not proper\" parsing is\n        #       acceptable for this use case.\n        if post:\n            prerelease = \"{}+{}\".format(pre, post)\n\n        return cls(\n            int(major), int(minor), int(patch), prerelease, origin=version\n        )\n\n    def has_compatible_release(self, other):\n        \"\"\"Version has compatible release as other version.\n\n        Both major and minor versions must be exactly the same. In that case\n        a build can be considered as release compatible with any version.\n\n        Args:\n            other (OpenPypeVersion): Other version.\n\n        Returns:\n            bool: Version is release compatible with other version.\n        \"\"\"\n\n        if self.is_valid and other.is_valid:\n            return self.major == other.major and self.minor == other.minor\n        return False\n\n    def __bool__(self):\n        return self.is_valid\n\n    def __repr__(self):\n        return \"&lt;{} {}&gt;\".format(self.__class__.__name__, self.origin)\n\n    def __eq__(self, other):\n        if not isinstance(other, self.__class__):\n            return self.origin == other\n        return self.origin == other.origin\n\n    def __lt__(self, other):\n        if not isinstance(other, self.__class__):\n            return None\n\n        if not self.is_valid:\n            return True\n\n        if not other.is_valid:\n            return False\n\n        if self.origin == other.origin:\n            return None\n\n        same_major = self.major == other.major\n        if not same_major:\n            return self.major &lt; other.major\n\n        same_minor = self.minor == other.minor\n        if not same_minor:\n            return self.minor &lt; other.minor\n\n        same_patch = self.patch == other.patch\n        if not same_patch:\n            return self.patch &lt; other.patch\n\n        if not self.prerelease:\n            return False\n\n        if not other.prerelease:\n            return True\n\n        pres = [self.prerelease, other.prerelease]\n        pres.sort()\n        return pres[0] == self.prerelease\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.OpenPypeVersion.from_string","title":"<code>from_string(version)</code>  <code>classmethod</code>","text":"<p>Create an object of version from string.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>str</code> <p>Version as a string.</p> required <p>Returns:</p> Type Description <p>Union[OpenPypeVersion, None]: Version object if input is nonempty string otherwise None.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>@classmethod\ndef from_string(cls, version):\n    \"\"\"Create an object of version from string.\n\n    Args:\n        version (str): Version as a string.\n\n    Returns:\n        Union[OpenPypeVersion, None]: Version object if input is nonempty\n            string otherwise None.\n    \"\"\"\n\n    if not version:\n        return None\n    valid_parts = VERSION_REGEX.findall(version)\n    if len(valid_parts) != 1:\n        # Return invalid version with filled 'origin' attribute\n        return cls(None, None, None, None, origin=str(version))\n\n    # Unpack found version\n    major, minor, patch, pre, post = valid_parts[0]\n    prerelease = pre\n    # Post release is not important anymore and should be considered as\n    #   part of prerelease\n    # - comparison is implemented to find suitable build and builds should\n    #       never contain prerelease part so \"not proper\" parsing is\n    #       acceptable for this use case.\n    if post:\n        prerelease = \"{}+{}\".format(pre, post)\n\n    return cls(\n        int(major), int(minor), int(patch), prerelease, origin=version\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.OpenPypeVersion.has_compatible_release","title":"<code>has_compatible_release(other)</code>","text":"<p>Version has compatible release as other version.</p> <p>Both major and minor versions must be exactly the same. In that case a build can be considered as release compatible with any version.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>OpenPypeVersion</code> <p>Other version.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Version is release compatible with other version.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>def has_compatible_release(self, other):\n    \"\"\"Version has compatible release as other version.\n\n    Both major and minor versions must be exactly the same. In that case\n    a build can be considered as release compatible with any version.\n\n    Args:\n        other (OpenPypeVersion): Other version.\n\n    Returns:\n        bool: Version is release compatible with other version.\n    \"\"\"\n\n    if self.is_valid and other.is_valid:\n        return self.major == other.major and self.minor == other.minor\n    return False\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.get_ayon_executable","title":"<code>get_ayon_executable()</code>","text":"<p>Return AYON Executable from Event Plug-in Settings</p> <p>Returns:</p> Type Description <p>list[str]: AYON executable paths.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>When no path configured at all.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>def get_ayon_executable():\n    \"\"\"Return AYON Executable from Event Plug-in Settings\n\n    Returns:\n        list[str]: AYON executable paths.\n\n    Raises:\n        RuntimeError: When no path configured at all.\n\n    \"\"\"\n    config = RepositoryUtils.GetPluginConfig(\"Ayon\")\n    exe_list = config.GetConfigEntryWithDefault(\"AyonExecutable\", \"\")\n\n    if not exe_list:\n        raise RuntimeError(\n            \"Path to AYON executable not configured.\"\n            \"Please set it in AYON Deadline Plugin.\"\n        )\n\n    # clean '\\ ' for MacOS pasting\n    if platform.system().lower() == \"darwin\":\n        exe_list = exe_list.replace(\"\\\\ \", \" \")\n\n    # Expand user paths\n    expanded_paths = []\n    for path in exe_list.split(\";\"):\n        if path.startswith(\"~\"):\n            path = os.path.expanduser(path)\n        expanded_paths.append(path)\n    return \";\".join(expanded_paths)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.get_openpype_executable","title":"<code>get_openpype_executable()</code>","text":"<p>Return OpenPype Executable from Event Plug-in Settings</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>def get_openpype_executable():\n    \"\"\"Return OpenPype Executable from Event Plug-in Settings\"\"\"\n    config = RepositoryUtils.GetPluginConfig(\"OpenPype\")\n    exe_list = config.GetConfigEntryWithDefault(\"OpenPypeExecutable\", \"\")\n    dir_list = config.GetConfigEntryWithDefault(\n        \"OpenPypeInstallationDirs\", \"\")\n\n    # clean '\\ ' for MacOS pasting\n    if platform.system().lower() == \"darwin\":\n        exe_list = exe_list.replace(\"\\\\ \", \" \")\n        dir_list = dir_list.replace(\"\\\\ \", \" \")\n    return exe_list, dir_list\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.get_openpype_version_from_path","title":"<code>get_openpype_version_from_path(path, build=True)</code>","text":"<p>Get OpenPype version from provided path.      path (str): Path to scan.      build (bool, optional): Get only builds, not sources</p> <p>Returns:</p> Type Description <p>Union[OpenPypeVersion, None]: version of OpenPype if found.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>def get_openpype_version_from_path(path, build=True):\n    \"\"\"Get OpenPype version from provided path.\n         path (str): Path to scan.\n         build (bool, optional): Get only builds, not sources\n\n    Returns:\n        Union[OpenPypeVersion, None]: version of OpenPype if found.\n    \"\"\"\n\n    # fix path for application bundle on macos\n    if platform.system().lower() == \"darwin\":\n        path = os.path.join(path, \"MacOS\")\n\n    version_file = os.path.join(path, \"openpype\", \"version.py\")\n    if not os.path.isfile(version_file):\n        return None\n\n    # skip if the version is not build\n    exe = os.path.join(path, \"openpype_console.exe\")\n    if platform.system().lower() in [\"linux\", \"darwin\"]:\n        exe = os.path.join(path, \"openpype_console\")\n\n    # if only builds are requested\n    if build and not os.path.isfile(exe):  # noqa: E501\n        print(\"   ! path is not a build: {}\".format(path))\n        return None\n\n    version = {}\n    with open(version_file, \"r\") as vf:\n        exec(vf.read(), version)\n\n    version_str = version.get(\"__version__\")\n    if version_str:\n        return OpenPypeVersion.from_string(version_str)\n    return None\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.handle_credentials","title":"<code>handle_credentials(job)</code>","text":"<p>Returns a tuple of values for AYON_SERVER_URL and AYON_API_KEY</p> <p>AYON_API_KEY might be overridden directly from job environments. Or specific AYON_SERVER_URL might be attached to job to pick corespondent AYON_API_KEY from plugin configuration.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>def handle_credentials(job):\n    \"\"\"Returns a tuple of values for AYON_SERVER_URL and AYON_API_KEY\n\n    AYON_API_KEY might be overridden directly from job environments.\n    Or specific AYON_SERVER_URL might be attached to job to pick corespondent\n    AYON_API_KEY from plugin configuration.\n    \"\"\"\n    config = RepositoryUtils.GetPluginConfig(\"Ayon\")\n    ayon_server_url = config.GetConfigEntryWithDefault(\"AyonServerUrl\", \"\")\n    ayon_api_key = config.GetConfigEntryWithDefault(\"AyonApiKey\", \"\")\n\n    job_ayon_server_url = job.GetJobEnvironmentKeyValue(\"AYON_SERVER_URL\")\n    job_ayon_api_key = job.GetJobEnvironmentKeyValue(\"AYON_API_KEY\")\n\n    # API key submitted with job environment will always take priority\n    if job_ayon_api_key:\n        ayon_api_key = job_ayon_api_key\n\n    # Allow custom AYON API key per server URL if server URL is submitted\n    # along with the job. The custom API keys can be configured on the\n    # Deadline Repository AYON Plug-in settings, in the format of\n    # `SERVER:PORT@APIKEY` per line.\n    elif job_ayon_server_url and job_ayon_server_url != ayon_server_url:\n        api_key = _get_ayon_api_key_from_additional_servers(\n            config, job_ayon_server_url)\n        if api_key:\n            ayon_api_key = api_key\n            print(\"&gt;&gt;&gt; Using API key from Additional AYON Servers.\")\n        else:\n            print(\n                \"&gt;&gt;&gt; AYON Server URL submitted with job \"\n                f\"'{job_ayon_server_url}' has no API key defined \"\n                \"in AYON Deadline plugin configuration,\"\n                \" `Additional AYON Servers` section.\"\n                \" Use Deadline monitor to modify the values.\"\n                \"Falling back to `AYON API key` set in `AYON Credentials`\"\n                \" section of AYON plugin configuration.\"\n            )\n        ayon_server_url = job_ayon_server_url\n    if not all([ayon_server_url, ayon_api_key]):\n        raise RuntimeError(\n            \"Missing required values for server url and api key. \"\n            \"Please fill in AYON Deadline plugin or provide by \"\n            \"AYON_SERVER_URL and AYON_API_KEY\"\n        )\n    return ayon_server_url, ayon_api_key\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.inject_ayon_environment","title":"<code>inject_ayon_environment(deadlinePlugin)</code>","text":"<p>Pull env vars from AYON and push them to rendering process.</p> <p>Used for correct paths, configuration from AYON etc.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>def inject_ayon_environment(deadlinePlugin):\n    \"\"\" Pull env vars from AYON and push them to rendering process.\n\n        Used for correct paths, configuration from AYON etc.\n    \"\"\"\n    job = deadlinePlugin.GetJob()\n\n    print(\"&gt;&gt;&gt; Injecting AYON environments ...\")\n    try:\n        exe_list = get_ayon_executable()\n        exe = FileUtils.SearchFileList(exe_list)\n\n        if not exe:\n            raise RuntimeError((\n               \"AYON executable was not found in the semicolon \"\n               \"separated list \\\"{}\\\".\"\n               \"The path to the render executable can be configured\"\n               \" from the Plugin Configuration in the Deadline Monitor.\"\n            ).format(exe_list))\n\n        print(\"--- AYON executable: {}\".format(exe))\n\n        ayon_bundle_name = job.GetJobEnvironmentKeyValue(\"AYON_BUNDLE_NAME\")\n        if not ayon_bundle_name:\n            raise RuntimeError(\n                \"Missing env var in job properties AYON_BUNDLE_NAME\"\n            )\n\n        ayon_server_url, ayon_api_key = handle_credentials(job)\n\n        site_id = os.environ.get(\"AYON_SITE_ID\")\n        shared_env_group = None\n        if site_id:\n            hash_base = f\"{site_id}|{getpass.getuser()}\"\n            hash_sha256 = sha256(hash_base.encode())\n            shared_env_group = hash_sha256.hexdigest()[-10:]\n        # drive caching of environment variables with env var\n        # it is recommended to use same value AYON_SITE_ID for 'same'\n        # render nodes (eg. same OS etc.)\n        if shared_env_group:\n            print(\"&gt;&gt;&gt; Caching of environment file will be used.\")\n            output_dir = _get_output_dir(job)\n            environment_file_name = f\"env_{job.JobId}_{shared_env_group}.json\"\n            export_dir_url = os.path.join(\n                output_dir,\n                \".ayon_env_cache\"\n            )\n\n            if not os.path.exists(export_dir_url):\n                os.makedirs(export_dir_url, exist_ok=True)\n\n            export_path = os.path.join(\n                export_dir_url,\n                environment_file_name)\n            _wait_for_in_progress(job, export_path)\n        else:\n            # no caching - default behavior\n            temp_file_name = \"{}_{}.json\".format(\n                datetime.utcnow().strftime(\"%Y%m%d%H%M%S%f\"),\n                str(uuid.uuid1())\n            )\n            export_path = os.path.join(tempfile.gettempdir(), temp_file_name)\n\n        if not os.path.exists(export_path):\n            print(\n                f\"&gt;&gt;&gt; '{export_path}' with extracted environment doesn't \"\n                \"exist yet, running extraction process...\"\n            )\n            temp_export_path = f\"{export_path}.tmp\"\n            with open(temp_export_path, \"w\"):\n                pass\n            try:\n                _extract_environments(\n                    ayon_server_url,\n                    ayon_api_key,\n                    ayon_bundle_name,\n                    deadlinePlugin,\n                    exe,\n                    temp_export_path,\n                    job\n                )\n                if (not os.path.exists(export_path) and\n                        os.path.exists(temp_export_path)):\n                    print(f\"Creating env var file {export_path}\")\n                    os.rename(temp_export_path, export_path)\n            finally:\n                if os.path.exists(temp_export_path):\n                    os.remove(temp_export_path)\n\n        print(f\"&gt;&gt;&gt; Loading file '{export_path}' ...\")\n        with open(export_path) as fp:\n            contents = json.load(fp)\n\n        for key, value in sorted(contents.items()):\n            deadlinePlugin.SetProcessEnvironmentVariable(key, value)\n\n        if \"PATH\" in contents:\n            # Set os.environ[PATH] so studio settings' path entries\n            # can be used to define search path for executables.\n            print(f\"&gt;&gt;&gt; Setting 'PATH' Environment to: {contents['PATH']}\")\n            os.environ[\"PATH\"] = contents[\"PATH\"]\n\n        script_url = job.GetJobPluginInfoKeyValue(\"ScriptFilename\")\n        if script_url:\n            script_url = script_url.format(**contents).replace(\"\\\\\", \"/\")\n            print(\"&gt;&gt;&gt; Setting script path {}\".format(script_url))\n            job.SetJobPluginInfoKeyValue(\"ScriptFilename\", script_url)\n\n        print(\"&gt;&gt; Injection end.\")\n    except Exception as e:\n        if hasattr(e, \"output\"):\n            print(\"&gt;&gt;&gt; Exception {}\".format(e.output))\n        import traceback\n        print(traceback.format_exc())\n        print(\"!!! Injection failed.\")\n        raise\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.inject_openpype_environment","title":"<code>inject_openpype_environment(deadlinePlugin)</code>","text":"<p>Pull env vars from OpenPype and push them to rendering process.</p> <p>Used for correct paths, configuration from OpenPype etc.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>def inject_openpype_environment(deadlinePlugin):\n    \"\"\" Pull env vars from OpenPype and push them to rendering process.\n\n        Used for correct paths, configuration from OpenPype etc.\n    \"\"\"\n    job = deadlinePlugin.GetJob()\n\n    print(\"&gt;&gt;&gt; Injecting OpenPype environments ...\")\n    try:\n        exe_list, dir_list = get_openpype_executable()\n        exe = FileUtils.SearchFileList(exe_list)\n\n        requested_version = job.GetJobEnvironmentKeyValue(\"OPENPYPE_VERSION\")\n        if requested_version:\n            exe = get_requested_openpype_executable(\n                exe, dir_list, requested_version\n            )\n            if exe is None:\n                raise RuntimeError((\n                    \"Cannot find compatible version available for version {}\"\n                    \" requested by the job. Please add it through plugin\"\n                    \" configuration in Deadline or install it to configured\"\n                    \" directory.\"\n                ).format(requested_version))\n\n        if not exe:\n            raise RuntimeError((\n                \"OpenPype executable was not found in the semicolon \"\n                \"separated list \\\"{}\\\".\"\n                \"The path to the render executable can be configured\"\n                \" from the Plugin Configuration in the Deadline Monitor.\"\n            ).format(\";\".join(exe_list)))\n\n        print(\"--- OpenPype executable: {}\".format(exe))\n\n        # tempfile.TemporaryFile cannot be used because of locking\n        temp_file_name = \"{}_{}.json\".format(\n            datetime.utcnow().strftime(\"%Y%m%d%H%M%S%f\"),\n            str(uuid.uuid1())\n        )\n        export_path = os.path.join(tempfile.gettempdir(), temp_file_name)\n        print(\"&gt;&gt;&gt; Temporary path: {}\".format(export_path))\n\n        args = [\n            \"--headless\",\n            \"extractenvironments\",\n            export_path\n        ]\n\n        add_kwargs = {\n            \"project\": job.GetJobEnvironmentKeyValue(\"AVALON_PROJECT\"),\n            \"asset\": job.GetJobEnvironmentKeyValue(\"AVALON_ASSET\"),\n            \"task\": job.GetJobEnvironmentKeyValue(\"AVALON_TASK\"),\n            \"app\": job.GetJobEnvironmentKeyValue(\"AVALON_APP_NAME\"),\n            \"envgroup\": \"farm\"\n        }\n\n        # use legacy IS_TEST env var to mark automatic tests for OP\n        if job.GetJobEnvironmentKeyValue(\"IS_TEST\"):\n            args.append(\"--automatic-tests\")\n\n        if all(add_kwargs.values()):\n            for key, value in add_kwargs.items():\n                args.extend([\"--{}\".format(key), value])\n        else:\n            raise RuntimeError((\n                \"Missing required env vars: AVALON_PROJECT, AVALON_ASSET,\"\n                \" AVALON_TASK, AVALON_APP_NAME\"\n            ))\n\n        openpype_mongo = job.GetJobEnvironmentKeyValue(\"OPENPYPE_MONGO\")\n        if openpype_mongo:\n            # inject env var for OP extractenvironments\n            # SetEnvironmentVariable is important, not SetProcessEnv...\n            deadlinePlugin.SetEnvironmentVariable(\"OPENPYPE_MONGO\",\n                                                  openpype_mongo)\n\n        if not os.environ.get(\"OPENPYPE_MONGO\"):\n            print(\"&gt;&gt;&gt; Missing OPENPYPE_MONGO env var, process won't work\")\n\n        os.environ[\"AVALON_TIMEOUT\"] = \"5000\"\n\n        args_str = subprocess.list2cmdline(args)\n        print(\"&gt;&gt;&gt; Executing: {} {}\".format(exe, args_str))\n        process_exitcode = deadlinePlugin.RunProcess(\n            exe, args_str, os.path.dirname(exe), -1\n        )\n\n        if process_exitcode != 0:\n            raise RuntimeError(\n                \"Failed to run OpenPype process to extract environments.\"\n            )\n\n        print(\"&gt;&gt;&gt; Loading file ...\")\n        with open(export_path) as fp:\n            contents = json.load(fp)\n\n        for key, value in sorted(contents.items()):\n            deadlinePlugin.SetProcessEnvironmentVariable(key, value)\n\n        if \"PATH\" in contents:\n            # Set os.environ[PATH] so studio settings' path entries\n            # can be used to define search path for executables.\n            print(f\"&gt;&gt;&gt; Setting 'PATH' Environment to: {contents['PATH']}\")\n            os.environ[\"PATH\"] = contents[\"PATH\"]\n\n        script_url = job.GetJobPluginInfoKeyValue(\"ScriptFilename\")\n        if script_url:\n            script_url = script_url.format(**contents).replace(\"\\\\\", \"/\")\n            print(\"&gt;&gt;&gt; Setting script path {}\".format(script_url))\n            job.SetJobPluginInfoKeyValue(\"ScriptFilename\", script_url)\n\n        print(\"&gt;&gt;&gt; Removing temporary file\")\n        os.remove(export_path)\n\n        print(\"&gt;&gt; Injection end.\")\n    except Exception as e:\n        if hasattr(e, \"output\"):\n            print(\"&gt;&gt;&gt; Exception {}\".format(e.output))\n        import traceback\n        print(traceback.format_exc())\n        print(\"!!! Injection failed.\")\n        raise\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.html#client.ayon_deadline.repository.custom.plugins.GlobalJobPreLoad.inject_render_job_id","title":"<code>inject_render_job_id(deadlinePlugin)</code>","text":"<p>Inject dependency ids to publish process as env var for validation.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/GlobalJobPreLoad.py</code> <pre><code>def inject_render_job_id(deadlinePlugin):\n    \"\"\"Inject dependency ids to publish process as env var for validation.\"\"\"\n    print(\"&gt;&gt;&gt; Injecting render job id ...\")\n    job = deadlinePlugin.GetJob()\n\n    dependency_ids = job.JobDependencyIDs\n    print(\"&gt;&gt;&gt; Dependency IDs: {}\".format(dependency_ids))\n    render_job_ids = \",\".join(dependency_ids)\n    deadlinePlugin.SetProcessEnvironmentVariable(\n        \"RENDER_JOB_IDS\", render_job_ids\n    )\n\n    ayon_server_url, ayon_api_key = handle_credentials(job)\n\n    credentials = {\n        \"AYON_SERVER_URL\": ayon_server_url,\n        \"AYON_API_KEY\": ayon_api_key\n    }\n    for env, val in credentials.items():\n        job.SetJobEnvironmentKeyValue(env, val)\n    print(\"&gt;&gt;&gt; Injection end.\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/Ayon/index.html","title":"Ayon","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/Ayon/Ayon.html","title":"Ayon","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/Ayon/Ayon.html#client.ayon_deadline.repository.custom.plugins.Ayon.Ayon.AyonDeadlinePlugin","title":"<code>AyonDeadlinePlugin</code>","text":"<p>               Bases: <code>DeadlinePlugin</code></p> <p>Standalone plugin for publishing from AYON</p> <p>Calls Ayonexecutable 'ayon_console' from first correctly found file based on plugin configuration. Uses 'publish' command and passes path to metadata json file, which contains all needed information for publish process.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/Ayon/Ayon.py</code> <pre><code>class AyonDeadlinePlugin(DeadlinePlugin):\n    \"\"\"\n        Standalone plugin for publishing from AYON\n\n        Calls Ayonexecutable 'ayon_console' from first correctly found\n        file based on plugin configuration. Uses 'publish' command and passes\n        path to metadata json file, which contains all needed information\n        for publish process.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self.InitializeProcessCallback += self.InitializeProcess\n        self.RenderExecutableCallback += self.RenderExecutable\n        self.RenderArgumentCallback += self.RenderArgument\n\n    def Cleanup(self):\n        for stdoutHandler in self.StdoutHandlers:\n            del stdoutHandler.HandleCallback\n\n        del self.InitializeProcessCallback\n        del self.RenderExecutableCallback\n        del self.RenderArgumentCallback\n\n    def InitializeProcess(self):\n        self.LogInfo(\n            \"Initializing process with AYON plugin {}\".format(__version__)\n        )\n        self.PluginType = PluginType.Simple\n        self.StdoutHandling = True\n\n        self.SingleFramesOnly = self.GetBooleanPluginInfoEntryWithDefault(\n            \"SingleFramesOnly\", False)\n        self.LogInfo(\"Single Frames Only: %s\" % self.SingleFramesOnly)\n\n        self.AddStdoutHandlerCallback(\n            \".*Progress: (\\\\d+)%.*\").HandleCallback += self.HandleProgress\n\n    def RenderExecutable(self):\n        job = self.GetJob()\n\n        # set required env vars for AYON\n        # cannot be in InitializeProcess as it is too soon\n        config = RepositoryUtils.GetPluginConfig(\"Ayon\")  # plugin name stays\n        ayon_server_url = (\n            job.GetJobEnvironmentKeyValue(\"AYON_SERVER_URL\")\n            or config.GetConfigEntryWithDefault(\"AyonServerUrl\", \"\")\n        )\n        ayon_api_key = (\n            job.GetJobEnvironmentKeyValue(\"AYON_API_KEY\")\n            or config.GetConfigEntryWithDefault(\"AyonApiKey\", \"\")\n        )\n\n        ayon_bundle_name = job.GetJobEnvironmentKeyValue(\"AYON_BUNDLE_NAME\")\n\n        environment = {\n            \"AYON_SERVER_URL\": ayon_server_url,\n            \"AYON_API_KEY\": ayon_api_key,\n            \"AYON_BUNDLE_NAME\": ayon_bundle_name,\n        }\n\n        for env, val in environment.items():\n            self.SetEnvironmentVariable(env, val)\n\n        exe_list = self.GetConfigEntry(\"AyonExecutable\")\n        # clean '\\ ' for MacOS pasting\n        if platform.system().lower() == \"darwin\":\n            exe_list = exe_list.replace(\"\\\\ \", \" \")\n\n        expanded_paths = []\n        for path in exe_list.split(\";\"):\n            if path.startswith(\"~\"):\n                path = os.path.expanduser(path)\n            expanded_paths.append(path)\n        exe = FileUtils.SearchFileList(\";\".join(expanded_paths))\n\n        if exe == \"\":\n            self.FailRender(\n                \"AYON executable was not found in the semicolon separated \"\n                \"list: \\\"{}\\\". The path to the render executable can be \"\n                \"configured from the Plugin Configuration in the Deadline \"\n                \"Monitor.\".format(exe_list)\n            )\n        return exe\n\n    def RenderArgument(self):\n        arguments = str(self.GetPluginInfoEntryWithDefault(\"Arguments\", \"\"))\n        arguments = RepositoryUtils.CheckPathMapping(arguments)\n\n        arguments = re.sub(r\"&lt;(?i)STARTFRAME&gt;\", str(self.GetStartFrame()),\n                           arguments)\n        arguments = re.sub(r\"&lt;(?i)ENDFRAME&gt;\", str(self.GetEndFrame()),\n                           arguments)\n        arguments = re.sub(r\"&lt;(?i)QUOTE&gt;\", \"\\\"\", arguments)\n\n        arguments = self.ReplacePaddedFrame(arguments,\n                                            \"&lt;(?i)STARTFRAME%([0-9]+)&gt;\",\n                                            self.GetStartFrame())\n        arguments = self.ReplacePaddedFrame(arguments,\n                                            \"&lt;(?i)ENDFRAME%([0-9]+)&gt;\",\n                                            self.GetEndFrame())\n\n        count = 0\n        for filename in self.GetAuxiliaryFilenames():\n            localAuxFile = Path.Combine(self.GetJobsDataDirectory(), filename)\n            arguments = re.sub(r\"&lt;(?i)AUXFILE\" + str(count) + r\"&gt;\",\n                               localAuxFile.replace(\"\\\\\", \"/\"), arguments)\n            count += 1\n\n        return arguments\n\n    def ReplacePaddedFrame(self, arguments, pattern, frame):\n        frameRegex = Regex(pattern)\n        while True:\n            frameMatch = frameRegex.Match(arguments)\n            if not frameMatch.Success:\n                break\n            paddingSize = int(frameMatch.Groups[1].Value)\n            if paddingSize &gt; 0:\n                padding = StringUtils.ToZeroPaddedString(\n                    frame, paddingSize, False)\n            else:\n                padding = str(frame)\n            arguments = arguments.replace(\n                frameMatch.Groups[0].Value, padding)\n\n        return arguments\n\n    def HandleProgress(self):\n        progress = float(self.GetRegexMatch(1))\n        self.SetProgress(progress)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/CelAction/index.html","title":"CelAction","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/CelAction/CelAction.html","title":"CelAction","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/HarmonyAYON/index.html","title":"HarmonyAYON","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/HarmonyAYON/HarmonyAYON.html","title":"HarmonyAYON","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/index.html","title":"UnrealEngine5","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html","title":"DeadlineRPC","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager","title":"<code>BaseDeadlineRPCJobManager</code>","text":"<p>This is a base class for exposing commonly used deadline function on RPC</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>class BaseDeadlineRPCJobManager:\n    \"\"\"\n    This is a base class for exposing commonly used deadline function on RPC\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Constructor\n        \"\"\"\n        # get the instance of the deadline plugin from the python globals\n        self._deadline_plugin = self.__get_instance_from_globals()\n\n        # Get the current running job\n        self._job = self._deadline_plugin.GetJob()\n        self._is_connected = False\n\n        # Track all completed tasks\n        self._completed_tasks = set()\n\n    def connect(self):\n        \"\"\"\n        First mode of contact to the rpc server. It is very critical the\n        client calls this function first as it will let the Deadline process\n        know a client has connected and to wait on the task to complete.\n        Else, Deadline will assume the connection was never made and requeue\n        the job after a few minutes\n        :return: bool representing the connection\n        \"\"\"\n        self._is_connected = True\n        print(\"Server connection established!\")\n        return self._is_connected\n\n    def is_connected(self):\n        \"\"\"\n        Returns the connection status to a client\n        :return:\n        \"\"\"\n        return self._is_connected\n\n    def is_task_complete(self, task_id):\n        \"\"\"\n        Checks and returns if a task has been marked as complete\n        :param task_id: job task id\n        :return: return True/False if the task id is present\n        \"\"\"\n        return task_id in self._completed_tasks\n\n    @staticmethod\n    def __get_instance_from_globals():\n        \"\"\"\n        Get the instance of the Deadline plugin from the python globals.\n        Since this class is executed in a thread, this was the best method to\n        get the plugin instance to the class without pass it though several\n        layers of abstraction\n        :return:\n        \"\"\"\n        import __main__\n\n        try:\n            return __main__.__deadline_plugin_instance__\n        except AttributeError as err:\n            raise RuntimeError(\n                f\"Could not get deadline plugin instance from globals. \"\n                f\"\\n\\tError: {err}\"\n            )\n\n    def get_job_id(self):\n        \"\"\"\n        Returns the current JobID\n        :return: Job ID\n        \"\"\"\n        return self._job.JobId\n\n    def get_task_frames(self):\n        \"\"\"\n        Returns the frames rendered by ths task\n        :return:\n        \"\"\"\n        return [\n            self._deadline_plugin.GetStartFrame(),\n            self._deadline_plugin.GetEndFrame()\n        ]\n\n    def get_job_extra_info_key_value(self, name):\n        \"\"\"\n        Returns the value of a key in the job extra info property\n        :param name: Extra Info Key\n        :return: Returns Extra Info Value\n        \"\"\"\n        # This function is probably the most important function in the class.\n        # This allows you to store different types of data and retrieve the\n        # data from the other side. This is what makes the Unreal plugin a bit\n        # more feature/task agnostic\n        return self._job.GetJobExtraInfoKeyValue(name)\n\n    def fail_render(self, message):\n        \"\"\"\n        Fail a render job with a message\n        :param message: Failure message\n        \"\"\"\n        self._deadline_plugin.FailRender(message.strip(\"\\n\"))\n        return True\n\n    def set_status_message(self, message):\n        \"\"\"\n        Sets the message on the job status\n        :param message: Status Message\n        \"\"\"\n        self._deadline_plugin.SetStatusMessage(message)\n        return True\n\n    def set_progress(self, progress):\n        \"\"\"\n        Sets the job progress\n        :param progress: job progress\n        \"\"\"\n        self._deadline_plugin.SetProgress(progress)\n        return True\n\n    def log_warning(self, message):\n        \"\"\"\n        Logs a warning message\n        :param message: Log message\n        \"\"\"\n        self._deadline_plugin.LogWarning(message)\n        return True\n\n    def log_info(self, message):\n        \"\"\"\n        Logs an informational message\n        :param message: Log message\n        \"\"\"\n        self._deadline_plugin.LogInfo(message)\n        return True\n\n    def get_task_id(self):\n        \"\"\"\n        Returns the current Task ID\n        :return:\n        \"\"\"\n        return self._deadline_plugin.GetCurrentTaskId()\n\n    def get_job_user(self):\n        \"\"\"\n        Return the job user\n        :return:\n        \"\"\"\n        return self._job.JobUserName\n\n    def complete_task(self, task_id):\n        \"\"\"\n        Marks a task as complete. This function should be called when a task\n        is complete. This will allow the Deadline render taskl process to end\n        and get the next render task. If this is not called, deadline will\n        render the task indefinitely\n        :param task_id: Task ID to mark as complete\n        :return:\n        \"\"\"\n        self._completed_tasks.add(task_id)\n        return True\n\n    def update_job_output_filenames(self, filenames):\n        \"\"\"\n        Updates the file names for the current job\n        :param list filenames: list of filenames\n        \"\"\"\n        if not isinstance(filenames, list):\n            filenames = list(filenames)\n\n        self._deadline_plugin.LogInfo(\n            \"Setting job filenames: {filename}\".format(\n                filename=\", \".join(filenames)\n            )\n        )\n\n        # Set the file names on the job\n        RepositoryUtils.UpdateJobOutputFileNames(self._job, filenames)\n\n        # Make sure to save the settings just in case\n        RepositoryUtils.SaveJob(self._job)\n\n    def update_job_output_directories(self, directories):\n        \"\"\"\n        Updates the output directories on job\n        :param list directories: List of directories\n        \"\"\"\n        if not isinstance(directories, list):\n            directories = list(directories)\n\n        self._deadline_plugin.LogInfo(\n            \"Setting job directories: {directories}\".format(\n                directories=\", \".join(directories)\n            )\n        )\n\n        # Set the directory on the job\n        RepositoryUtils.SetJobOutputDirectories(self._job, directories)\n\n        # Make sure to save the settings just in case\n        RepositoryUtils.SaveJob(self._job)\n\n    def check_path_mappings(self, paths):\n        \"\"\"\n        Resolves any path mappings set on input path\n        :param [str] paths: Path string with tokens\n        :return: Resolved path mappings\n        \"\"\"\n        if not isinstance(paths, list):\n            paths = list(paths)\n\n        # Deadline returns a System.String[] object here. Convert to a proper\n        # list\n        path_mapped_strings = RepositoryUtils.CheckPathMappingForMultiplePaths(\n            paths,\n            forceSeparator=\"/\",\n            verbose=False\n        )\n\n        return [str(path) for path in path_mapped_strings]\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.__get_instance_from_globals","title":"<code>__get_instance_from_globals()</code>  <code>staticmethod</code>","text":"<p>Get the instance of the Deadline plugin from the python globals. Since this class is executed in a thread, this was the best method to get the plugin instance to the class without pass it though several layers of abstraction :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>@staticmethod\ndef __get_instance_from_globals():\n    \"\"\"\n    Get the instance of the Deadline plugin from the python globals.\n    Since this class is executed in a thread, this was the best method to\n    get the plugin instance to the class without pass it though several\n    layers of abstraction\n    :return:\n    \"\"\"\n    import __main__\n\n    try:\n        return __main__.__deadline_plugin_instance__\n    except AttributeError as err:\n        raise RuntimeError(\n            f\"Could not get deadline plugin instance from globals. \"\n            f\"\\n\\tError: {err}\"\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.__init__","title":"<code>__init__()</code>","text":"<p>Constructor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Constructor\n    \"\"\"\n    # get the instance of the deadline plugin from the python globals\n    self._deadline_plugin = self.__get_instance_from_globals()\n\n    # Get the current running job\n    self._job = self._deadline_plugin.GetJob()\n    self._is_connected = False\n\n    # Track all completed tasks\n    self._completed_tasks = set()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.check_path_mappings","title":"<code>check_path_mappings(paths)</code>","text":"<p>Resolves any path mappings set on input path :param [str] paths: Path string with tokens :return: Resolved path mappings</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def check_path_mappings(self, paths):\n    \"\"\"\n    Resolves any path mappings set on input path\n    :param [str] paths: Path string with tokens\n    :return: Resolved path mappings\n    \"\"\"\n    if not isinstance(paths, list):\n        paths = list(paths)\n\n    # Deadline returns a System.String[] object here. Convert to a proper\n    # list\n    path_mapped_strings = RepositoryUtils.CheckPathMappingForMultiplePaths(\n        paths,\n        forceSeparator=\"/\",\n        verbose=False\n    )\n\n    return [str(path) for path in path_mapped_strings]\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.complete_task","title":"<code>complete_task(task_id)</code>","text":"<p>Marks a task as complete. This function should be called when a task is complete. This will allow the Deadline render taskl process to end and get the next render task. If this is not called, deadline will render the task indefinitely :param task_id: Task ID to mark as complete :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def complete_task(self, task_id):\n    \"\"\"\n    Marks a task as complete. This function should be called when a task\n    is complete. This will allow the Deadline render taskl process to end\n    and get the next render task. If this is not called, deadline will\n    render the task indefinitely\n    :param task_id: Task ID to mark as complete\n    :return:\n    \"\"\"\n    self._completed_tasks.add(task_id)\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.connect","title":"<code>connect()</code>","text":"<p>First mode of contact to the rpc server. It is very critical the client calls this function first as it will let the Deadline process know a client has connected and to wait on the task to complete. Else, Deadline will assume the connection was never made and requeue the job after a few minutes :return: bool representing the connection</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def connect(self):\n    \"\"\"\n    First mode of contact to the rpc server. It is very critical the\n    client calls this function first as it will let the Deadline process\n    know a client has connected and to wait on the task to complete.\n    Else, Deadline will assume the connection was never made and requeue\n    the job after a few minutes\n    :return: bool representing the connection\n    \"\"\"\n    self._is_connected = True\n    print(\"Server connection established!\")\n    return self._is_connected\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.fail_render","title":"<code>fail_render(message)</code>","text":"<p>Fail a render job with a message :param message: Failure message</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def fail_render(self, message):\n    \"\"\"\n    Fail a render job with a message\n    :param message: Failure message\n    \"\"\"\n    self._deadline_plugin.FailRender(message.strip(\"\\n\"))\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.get_job_extra_info_key_value","title":"<code>get_job_extra_info_key_value(name)</code>","text":"<p>Returns the value of a key in the job extra info property :param name: Extra Info Key :return: Returns Extra Info Value</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def get_job_extra_info_key_value(self, name):\n    \"\"\"\n    Returns the value of a key in the job extra info property\n    :param name: Extra Info Key\n    :return: Returns Extra Info Value\n    \"\"\"\n    # This function is probably the most important function in the class.\n    # This allows you to store different types of data and retrieve the\n    # data from the other side. This is what makes the Unreal plugin a bit\n    # more feature/task agnostic\n    return self._job.GetJobExtraInfoKeyValue(name)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.get_job_id","title":"<code>get_job_id()</code>","text":"<p>Returns the current JobID :return: Job ID</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def get_job_id(self):\n    \"\"\"\n    Returns the current JobID\n    :return: Job ID\n    \"\"\"\n    return self._job.JobId\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.get_job_user","title":"<code>get_job_user()</code>","text":"<p>Return the job user :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def get_job_user(self):\n    \"\"\"\n    Return the job user\n    :return:\n    \"\"\"\n    return self._job.JobUserName\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.get_task_frames","title":"<code>get_task_frames()</code>","text":"<p>Returns the frames rendered by ths task :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def get_task_frames(self):\n    \"\"\"\n    Returns the frames rendered by ths task\n    :return:\n    \"\"\"\n    return [\n        self._deadline_plugin.GetStartFrame(),\n        self._deadline_plugin.GetEndFrame()\n    ]\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.get_task_id","title":"<code>get_task_id()</code>","text":"<p>Returns the current Task ID :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def get_task_id(self):\n    \"\"\"\n    Returns the current Task ID\n    :return:\n    \"\"\"\n    return self._deadline_plugin.GetCurrentTaskId()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.is_connected","title":"<code>is_connected()</code>","text":"<p>Returns the connection status to a client :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def is_connected(self):\n    \"\"\"\n    Returns the connection status to a client\n    :return:\n    \"\"\"\n    return self._is_connected\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.is_task_complete","title":"<code>is_task_complete(task_id)</code>","text":"<p>Checks and returns if a task has been marked as complete :param task_id: job task id :return: return True/False if the task id is present</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def is_task_complete(self, task_id):\n    \"\"\"\n    Checks and returns if a task has been marked as complete\n    :param task_id: job task id\n    :return: return True/False if the task id is present\n    \"\"\"\n    return task_id in self._completed_tasks\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.log_info","title":"<code>log_info(message)</code>","text":"<p>Logs an informational message :param message: Log message</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def log_info(self, message):\n    \"\"\"\n    Logs an informational message\n    :param message: Log message\n    \"\"\"\n    self._deadline_plugin.LogInfo(message)\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.log_warning","title":"<code>log_warning(message)</code>","text":"<p>Logs a warning message :param message: Log message</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def log_warning(self, message):\n    \"\"\"\n    Logs a warning message\n    :param message: Log message\n    \"\"\"\n    self._deadline_plugin.LogWarning(message)\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.set_progress","title":"<code>set_progress(progress)</code>","text":"<p>Sets the job progress :param progress: job progress</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def set_progress(self, progress):\n    \"\"\"\n    Sets the job progress\n    :param progress: job progress\n    \"\"\"\n    self._deadline_plugin.SetProgress(progress)\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.set_status_message","title":"<code>set_status_message(message)</code>","text":"<p>Sets the message on the job status :param message: Status Message</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def set_status_message(self, message):\n    \"\"\"\n    Sets the message on the job status\n    :param message: Status Message\n    \"\"\"\n    self._deadline_plugin.SetStatusMessage(message)\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.update_job_output_directories","title":"<code>update_job_output_directories(directories)</code>","text":"<p>Updates the output directories on job :param list directories: List of directories</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def update_job_output_directories(self, directories):\n    \"\"\"\n    Updates the output directories on job\n    :param list directories: List of directories\n    \"\"\"\n    if not isinstance(directories, list):\n        directories = list(directories)\n\n    self._deadline_plugin.LogInfo(\n        \"Setting job directories: {directories}\".format(\n            directories=\", \".join(directories)\n        )\n    )\n\n    # Set the directory on the job\n    RepositoryUtils.SetJobOutputDirectories(self._job, directories)\n\n    # Make sure to save the settings just in case\n    RepositoryUtils.SaveJob(self._job)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.BaseDeadlineRPCJobManager.update_job_output_filenames","title":"<code>update_job_output_filenames(filenames)</code>","text":"<p>Updates the file names for the current job :param list filenames: list of filenames</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def update_job_output_filenames(self, filenames):\n    \"\"\"\n    Updates the file names for the current job\n    :param list filenames: list of filenames\n    \"\"\"\n    if not isinstance(filenames, list):\n        filenames = list(filenames)\n\n    self._deadline_plugin.LogInfo(\n        \"Setting job filenames: {filename}\".format(\n            filename=\", \".join(filenames)\n        )\n    )\n\n    # Set the file names on the job\n    RepositoryUtils.UpdateJobOutputFileNames(self._job, filenames)\n\n    # Make sure to save the settings just in case\n    RepositoryUtils.SaveJob(self._job)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.DeadlineRPCServerManager","title":"<code>DeadlineRPCServerManager</code>","text":"<p>               Bases: <code>BaseRPCServerManager</code></p> <p>RPC server manager class. This class is responsible for registering a server thread class and starting the thread. This can be a blocking or non-blocking thread</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>class DeadlineRPCServerManager(BaseRPCServerManager):\n    \"\"\"\n    RPC server manager class. This class is responsible for registering a\n    server thread class and starting the thread. This can be a blocking or\n    non-blocking thread\n    \"\"\"\n\n    def __init__(self, deadline_plugin, port):\n        super(DeadlineRPCServerManager, self).__init__()\n        self.name = \"DeadlineRPCServer\"\n        self.port = port\n        self.is_started = False\n        self.__make_plugin_instance_global(deadline_plugin)\n\n    @staticmethod\n    def __make_plugin_instance_global(deadline_plugin_instance):\n        \"\"\"\n        Puts an instance of the deadline plugin in the python globals. This\n        allows the server thread to get the plugin instance without having\n        the instance passthrough abstraction layers\n        :param deadline_plugin_instance: Deadline plugin instance\n        :return:\n        \"\"\"\n        import __main__\n\n        if not hasattr(__main__, \"__deadline_plugin_instance__\"):\n            __main__.__deadline_plugin_instance__ = None\n\n        __main__.__deadline_plugin_instance__ = deadline_plugin_instance\n\n    def start(self, threaded=True):\n        \"\"\"\n        Starts the server thread\n        :param threaded: Run as threaded or blocking\n        :return:\n        \"\"\"\n        super(DeadlineRPCServerManager, self).start(threaded=threaded)\n        self.is_started = True\n\n    def client_connected(self):\n        \"\"\"\n        Check if there is a client connected\n        :return:\n        \"\"\"\n        if self.server_thread:\n            return self.server_thread.deadline_job_manager.is_connected()\n        return False\n\n    def get_temporary_client_proxy(self):\n        \"\"\"\n        This returns client proxy and is not necessarily expected to be used\n        for server communication but for mostly queries.\n        NOTE: This behavior is implied\n        :return: RPC client proxy\n        \"\"\"\n        from ue_utils.rpc.client import RPCClient\n\n        # Get the port the server is using\n        server = self.get_server()\n        _, server_port = server.socket.getsockname()\n        return RPCClient(port=int(server_port)).proxy\n\n    def shutdown(self):\n        \"\"\"\n        Stops the server and shuts down the thread\n        :return:\n        \"\"\"\n        super(DeadlineRPCServerManager, self).shutdown()\n        self.is_started = False\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.DeadlineRPCServerManager.__make_plugin_instance_global","title":"<code>__make_plugin_instance_global(deadline_plugin_instance)</code>  <code>staticmethod</code>","text":"<p>Puts an instance of the deadline plugin in the python globals. This allows the server thread to get the plugin instance without having the instance passthrough abstraction layers :param deadline_plugin_instance: Deadline plugin instance :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>@staticmethod\ndef __make_plugin_instance_global(deadline_plugin_instance):\n    \"\"\"\n    Puts an instance of the deadline plugin in the python globals. This\n    allows the server thread to get the plugin instance without having\n    the instance passthrough abstraction layers\n    :param deadline_plugin_instance: Deadline plugin instance\n    :return:\n    \"\"\"\n    import __main__\n\n    if not hasattr(__main__, \"__deadline_plugin_instance__\"):\n        __main__.__deadline_plugin_instance__ = None\n\n    __main__.__deadline_plugin_instance__ = deadline_plugin_instance\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.DeadlineRPCServerManager.client_connected","title":"<code>client_connected()</code>","text":"<p>Check if there is a client connected :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def client_connected(self):\n    \"\"\"\n    Check if there is a client connected\n    :return:\n    \"\"\"\n    if self.server_thread:\n        return self.server_thread.deadline_job_manager.is_connected()\n    return False\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.DeadlineRPCServerManager.get_temporary_client_proxy","title":"<code>get_temporary_client_proxy()</code>","text":"<p>This returns client proxy and is not necessarily expected to be used for server communication but for mostly queries. NOTE: This behavior is implied :return: RPC client proxy</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def get_temporary_client_proxy(self):\n    \"\"\"\n    This returns client proxy and is not necessarily expected to be used\n    for server communication but for mostly queries.\n    NOTE: This behavior is implied\n    :return: RPC client proxy\n    \"\"\"\n    from ue_utils.rpc.client import RPCClient\n\n    # Get the port the server is using\n    server = self.get_server()\n    _, server_port = server.socket.getsockname()\n    return RPCClient(port=int(server_port)).proxy\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.DeadlineRPCServerManager.shutdown","title":"<code>shutdown()</code>","text":"<p>Stops the server and shuts down the thread :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def shutdown(self):\n    \"\"\"\n    Stops the server and shuts down the thread\n    :return:\n    \"\"\"\n    super(DeadlineRPCServerManager, self).shutdown()\n    self.is_started = False\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.DeadlineRPCServerManager.start","title":"<code>start(threaded=True)</code>","text":"<p>Starts the server thread :param threaded: Run as threaded or blocking :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>def start(self, threaded=True):\n    \"\"\"\n    Starts the server thread\n    :param threaded: Run as threaded or blocking\n    :return:\n    \"\"\"\n    super(DeadlineRPCServerManager, self).start(threaded=threaded)\n    self.is_started = True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.DeadlineRPC.DeadlineRPCServerThread","title":"<code>DeadlineRPCServerThread</code>","text":"<p>               Bases: <code>RPCServerThread</code></p> <p>Deadline server thread</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/DeadlineRPC.py</code> <pre><code>class DeadlineRPCServerThread(RPCServerThread):\n    \"\"\"\n    Deadline server thread\n    \"\"\"\n\n    deadline_job_manager = None\n\n    def __init__(self, name, port):\n        super(DeadlineRPCServerThread, self).__init__(name, port)\n        if self.deadline_job_manager:\n            self.deadline_job_manager = self.deadline_job_manager()\n        else:\n            self.deadline_job_manager = BaseDeadlineRPCJobManager()\n\n        # Register our instance on the server\n        self.server.register_instance(\n            self.deadline_job_manager,\n            allow_dotted_names=True\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/JobPreLoad.html","title":"JobPreLoad","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/PluginPreLoad.html","title":"PluginPreLoad","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html","title":"UnrealEngine5","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEngineCmdManagedProcess","title":"<code>UnrealEngineCmdManagedProcess</code>","text":"<p>               Bases: <code>ManagedProcess</code></p> <p>Process for executing unreal over commandline</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>class UnrealEngineCmdManagedProcess(ManagedProcess):\n    \"\"\"\n    Process for executing unreal over commandline\n    \"\"\"\n\n    def __init__(self, deadline_plugin, process_name, startup_dir=\"\"):\n        \"\"\"\n        Constructor\n        :param process_name: The name of this process\n        \"\"\"\n        if sys.version_info.major == 3:\n            super().__init__()\n        self._deadline_plugin = deadline_plugin\n        self._name = process_name\n        self.ExitCode = -1\n        self._startup_dir = startup_dir\n        self._executable_path = None\n\n        self.InitializeProcessCallback += self._initialize_process\n        self.RenderExecutableCallback += self._render_executable\n        self.RenderArgumentCallback += self._render_argument\n        self.CheckExitCodeCallback += self._check_exit_code\n        self.StartupDirectoryCallback += self._startup_directory\n\n    def clean_up(self):\n        \"\"\"\n        Called when the plugin cleanup is called\n        \"\"\"\n        self._deadline_plugin.LogInfo(\"Executing managed process cleanup.\")\n        # Clean up stdout handler callbacks.\n        for stdoutHandler in self.StdoutHandlers:\n            del stdoutHandler.HandleCallback\n\n        del self.InitializeProcessCallback\n        del self.RenderExecutableCallback\n        del self.RenderArgumentCallback\n        del self.CheckExitCodeCallback\n        del self.StartupDirectoryCallback\n        self._deadline_plugin.LogInfo(\"Managed Process Cleanup Finished.\")\n\n    def _initialize_process(self):\n        \"\"\"\n        Called by Deadline to initialize the process.\n        \"\"\"\n        self._deadline_plugin.LogInfo(\n            \"Executing managed process Initialize Process.\"\n        )\n\n        # Set the ManagedProcess specific settings.\n        self.PopupHandling = True\n        self.StdoutHandling = True\n        self.HideDosWindow = True\n\n        # Ensure child processes are killed and the parent process is\n        # terminated on exit\n        self.UseProcessTree = True\n        self.TerminateOnExit = True\n\n        shell = self._deadline_plugin.GetPluginInfoEntryWithDefault(\"Shell\", \"\")\n\n        if shell:\n            self._shell = shell\n\n        self.AddStdoutHandlerCallback(\n            \".*Progress: (\\d+)%.*\"\n        ).HandleCallback += self._handle_progress\n\n        # self.AddStdoutHandlerCallback(\"LogPython: Error:.*\").HandleCallback += self._handle_stdout_error\n\n        # Get the current frames for the task\n        current_task_frames = self._deadline_plugin.GetCurrentTask().TaskFrameString\n\n        # Set the frames sting as an environment variable\n        self.SetEnvironmentVariable(\"CURRENT_RENDER_FRAMES\", current_task_frames)\n\n    def _handle_stdout_error(self):\n        \"\"\"\n        Callback for when a line of stdout contains an ERROR message.\n        \"\"\"\n        self._deadline_plugin.FailRender(self.GetRegexMatch(0))\n\n    def _check_exit_code(self, exit_code):\n        \"\"\"\n        Returns the process exit code\n        :param exit_code:\n        :return:\n        \"\"\"\n        self.ExitCode = exit_code\n\n    def _startup_directory(self):\n        \"\"\"\n        Startup directory\n        \"\"\"\n        return self._startup_dir\n\n    def _handle_progress(self):\n        \"\"\"\n        Handles progress reports\n        \"\"\"\n        progress = float(self.GetRegexMatch(1))\n        self._deadline_plugin.SetProgress(progress)\n\n    def _render_executable(self):\n        \"\"\"\n        Get the render executable\n        \"\"\"\n\n        self._deadline_plugin.LogInfo(\"Setting up Render Executable\")\n\n        executable = self._deadline_plugin.GetEnvironmentVariable(\"UnrealExecutable\")\n\n        if not executable:\n            executable = self._deadline_plugin.GetPluginInfoEntry(\"Executable\")\n\n        # Get the executable from the plugin\n        executable = RepositoryUtils.CheckPathMapping(executable)\n        # Get the project root path\n        project_root = self._deadline_plugin.GetProcessEnvironmentVariable(\n            \"ProjectRoot\"\n        )\n\n        # Resolve any `{ProjectRoot}` tokens in the environment\n        if project_root:\n            executable = executable.format(ProjectRoot=project_root)\n\n        if not FileUtils.FileExists(executable):\n            self._deadline_plugin.FailRender(\n                \"{executable} could not be found\".format(executable=executable)\n            )\n\n        # TODO: Setup getting executable from the config as well\n\n        self._deadline_plugin.LogInfo(\n            \"Render Executable: {exe}\".format(exe=executable)\n        )\n        self._executable_path = executable.replace(\"\\\\\", \"/\")\n\n        return self._executable_path\n\n    def _render_argument(self):\n        \"\"\"\n        Get the arguments to startup unreal\n        :return:\n        \"\"\"\n        self._deadline_plugin.LogInfo(\"Setting up Render Arguments\")\n\n        # Look for any unreal uproject paths in the process environment. This\n        # assumes a previous process resolves a uproject path and makes it\n        # available.\n        project_file = self._deadline_plugin.GetEnvironmentVariable(\"UnrealUProject\")\n\n        if not project_file:\n            project_file = self._deadline_plugin.GetPluginInfoEntry(\"ProjectFile\")\n\n        # Get any path mappings required. Expects this to be a full path\n        project_file = RepositoryUtils.CheckPathMapping(project_file)\n\n        # Get the project root path\n        project_root = self._deadline_plugin.GetProcessEnvironmentVariable(\n            \"ProjectRoot\"\n        )\n\n        # Resolve any `{ProjectRoot}` tokens in the environment\n        if project_root:\n            project_file = project_file.format(ProjectRoot=project_root)\n\n        if not project_file:\n            self._deadline_plugin.FailRender(\n                f\"Expected project file but found `{project_file}`\"\n            )\n\n        project_file = Path(project_file.replace(\"\\u201c\", '\"').replace(\n            \"\\u201d\", '\"'\n        ).replace(\"\\\\\", \"/\"))\n\n        # Check to see if the Uproject is a relative path\n        if str(project_file).replace(\"\\\\\", \"/\").startswith(\"../\"):\n\n            if not self._executable_path:\n                self._deadline_plugin.FailRender(\"Could not find executable path to resolve relative path.\")\n\n            # Find executable root\n            import re\n            engine_dir = re.findall(\"([\\s\\S]*.Engine)\", self._executable_path)\n            if not engine_dir:\n                self._deadline_plugin.FailRender(\"Could not find executable Engine directory.\")\n\n            executable_root = Path(engine_dir[0]).parent\n\n            # Resolve editor relative paths\n            found_paths = sorted(executable_root.rglob(str(project_file).replace(\"\\\\\", \"/\").strip(\"../\")))\n\n            if not found_paths or len(found_paths) &gt; 1:\n                self._deadline_plugin.FailRender(\n                    f\"Found multiple uprojects relative to the root directory. There should only be one when a relative path is defined.\"\n                )\n\n            project_file = found_paths[0]\n        self._deadline_plugin.LogInfo(f\"project_file:: `{project_file}`\")\n        # make sure the project exists\n        if not FileUtils.FileExists(project_file.as_posix()):\n            self._deadline_plugin.FailRender(f\"Could not find `{project_file.as_posix()}`\")\n\n        # Get the render arguments\n        args = RepositoryUtils.CheckPathMapping(\n            self._deadline_plugin.GetPluginInfoEntry(\n                \"CommandLineArguments\"\n            ).strip()\n        )\n\n        args = args.replace(\"\\u201c\", '\"').replace(\"\\u201d\", '\"')\n\n        startup_args = \" \".join(\n            [\n                '\"{u_project}\"'.format(u_project=project_file.as_posix()),\n                args,\n                \"-log\",\n                \"-unattended\",\n                \"-stdout\",\n                \"-allowstdoutlogverbosity\",\n            ]\n        )\n\n        self._deadline_plugin.LogInfo(\n            \"Render Arguments: {args}\".format(args=startup_args)\n        )\n\n        return startup_args\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEngineCmdManagedProcess.__init__","title":"<code>__init__(deadline_plugin, process_name, startup_dir='')</code>","text":"<p>Constructor :param process_name: The name of this process</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def __init__(self, deadline_plugin, process_name, startup_dir=\"\"):\n    \"\"\"\n    Constructor\n    :param process_name: The name of this process\n    \"\"\"\n    if sys.version_info.major == 3:\n        super().__init__()\n    self._deadline_plugin = deadline_plugin\n    self._name = process_name\n    self.ExitCode = -1\n    self._startup_dir = startup_dir\n    self._executable_path = None\n\n    self.InitializeProcessCallback += self._initialize_process\n    self.RenderExecutableCallback += self._render_executable\n    self.RenderArgumentCallback += self._render_argument\n    self.CheckExitCodeCallback += self._check_exit_code\n    self.StartupDirectoryCallback += self._startup_directory\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEngineCmdManagedProcess.clean_up","title":"<code>clean_up()</code>","text":"<p>Called when the plugin cleanup is called</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def clean_up(self):\n    \"\"\"\n    Called when the plugin cleanup is called\n    \"\"\"\n    self._deadline_plugin.LogInfo(\"Executing managed process cleanup.\")\n    # Clean up stdout handler callbacks.\n    for stdoutHandler in self.StdoutHandlers:\n        del stdoutHandler.HandleCallback\n\n    del self.InitializeProcessCallback\n    del self.RenderExecutableCallback\n    del self.RenderArgumentCallback\n    del self.CheckExitCodeCallback\n    del self.StartupDirectoryCallback\n    self._deadline_plugin.LogInfo(\"Managed Process Cleanup Finished.\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEngineManagedProcess","title":"<code>UnrealEngineManagedProcess</code>","text":"<p>               Bases: <code>ManagedProcess</code></p> <p>Process for executing and managing an unreal jobs.</p> <p>.. note::</p> <pre><code>Although this process can auto start a batch process by\nexecuting a script on startup, it is VERY important the command\nthat is executed on startup makes a connection to the Deadline RPC\nserver.\nThis will allow Deadline to know a task is running and will wait\nuntil the task is complete before rendering the next one. If this\nis not done, Deadline will assume something went wrong with the\nprocess and fail the job after a few minutes. It is also VERY\ncritical the Deadline process is told when a task is complete, so\nit can move on to the next one. See the Deadline RPC manager on how\nthis communication system works.\nThe reason for this complexity is, sometimes an unreal project can\ntake several minutes to load, and we only want to bare the cost of\nthat load time once between tasks.\n</code></pre> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>class UnrealEngineManagedProcess(ManagedProcess):\n    \"\"\"\n    Process for executing and managing an unreal jobs.\n\n    .. note::\n\n        Although this process can auto start a batch process by\n        executing a script on startup, it is VERY important the command\n        that is executed on startup makes a connection to the Deadline RPC\n        server.\n        This will allow Deadline to know a task is running and will wait\n        until the task is complete before rendering the next one. If this\n        is not done, Deadline will assume something went wrong with the\n        process and fail the job after a few minutes. It is also VERY\n        critical the Deadline process is told when a task is complete, so\n        it can move on to the next one. See the Deadline RPC manager on how\n        this communication system works.\n        The reason for this complexity is, sometimes an unreal project can\n        take several minutes to load, and we only want to bare the cost of\n        that load time once between tasks.\n\n    \"\"\"\n\n    def __init__(self, process_name, deadline_plugin, deadline_rpc_manager):\n        \"\"\"\n        Constructor\n        :param process_name: The name of this process\n        :param deadline_plugin: An instance of the plugin\n        :param deadline_rpc_manager: An instance of the rpc manager\n        \"\"\"\n        if sys.version_info.major == 3:\n            super().__init__()\n        self.InitializeProcessCallback += self._initialize_process\n        self.RenderExecutableCallback += self._render_executable\n        self.RenderArgumentCallback += self._render_argument\n        self._deadline_plugin = deadline_plugin\n        self._deadline_rpc_manager = deadline_rpc_manager\n        self._temp_rpc_client = None\n        self._name = process_name\n        self._executable_path = None\n\n        # Elapsed time to check for connection\n        self._process_wait_time = int(self._deadline_plugin.GetConfigEntryWithDefault(\"RPCWaitTime\", \"300\"))\n\n    def clean_up(self):\n        \"\"\"\n        Called when the plugin cleanup is called\n        \"\"\"\n        self._deadline_plugin.LogInfo(\"Executing managed process cleanup.\")\n        # Clean up stdout handler callbacks.\n        for stdoutHandler in self.StdoutHandlers:\n            del stdoutHandler.HandleCallback\n\n        del self.InitializeProcessCallback\n        del self.RenderExecutableCallback\n        del self.RenderArgumentCallback\n        self._deadline_plugin.LogInfo(\"Managed Process Cleanup Finished.\")\n\n    def _initialize_process(self):\n        \"\"\"\n        Called by Deadline to initialize the process.\n        \"\"\"\n        self._deadline_plugin.LogInfo(\n            \"Executing managed process Initialize Process.\"\n        )\n\n        # Set the ManagedProcess specific settings.\n        self.PopupHandling = False\n        self.StdoutHandling = True\n\n        # Set the stdout handlers.\n\n        self.AddStdoutHandlerCallback(\n            \"LogPython: Error:.*\"\n        ).HandleCallback += self._handle_stdout_error\n        self.AddStdoutHandlerCallback(\n            \"Warning:.*\"\n        ).HandleCallback += self._handle_stdout_warning\n\n        logs_dir = self._deadline_plugin.GetPluginInfoEntryWithDefault(\n            \"LoggingDirectory\", \"\"\n        )\n        # error handler for Apple ProRes Media not writing file\n        self.AddStdoutHandlerCallback(\n            \".*LogAppleProResMedia: Error: Failed to.*\"\n        ).HandleCallback += self._handle_stdout_error\n\n        self.AddStdoutHandlerCallback(\n            \".*LogWindows: FPlatformMisc::RequestExitWithStatus\\(1,.*\"\n        ).HandleCallback += self._handle_stdout_error\n\n        self.AddStdoutHandlerCallback(\n            \".*with error DXGI_ERROR_DEVICE_REMOVED with Reason: DXGI_ERROR_DEVICE_HUNG*\"\n        ).HandleCallback += self._handle_stdout_error\n\n        if logs_dir:\n\n            job = self._deadline_plugin.GetJob()\n\n            log_file_dir = os.path.join(\n                job.JobName,\n                f\"{job.JobSubmitDateTime.ToUniversalTime()}\".replace(\" \", \"-\"),\n            )\n\n            if not os.path.exists(log_file_dir):\n                os.makedirs(log_file_dir)\n\n            # If a log directory is specified, this may redirect stdout to the\n            # log file instead. This is a builtin Deadline behavior\n            self.RedirectStdoutToFile(\n                os.path.join(\n                    log_file_dir,\n                    f\"{self._deadline_plugin.GetSlaveName()}_{datetime.now()}.log\".replace(\" \", \"-\")\n                )\n            )\n\n    def _handle_std_out(self):\n        self._deadline_plugin.LogInfo(self.GetRegexMatch(0))\n\n    # Callback for when a line of stdout contains a WARNING message.\n    def _handle_stdout_warning(self):\n        self._deadline_plugin.LogWarning(self.GetRegexMatch(0))\n\n    # Callback for when a line of stdout contains an ERROR message.\n    def _handle_stdout_error(self):\n        self._deadline_plugin.FailRender(self.GetRegexMatch(0))\n\n    def render_task(self):\n        \"\"\"\n        Render a task\n        \"\"\"\n\n        # Fail the render is we do not have a manager running\n        if not self._deadline_rpc_manager:\n            self._deadline_plugin.FailRender(\"No rpc manager was running!\")\n\n        # Start a timer to monitor the process time\n        start_time = time.time()\n\n        # Get temp client connection\n        if not self._temp_rpc_client:\n            self._temp_rpc_client = self._deadline_rpc_manager.get_temporary_client_proxy()\n\n\n        print(\"Is server and client connected?\", self._temp_rpc_client.is_connected())\n\n        # Make sure we have a manager running, and we can establish a connection\n        if not self._temp_rpc_client.is_connected():\n            # Wait for a connection. This polls the server thread till an\n            # unreal process client has connected. It is very important that\n            # a connection is established by the client to allow this process\n            # to execute.\n            while round(time.time() - start_time) &lt;= self._process_wait_time:\n                try:\n                    # keep checking to see if a client has connected\n                    if self._temp_rpc_client.is_connected():\n                        self._deadline_plugin.LogInfo(\n                            \"Client connection established!!\"\n                        )\n                        break\n                except Exception:\n                    pass\n\n                self._deadline_plugin.LogInfo(\"Waiting on client connection..\")\n                self._deadline_plugin.FlushMonitoredManagedProcessStdout(\n                    self._name\n                )\n                time.sleep(2)\n            else:\n\n                # Fail the render after waiting too long\n                self._deadline_plugin.FailRender(\n                    \"A connection was not established with an unreal process\"\n                )\n\n        # if we are connected, wait till the process task is marked as\n        # complete.\n        while not self._temp_rpc_client.is_task_complete(\n            self._deadline_plugin.GetCurrentTaskId()\n        ):\n            # Keep flushing stdout\n            self._deadline_plugin.FlushMonitoredManagedProcessStdout(self._name)\n\n        # Flush one last time\n        self._deadline_plugin.FlushMonitoredManagedProcessStdout(self._name)\n\n    def _render_executable(self):\n        \"\"\"\n        Get the render executable\n        \"\"\"\n        self._deadline_plugin.LogInfo(\"Setting up Render Executable\")\n\n        executable = self._deadline_plugin.GetEnvironmentVariable(\"UnrealExecutable\")\n\n        if not executable:\n            executable = self._deadline_plugin.GetPluginInfoEntry(\"Executable\")\n\n        # Resolve any path mappings required\n        executable = RepositoryUtils.CheckPathMapping(executable)\n\n        project_root = self._deadline_plugin.GetEnvironmentVariable(\"ProjectRoot\")\n\n        # If a project root is specified in the environment, it is assumed a\n        # previous process resolves the root location of the executable and\n        # presents it in the environment.\n        if project_root:\n            # Resolve any `{ProjectRoot}` tokens present in the executable path\n            executable = executable.format(ProjectRoot=project_root)\n\n        # Make sure the executable exists\n        if not FileUtils.FileExists(executable):\n            self._deadline_plugin.FailRender(f\"Could not find `{executable}`\")\n\n        self._executable_path = executable.replace(\"\\\\\", \"/\")\n\n        self._deadline_plugin.LogInfo(f\"Found executable `{executable}`\")\n\n        return self._executable_path\n\n    def _render_argument(self):\n        \"\"\"\n        Get the arguments to startup unreal\n        \"\"\"\n        self._deadline_plugin.LogInfo(\"Setting up Render Arguments\")\n\n        # Look for any unreal uproject paths in the process environment. This\n        # assumes a previous process resolves a uproject path and makes it\n        # available.\n        uproject = self._deadline_plugin.GetEnvironmentVariable(\"UnrealUProject\")\n\n        if not uproject:\n            uproject = self._deadline_plugin.GetPluginInfoEntry(\"ProjectFile\")\n\n        # Get any path mappings required. Expects this to be a full path\n        uproject = RepositoryUtils.CheckPathMapping(uproject)\n\n        # Get the project root path\n        project_root = self._deadline_plugin.GetEnvironmentVariable(\"ProjectRoot\")\n\n        # Resolve any `{ProjectRoot}` tokens in the environment\n        if project_root:\n            uproject = uproject.format(ProjectRoot=project_root)\n\n        uproject = Path(uproject.replace(\"\\\\\", \"/\"))\n        self._deadline_plugin.LogInfo(f\"uproject:: `{uproject}`\")\n        # Check to see if the Uproject is a relative path\n        if str(uproject).replace(\"\\\\\", \"/\").startswith(\"../\"):\n\n            if not self._executable_path:\n                self._deadline_plugin.FailRender(\"Could not find executable path to resolve relative path.\")\n\n            # Find executable root\n            import re\n            engine_dir = re.findall(\"([\\s\\S]*.Engine)\", self._executable_path)\n            if not engine_dir:\n                self._deadline_plugin.FailRender(\"Could not find executable Engine directory.\")\n\n            executable_root = Path(engine_dir[0]).parent\n\n            # Resolve editor relative paths\n            found_paths = sorted(executable_root.rglob(str(uproject).replace(\"\\\\\", \"/\").strip(\"../\")))\n\n            if not found_paths or len(found_paths) &gt; 1:\n                self._deadline_plugin.FailRender(\n                    f\"Found multiple uprojects relative to the root directory. There should only be one when a relative path is defined.\"\n                )\n\n            uproject = found_paths[0]\n\n        # make sure the project exists\n        if not FileUtils.FileExists(uproject.as_posix()):\n            self._deadline_plugin.FailRender(f\"Could not find `{uproject.as_posix()}`\")\n\n        # Set up the arguments to startup unreal.\n        job_command_args = [\n            '\"{u_project}\"'.format(u_project=uproject.as_posix()),\n            self._deadline_plugin.GetPluginInfoEntryWithDefault(\"CommandLineArguments\", \"\"),\n            # Force \"-log\" otherwise there is no output from the executable\n            \"-log\",\n            \"-unattended\",\n            \"-stdout\",\n            \"-allowstdoutlogverbosity\",\n        ]\n\n        arguments = \" \".join(job_command_args)\n        self._deadline_plugin.LogInfo(f\"Startup Arguments: `{arguments}`\")\n\n        return arguments\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEngineManagedProcess.__init__","title":"<code>__init__(process_name, deadline_plugin, deadline_rpc_manager)</code>","text":"<p>Constructor :param process_name: The name of this process :param deadline_plugin: An instance of the plugin :param deadline_rpc_manager: An instance of the rpc manager</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def __init__(self, process_name, deadline_plugin, deadline_rpc_manager):\n    \"\"\"\n    Constructor\n    :param process_name: The name of this process\n    :param deadline_plugin: An instance of the plugin\n    :param deadline_rpc_manager: An instance of the rpc manager\n    \"\"\"\n    if sys.version_info.major == 3:\n        super().__init__()\n    self.InitializeProcessCallback += self._initialize_process\n    self.RenderExecutableCallback += self._render_executable\n    self.RenderArgumentCallback += self._render_argument\n    self._deadline_plugin = deadline_plugin\n    self._deadline_rpc_manager = deadline_rpc_manager\n    self._temp_rpc_client = None\n    self._name = process_name\n    self._executable_path = None\n\n    # Elapsed time to check for connection\n    self._process_wait_time = int(self._deadline_plugin.GetConfigEntryWithDefault(\"RPCWaitTime\", \"300\"))\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEngineManagedProcess.clean_up","title":"<code>clean_up()</code>","text":"<p>Called when the plugin cleanup is called</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def clean_up(self):\n    \"\"\"\n    Called when the plugin cleanup is called\n    \"\"\"\n    self._deadline_plugin.LogInfo(\"Executing managed process cleanup.\")\n    # Clean up stdout handler callbacks.\n    for stdoutHandler in self.StdoutHandlers:\n        del stdoutHandler.HandleCallback\n\n    del self.InitializeProcessCallback\n    del self.RenderExecutableCallback\n    del self.RenderArgumentCallback\n    self._deadline_plugin.LogInfo(\"Managed Process Cleanup Finished.\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEngineManagedProcess.render_task","title":"<code>render_task()</code>","text":"<p>Render a task</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def render_task(self):\n    \"\"\"\n    Render a task\n    \"\"\"\n\n    # Fail the render is we do not have a manager running\n    if not self._deadline_rpc_manager:\n        self._deadline_plugin.FailRender(\"No rpc manager was running!\")\n\n    # Start a timer to monitor the process time\n    start_time = time.time()\n\n    # Get temp client connection\n    if not self._temp_rpc_client:\n        self._temp_rpc_client = self._deadline_rpc_manager.get_temporary_client_proxy()\n\n\n    print(\"Is server and client connected?\", self._temp_rpc_client.is_connected())\n\n    # Make sure we have a manager running, and we can establish a connection\n    if not self._temp_rpc_client.is_connected():\n        # Wait for a connection. This polls the server thread till an\n        # unreal process client has connected. It is very important that\n        # a connection is established by the client to allow this process\n        # to execute.\n        while round(time.time() - start_time) &lt;= self._process_wait_time:\n            try:\n                # keep checking to see if a client has connected\n                if self._temp_rpc_client.is_connected():\n                    self._deadline_plugin.LogInfo(\n                        \"Client connection established!!\"\n                    )\n                    break\n            except Exception:\n                pass\n\n            self._deadline_plugin.LogInfo(\"Waiting on client connection..\")\n            self._deadline_plugin.FlushMonitoredManagedProcessStdout(\n                self._name\n            )\n            time.sleep(2)\n        else:\n\n            # Fail the render after waiting too long\n            self._deadline_plugin.FailRender(\n                \"A connection was not established with an unreal process\"\n            )\n\n    # if we are connected, wait till the process task is marked as\n    # complete.\n    while not self._temp_rpc_client.is_task_complete(\n        self._deadline_plugin.GetCurrentTaskId()\n    ):\n        # Keep flushing stdout\n        self._deadline_plugin.FlushMonitoredManagedProcessStdout(self._name)\n\n    # Flush one last time\n    self._deadline_plugin.FlushMonitoredManagedProcessStdout(self._name)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEnginePlugin","title":"<code>UnrealEnginePlugin</code>","text":"<p>               Bases: <code>DeadlinePlugin</code></p> <p>Deadline plugin to execute an Unreal Engine job. NB: This plugin makes no assumptions about what the render job is but has a few expectations. This plugin runs as a server in the deadline process and exposes a few Deadline functionalities over XML RPC. The managed process used by this plugin waits for a client to connect and continuously polls the RPC server till a task has been marked complete before exiting the process. This behavior however has a drawback. If for some reason your process does not mark a task complete after working on a command, the plugin will run the current task indefinitely until specified to end by the repository settings or manually.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>class UnrealEnginePlugin(DeadlinePlugin):\n    \"\"\"\n    Deadline plugin to execute an Unreal Engine job.\n    NB: This plugin makes no assumptions about what the render job is but has a\n    few expectations. This plugin runs as a server in the deadline process\n    and exposes a few Deadline functionalities over XML RPC. The managed process\n    used by this plugin waits for a client to connect and continuously polls the\n    RPC server till a task has been marked complete before exiting the\n    process. This behavior however has a drawback. If for some reason your\n    process does not mark a task complete after working on a command,\n    the plugin will run the current task indefinitely until specified to\n    end by the repository settings or manually.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Constructor\n        \"\"\"\n        if sys.version_info.major == 3:\n            super().__init__()\n        self.InitializeProcessCallback += self._on_initialize_process\n        self.StartJobCallback += self._on_start_job\n        self.RenderTasksCallback += self._on_render_tasks\n        self.EndJobCallback += self._on_end_job\n        self.MonitoredManagedProcessExitCallback += self._on_process_exit\n\n        # Set the name of the managed process to the current deadline process ID\n        self._unreal_process_name = f\"UnrealEngine_{os.getpid()}\"\n        self.unreal_managed_process = None\n\n        # Keep track of the RPC manager\n        self._deadline_rpc_manager = None\n\n        # Keep track of when Job Ended has been called\n        self._job_ended = False\n\n        # set the plugin to commandline mode by default. This will launch the\n        # editor and wait for the process to exit. There is no communication\n        # with the deadline process.\n        self._commandline_mode = True\n\n    def clean_up(self):\n        \"\"\"\n        Plugin cleanup\n        \"\"\"\n        del self.InitializeProcessCallback\n        del self.StartJobCallback\n        del self.RenderTasksCallback\n        del self.EndJobCallback\n\n        if self.unreal_managed_process:\n            self.unreal_managed_process.clean_up()\n            del self.unreal_managed_process\n\n        del self.MonitoredManagedProcessExitCallback\n\n    def _on_initialize_process(self):\n        \"\"\"\n        Initialize the plugin\n        \"\"\"\n        self.LogInfo(\"Initializing job plugin\")\n        self.SingleFramesOnly = False\n        self.StdoutHandling = True\n        self.PluginType = PluginType.Advanced\n        self._commandline_mode = StringUtils.ParseBoolean(\n            self.GetPluginInfoEntryWithDefault(\"CommandLineMode\", \"true\")\n        )\n\n        if self._commandline_mode:\n            self.AddStdoutHandlerCallback(\n                \".*Progress: (\\\\d+)%.*\"\n            ).HandleCallback += self._handle_progress\n            self.AddStdoutHandlerCallback(\n                \".*\"\n            ).HandleCallback += self._handle_stdout\n\n        self.LogInfo(\"Initialization complete!\")\n\n    def _on_start_job(self):\n        \"\"\"\n        This is executed when the plugin picks up a job\n        \"\"\"\n\n        # Skip if we are in commandline mode\n        if self._commandline_mode:\n            return\n\n        self.LogInfo(\"Executing Start Job\")\n\n        # Get and set up the RPC manager for the plugin\n        self._deadline_rpc_manager = self._setup_rpc_manager()\n\n        # Get a managed process\n        self.unreal_managed_process = UnrealEngineManagedProcess(\n            self._unreal_process_name, self, self._deadline_rpc_manager\n        )\n        self.LogInfo(\"Done executing Start Job\")\n\n    def _setup_rpc_manager(self):\n        \"\"\"\n        Get an RPC manager for the plugin.\n        \"\"\"\n        self.LogInfo(\"Setting up RPC Manager\")\n        # Setting the port to `0` will get a random available port for the\n        # processes to connect on. This will help avoid TIME_WAIT\n        # issues with the client if the job has to be re-queued\n        port = 0\n\n        # Get an instance of the deadline rpc manager class. This class will\n        # store an instance of this plugin in the python globals. This should\n        # allow threads in the process to get an instance of the plugin without\n        # passing the data down through the thread instance\n        _deadline_rpc_manager = DeadlineRPCServerManager(self, port)\n\n        # We would like to run the server in a thread to not block deadline's\n        # process. Get the Deadline RPC thread class. Set the class that is\n        # going to be registered on the server on the thread class\n        DeadlineRPCServerThread.deadline_job_manager = BaseDeadlineRPCJobManager\n\n        # Set the threading class on the deadline manager\n        _deadline_rpc_manager.threaded_server_class = DeadlineRPCServerThread\n\n        return _deadline_rpc_manager\n\n    def _on_render_tasks(self):\n        \"\"\"\n        Execute the render task\n        \"\"\"\n        # This starts a self-managed process that terminates based on the exit\n        # code of the process. 0 means success\n        if self._commandline_mode:\n            startup_dir = self._get_startup_directory()\n\n            self.unreal_managed_process = UnrealEngineCmdManagedProcess(\n                self, self._unreal_process_name, startup_dir=startup_dir\n            )\n\n            # Auto execute the managed process\n            self.RunManagedProcess(self.unreal_managed_process)\n            exit_code = self.unreal_managed_process.ExitCode  # type: ignore\n\n            self.LogInfo(f\"Process returned: {exit_code}\")\n\n            if exit_code != 0:\n                self.FailRender(\n                    f\"Process returned non-zero exit code '{exit_code}'\"\n                )\n\n        else:\n            # Flush stdout. This is useful after executing the first task\n            self.FlushMonitoredManagedProcessStdout(self._unreal_process_name)\n\n            # Start next tasks\n            self.LogWarning(f\"Starting Task {self.GetCurrentTaskId()}\")\n\n            # Account for any re-queued jobs. Deadline will immediately execute\n            # render tasks if a job has been re-queued on the same process. If\n            # that happens get a new instance of the rpc manager\n            if not self._deadline_rpc_manager or self._job_ended:\n                self._deadline_rpc_manager = self._setup_rpc_manager()\n\n            if not self._deadline_rpc_manager.is_started:\n\n                # Start the manager\n                self._deadline_rpc_manager.start(threaded=True)\n\n                # Get the socket the server is using and expose it to the\n                # process\n                server = self._deadline_rpc_manager.get_server()\n\n                _, server_port = server.socket.getsockname()\n\n                self.LogWarning(\n                    f\"Starting Deadline RPC Manager on port `{server_port}`\"\n                )\n\n                # Get the port the server socket is going to use and\n                # allow other systems to get the port to the rpc server from the\n                # process environment variables\n                self.SetProcessEnvironmentVariable(\n                    \"DEADLINE_RPC_PORT\", str(server_port)\n                )\n\n            # Fail if we don't have an instance to a managed process.\n            # This should typically return true\n            if not self.unreal_managed_process:\n                self.FailRender(\"There is no unreal process Running\")\n\n            if not self.MonitoredManagedProcessIsRunning(self._unreal_process_name):\n                # Start the monitored Process\n                self.StartMonitoredManagedProcess(\n                    self._unreal_process_name,\n                    self.unreal_managed_process\n                )\n\n                self.VerifyMonitoredManagedProcess(self._unreal_process_name)\n\n            # Execute the render task\n            self.unreal_managed_process.render_task()\n\n            self.LogWarning(f\"Finished Task {self.GetCurrentTaskId()}\")\n            self.FlushMonitoredManagedProcessStdout(self._unreal_process_name)\n\n    def _on_end_job(self):\n        \"\"\"\n        Called when the job ends\n        \"\"\"\n        if self._commandline_mode:\n            return\n\n        self.FlushMonitoredManagedProcessStdout(self._unreal_process_name)\n        self.LogWarning(\"EndJob called\")\n        self.ShutdownMonitoredManagedProcess(self._unreal_process_name)\n\n        # Gracefully shutdown the RPC manager. This will also shut down any\n        # threads spun up by the manager\n        if self._deadline_rpc_manager:\n            self._deadline_rpc_manager.shutdown()\n\n        # Mark the job as ended. This also helps us to know when a job has\n        # been re-queued, so we can get a new instance of the RPC manager,\n        # as Deadline calls End Job when an error occurs\n        self._job_ended = True\n\n    def _on_process_exit(self):\n        # If the process ends unexpectedly, make sure we shut down the manager\n        # gracefully\n        if self._commandline_mode:\n            return\n\n        if self._deadline_rpc_manager:\n            self._deadline_rpc_manager.shutdown()\n\n    def _handle_stdout(self):\n        \"\"\"\n        Handle stdout\n        \"\"\"\n        self._deadline_plugin.LogInfo(self.GetRegexMatch(0))\n\n    def _handle_progress(self):\n        \"\"\"\n        Handles any progress reports\n        :return:\n        \"\"\"\n        progress = float(self.GetRegexMatch(1))\n        self.SetProgress(progress)\n\n    def _get_startup_directory(self):\n        \"\"\"\n        Get startup directory\n        \"\"\"\n        startup_dir = self.GetPluginInfoEntryWithDefault(\n            \"StartupDirectory\", \"\"\n        ).strip()\n        # Get the project root path\n        project_root = self.GetProcessEnvironmentVariable(\"ProjectRoot\")\n\n        if startup_dir:\n            if project_root:\n                startup_dir = startup_dir.format(ProjectRoot=project_root)\n\n            self.LogInfo(\"Startup Directory: {dir}\".format(dir=startup_dir))\n            return startup_dir.replace(\"\\\\\", \"/\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEnginePlugin.__init__","title":"<code>__init__()</code>","text":"<p>Constructor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Constructor\n    \"\"\"\n    if sys.version_info.major == 3:\n        super().__init__()\n    self.InitializeProcessCallback += self._on_initialize_process\n    self.StartJobCallback += self._on_start_job\n    self.RenderTasksCallback += self._on_render_tasks\n    self.EndJobCallback += self._on_end_job\n    self.MonitoredManagedProcessExitCallback += self._on_process_exit\n\n    # Set the name of the managed process to the current deadline process ID\n    self._unreal_process_name = f\"UnrealEngine_{os.getpid()}\"\n    self.unreal_managed_process = None\n\n    # Keep track of the RPC manager\n    self._deadline_rpc_manager = None\n\n    # Keep track of when Job Ended has been called\n    self._job_ended = False\n\n    # set the plugin to commandline mode by default. This will launch the\n    # editor and wait for the process to exit. There is no communication\n    # with the deadline process.\n    self._commandline_mode = True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.UnrealEnginePlugin.clean_up","title":"<code>clean_up()</code>","text":"<p>Plugin cleanup</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def clean_up(self):\n    \"\"\"\n    Plugin cleanup\n    \"\"\"\n    del self.InitializeProcessCallback\n    del self.StartJobCallback\n    del self.RenderTasksCallback\n    del self.EndJobCallback\n\n    if self.unreal_managed_process:\n        self.unreal_managed_process.clean_up()\n        del self.unreal_managed_process\n\n    del self.MonitoredManagedProcessExitCallback\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.CleanupDeadlinePlugin","title":"<code>CleanupDeadlinePlugin(deadline_plugin)</code>","text":"<p>Deadline call this function to run any cleanup code :param deadline_plugin: An instance of the deadline plugin</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def CleanupDeadlinePlugin(deadline_plugin):\n    \"\"\"\n    Deadline call this function to run any cleanup code\n    :param deadline_plugin: An instance of the deadline plugin\n    \"\"\"\n    deadline_plugin.clean_up()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEngine5.GetDeadlinePlugin","title":"<code>GetDeadlinePlugin()</code>","text":"<p>Deadline calls this function to get am instance of our class</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEngine5.py</code> <pre><code>def GetDeadlinePlugin():\n    \"\"\"\n    Deadline calls this function to get am instance of our class\n    \"\"\"\n    return UnrealEnginePlugin()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealSyncUtil.html","title":"UnrealSyncUtil","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealSyncUtil.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealSyncUtil.PerforceArgumentError","title":"<code>PerforceArgumentError</code>","text":"<p>               Bases: <code>PerforceError</code></p> <p>An exception that is raised when a perforce command is executed but is missing required arguments.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealSyncUtil.py</code> <pre><code>class PerforceArgumentError(PerforceError):\n    \"\"\"An exception that is raised when a perforce command is executed but is missing required arguments.\n\n    Attributes:\n        message -- programmer defined message\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/index.html","title":"UnrealEnginePlugins","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/index.html","title":"MoviePipelineDeadline","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/index.html","title":"Content","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/index.html","title":"Python","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/init_unreal.html","title":"init_unreal","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli.html","title":"mrq_cli","text":"<p>This is a commandline script that can be used to execute local and remote renders from Unreal. This script can be executed in Editor or via commandline.</p> <p>This script has several modes:</p> <pre><code>manifest:\n    This mode allows you to specify a full path to manifest file and a queue will be created from the manifest.\n\n    Command:\n        .. code-block:: shell\n\n            $ py mrq_cli.py manifest \"Full/Path/To/Manifest.utxt\"\n    Options:\n        *--load*: This allows you to only load the manifest file without executing a render.\n\nsequence:\n    This mode allows you to specify a specific level sequence, map and movie render queue preset to render.\n\n    Command:\n        .. code-block:: shell\n\n            $ py mrq_cli.py sequence my_level_sequence_name my_map_name my_mrq_preset_name\n\nqueue:\n    This mode allows you to load and render a queue asset.\n\n    Command:\n        .. code-block:: shell\n\n           $ py mrq_cli.py queue \"/Game/path/to/queue/asset\"\n    Options:\n        *--load*: This allows you to only load the queue asset without executing a render.\n\n        *--jobs*: A queue can have more than one job. This allows you to specify particular jobs in the queue and render its current state\n\nrender:\n    This mode allows you to render the jobs in the current loaded queue. This is useful when you what to execute\n    renders in multi steps. For example, executing in a farm context, you can load a manifest file and trigger\n    multiple different shots for the current worker machine based on some database without reloading the\n    manifest file everytime. By default, the queue is rendered in its current state if no other arguments are\n    specified.\n\n    Command:\n        .. code-block:: shell\n\n            $ py mrq_cli.py render\n    Options:\n        *--jobs*: The current queue can have more than one job. This allows you to specify a particular list of jobs in the queue and render in its current state\n</code></pre> <p>Optional Arguments:</p> <pre><code>There a few optional arguments that can be supplied to the script and are global to the modes\n\n*--shots*: This option allows you to specify a list of shots to render in the queue. This optional argument can be used with both modes of the script.\n\n*--all-shots*: This options enables all shots on all jobs. This is useful when you want to render everything in a queue.\n\n*--user*: This options sets the author on the render job. If None is provided, the current logged-in user is used.\n\n*--remote/-r*: This option submits the render to a remote process. This remote process is whatever is set in the\nMRQ remote executor option. This script is targeted for Deadline. However, it can still support\nthe default \"Out-of-Process\" executor. This flag can be used with both modes of the script.\nWhen specifying a remote command for deadline, you'll need to also supply these commands:\n\n    *--batch_name*: This sets the batch name on the executor.\n\n    *--deadline_job_preset*: The deadline preset for Deadline job/plugin info\n</code></pre> Editor CMD window <p>.. code-block:: shell</p> <pre><code>$ py mrq_cli.py &lt;--remote&gt; sequence sequence_name map mrq_preset_name\n</code></pre> Editor Commandline <p>.. code-block:: shell</p> <pre><code>UnrealEditor.exe uproject_name/path &lt;startup-args&gt; -execcmds=\"py mrq_cli.py sequence sequence_name map mrq_preset_name --cmdline\"\n</code></pre> <p>In a commandline interface, it is very important to append <code>--cmdline</code> to the script args as this will tell the editor to shut down after a render is complete. Currently, this is the only method to keep the editor open till a render is complete due to the default python commandlet assuming when a python script ends, the editor needs to shut down. This behavior is not ideal as PIE is an asynchronous process we need to wait for during rendering.</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.html","title":"mrq_rpc","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_rpc.MRQRender","title":"<code>MRQRender</code>","text":"<p>               Bases: <code>BaseRPC</code></p> <p>Class to execute deadline MRQ renders using RPC</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.py</code> <pre><code>class MRQRender(BaseRPC):\n    \"\"\"\n    Class to execute deadline MRQ renders using RPC\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Constructor\n        \"\"\"\n        super(MRQRender, self).__init__(*args, **kwargs)\n\n        self._render_cmd = [\"mrq_cli.py\"]\n\n        # Keep track of the task data\n        self._shot_data = None\n        self._queue = None\n        self._manifest = None\n        self._sequence_data = None\n\n    def _get_queue(self):\n        \"\"\"\n        Render a MRQ queue asset\n\n        :return: MRQ queue asset name\n        \"\"\"\n        if not self._queue:\n            self._queue = self.proxy.get_job_extra_info_key_value(\"queue_name\")\n\n        return self._queue\n\n    def _get_sequence_data(self):\n        \"\"\"\n        Get sequence data\n\n        :return: Sequence data\n        \"\"\"\n        if not self._sequence_data:\n            self._sequence_data = self.proxy.get_job_extra_info_key_value(\n                \"sequence_render\"\n            )\n\n        return self._sequence_data\n\n    def _get_serialized_pipeline(self):\n        \"\"\"\n        Get Serialized pipeline from Deadline\n\n        :return:\n        \"\"\"\n        if not self._manifest:\n            serialized_pipeline = self.proxy.get_job_extra_info_key_value(\n                \"serialized_pipeline\"\n            )\n            if not serialized_pipeline:\n                return\n\n            unreal.log(\n                f\"Executing Serialized Pipeline: `{serialized_pipeline}`\"\n            )\n\n            # create temp manifest folder\n            movieRenderPipeline_dir = os.path.join(\n                unreal.SystemLibrary.get_project_saved_directory(),\n                \"MovieRenderPipeline\",\n                \"TempManifests\",\n            )\n\n            if not os.path.exists(movieRenderPipeline_dir ):\n                os.makedirs(movieRenderPipeline_dir )\n\n            # create manifest file\n            manifest_file = unreal.Paths.create_temp_filename(\n                movieRenderPipeline_dir ,\n                prefix='TempManifest',\n                extension='.utxt')\n\n            unreal.log(f\"Saving Manifest file `{manifest_file}`\")\n\n            # Dump the manifest data into the manifest file\n            with open(manifest_file, \"w\") as manifest:\n                manifest.write(serialized_pipeline)\n\n            self._manifest = manifest_file\n\n        return self._manifest\n\n    def execute(self):\n        \"\"\"\n        Starts the render execution\n        \"\"\"\n\n        # shots are listed as a dictionary of task id -&gt; shotnames\n        # i.e {\"O\": \"my_new_shot\"} or {\"20\", \"shot_1,shot_2,shot_4\"}\n\n        # Get the task data and cache it\n        if not self._shot_data:\n            self._shot_data = json.loads(\n                self.proxy.get_job_extra_info_key_value(\"shot_info\")\n            )\n\n        # Get any output overrides\n        output_dir = self.proxy.get_job_extra_info_key_value(\n            \"output_directory_override\"\n        )\n\n        # Resolve any path mappings in the directory name. The server expects\n        # a list of paths, but we only ever expect one. So wrap it in a list\n        # if we have an output directory\n        if output_dir:\n            output_dir = self.proxy.check_path_mappings([output_dir])\n            output_dir = output_dir[0]\n\n        # Get the filename format\n        filename_format = self.proxy.get_job_extra_info_key_value(\n            \"filename_format_override\"\n        )\n\n        # Resolve any path mappings in the filename. The server expects\n        # a list of paths, but we only ever expect one. So wrap it in a list\n        if filename_format:\n            filename_format = self.proxy.check_path_mappings([filename_format])\n            filename_format = filename_format[0]\n\n        # get the shots for the current task\n        current_task_data = self._shot_data.get(str(self.current_task_id), None)\n\n        if not current_task_data:\n            self.proxy.fail_render(\"There are no task data to execute!\")\n            return\n\n        shots = current_task_data.split(\",\")\n\n        if self._get_queue():\n            return self.render_queue(\n                self._get_queue(),\n                shots,\n                output_dir_override=output_dir if output_dir else None,\n                filename_format_override=filename_format if filename_format else None\n            )\n\n        if self._get_serialized_pipeline():\n            return self.render_serialized_pipeline(\n                self._get_serialized_pipeline(),\n                shots,\n                output_dir_override=output_dir if output_dir else None,\n                filename_format_override=filename_format if filename_format else None\n            )\n\n        if self._get_sequence_data():\n            render_data = json.loads(self._get_sequence_data())\n            sequence = render_data.get(\"sequence_name\")\n            level = render_data.get(\"level_name\")\n            mrq_preset = render_data.get(\"mrq_preset_name\")\n            return self.render_sequence(\n                sequence,\n                level,\n                mrq_preset,\n                shots,\n                output_dir_override=output_dir if output_dir else None,\n                filename_format_override=filename_format if filename_format else None\n            )\n\n    def render_queue(\n        self,\n        queue_path,\n        shots,\n        output_dir_override=None,\n        filename_format_override=None\n    ):\n        \"\"\"\n        Executes a render from a queue\n\n        :param str queue_path: Name/path of the queue asset\n        :param list shots: Shots to render\n        :param str output_dir_override: Movie Pipeline output directory\n        :param str filename_format_override: Movie Pipeline filename format override\n        \"\"\"\n        unreal.log(f\"Executing Queue asset `{queue_path}`\")\n        unreal.log(f\"Rendering shots: {shots}\")\n\n        # Get an executor instance\n        executor = self._get_executor_instance()\n\n        # Set executor callbacks\n\n        # Set shot finished callbacks\n        executor.on_individual_shot_work_finished_delegate.add_callable(\n            self._on_individual_shot_finished_callback\n        )\n\n        # Set executor finished callbacks\n        executor.on_executor_finished_delegate.add_callable(\n            self._on_job_finished\n        )\n        executor.on_executor_errored_delegate.add_callable(self._on_job_failed)\n\n        # Render queue with executor\n        render_queue_asset(\n            queue_path,\n            shots=shots,\n            user=self.proxy.get_job_user(),\n            executor_instance=executor,\n            output_dir_override=output_dir_override,\n            output_filename_override=filename_format_override\n        )\n\n    def render_serialized_pipeline(\n        self,\n        manifest_file,\n        shots,\n        output_dir_override=None,\n        filename_format_override=None\n    ):\n        \"\"\"\n        Executes a render using a manifest file\n\n        :param str manifest_file: serialized pipeline used to render a manifest file\n        :param list shots: Shots to render\n        :param str output_dir_override: Movie Pipeline output directory\n        :param str filename_format_override: Movie Pipeline filename format override\n        \"\"\"\n        unreal.log(f\"Rendering shots: {shots}\")\n\n        # Get an executor instance\n        executor = self._get_executor_instance()\n\n        # Set executor callbacks\n\n        # Set shot finished callbacks\n        executor.on_individual_shot_work_finished_delegate.add_callable(\n            self._on_individual_shot_finished_callback\n        )\n\n        # Set executor finished callbacks\n        executor.on_executor_finished_delegate.add_callable(\n            self._on_job_finished\n        )\n        executor.on_executor_errored_delegate.add_callable(self._on_job_failed)\n\n        render_queue_manifest(\n            manifest_file,\n            shots=shots,\n            user=self.proxy.get_job_user(),\n            executor_instance=executor,\n            output_dir_override=output_dir_override,\n            output_filename_override=filename_format_override\n        )\n\n    def render_sequence(\n        self,\n        sequence,\n        level,\n        mrq_preset,\n        shots,\n        output_dir_override=None,\n        filename_format_override=None\n    ):\n        \"\"\"\n        Executes a render using a sequence level and map\n\n        :param str sequence: Level Sequence name\n        :param str level: Level\n        :param str mrq_preset: MovieRenderQueue preset\n        :param list shots: Shots to render\n        :param str output_dir_override: Movie Pipeline output directory\n        :param str filename_format_override: Movie Pipeline filename format override\n        \"\"\"\n        unreal.log(\n            f\"Executing sequence `{sequence}` with map `{level}` \"\n            f\"and mrq preset `{mrq_preset}`\"\n        )\n        unreal.log(f\"Rendering shots: {shots}\")\n\n        # Get an executor instance\n        executor = self._get_executor_instance()\n\n        # Set executor callbacks\n\n        # Set shot finished callbacks\n        executor.on_individual_shot_work_finished_delegate.add_callable(\n            self._on_individual_shot_finished_callback\n        )\n\n        # Set executor finished callbacks\n        executor.on_executor_finished_delegate.add_callable(\n            self._on_job_finished\n        )\n        executor.on_executor_errored_delegate.add_callable(self._on_job_failed)\n\n        render_current_sequence(\n            sequence,\n            level,\n            mrq_preset,\n            shots=shots,\n            user=self.proxy.get_job_user(),\n            executor_instance=executor,\n            output_dir_override=output_dir_override,\n            output_filename_override=filename_format_override\n        )\n\n    @staticmethod\n    def _get_executor_instance():\n        \"\"\"\n        Gets an instance of the movie pipeline executor\n\n        :return: Movie Pipeline Executor instance\n        \"\"\"\n        return utils.get_executor_instance(False)\n\n    def _on_individual_shot_finished_callback(self, shot_params):\n        \"\"\"\n        Callback to execute when a shot is done rendering\n\n        :param shot_params: Movie pipeline shot params\n        \"\"\"\n        unreal.log(\"Executing On individual shot callback\")\n\n        # Since MRQ cannot parse certain parameters/arguments till an actual\n        # render is complete (e.g. local version numbers), we will use this as\n        # an opportunity to update the deadline proxy on the actual frame\n        # details that were rendered\n\n        file_patterns = set()\n\n        # Iterate over all the shots in the shot list (typically one shot as\n        # this callback is executed) on a shot by shot bases.\n        for shot in shot_params.shot_data:\n            for pass_identifier in shot.render_pass_data:\n\n                # only get the first file\n                paths = shot.render_pass_data[pass_identifier].file_paths\n\n                # make sure we have paths to iterate on\n                if len(paths) &lt; 1:\n                    continue\n\n                # we only need the ext from the first file\n                ext = os.path.splitext(paths[0])[1].replace(\".\", \"\")\n\n                # Make sure we actually have an extension to use\n                if not ext:\n                    continue\n\n                # Get the current job output settings\n                output_settings = shot_params.job.get_configuration().find_or_add_setting_by_class(\n                    unreal.MoviePipelineOutputSetting\n                )\n\n                resolve_params = unreal.MoviePipelineFilenameResolveParams()\n\n                # Set the camera name from the shot data\n                resolve_params.camera_name_override = shot_params.shot_data[\n                    0\n                ].shot.inner_name\n\n                # set the shot name from the shot data\n                resolve_params.shot_name_override = shot_params.shot_data[\n                    0\n                ].shot.outer_name\n\n                # Get the zero padding configuration\n                resolve_params.zero_pad_frame_number_count = (\n                    output_settings.zero_pad_frame_numbers\n                )\n\n                # Update the formatting of frame numbers based on the padding.\n                # Deadline uses # (* padding) to display the file names in a job\n                resolve_params.file_name_format_overrides[\n                    \"frame_number\"\n                ] = \"#\" * int(output_settings.zero_pad_frame_numbers)\n\n                # Update the extension\n                resolve_params.file_name_format_overrides[\"ext\"] = ext\n\n                # Set the job on the resolver\n                resolve_params.job = shot_params.job\n\n                # Set the initialization time on the resolver\n                resolve_params.initialization_time = (\n                    unreal.MoviePipelineLibrary.get_job_initialization_time(\n                        shot_params.pipeline\n                    )\n                )\n\n                # Set the shot overrides\n                resolve_params.shot_override = shot_params.shot_data[0].shot\n\n                combined_path = unreal.Paths.combine(\n                    [\n                        output_settings.output_directory.path,\n                        output_settings.file_name_format,\n                    ]\n                )\n\n                # Resolve the paths\n                # The returned values are a tuple with the resolved paths as the\n                # first index. Get the paths and add it to a list\n                (\n                    path,\n                    _,\n                ) = unreal.MoviePipelineLibrary.resolve_filename_format_arguments(\n                    combined_path, resolve_params\n                )\n\n                # Make sure we are getting the right type from resolved\n                # arguments\n                if isinstance(path, str):\n                    # Sanitize the paths\n                    path = os.path.normpath(path).replace(\"\\\\\", \"/\")\n                    file_patterns.add(path)\n\n                elif isinstance(path, list):\n\n                    file_patterns.update(\n                        set(\n                            [\n                                os.path.normpath(p).replace(\"\\\\\", \"/\")\n                                for p in path\n                            ]\n                        )\n                    )\n\n                else:\n                    raise RuntimeError(\n                        f\"Expected the shot file paths to be a \"\n                        f\"string or list but got: {type(path)}\"\n                    )\n\n        if file_patterns:\n            unreal.log(f'Updating remote filenames: {\", \".join(file_patterns)}')\n\n            # Update the paths on the deadline job\n            self.proxy.update_job_output_filenames(list(file_patterns))\n\n    def _on_job_finished(self, executor=None, success=None):\n        \"\"\"\n        Callback to execute on executor finished\n        \"\"\"\n        # TODO: add th ability to set the output directory for the task\n        unreal.log(f\"Task {self.current_task_id} complete!\")\n        self.task_complete = True\n\n    def _on_job_failed(self, executor, pipeline, is_fatal, error):\n        \"\"\"\n        Callback to execute on job failed\n        \"\"\"\n        unreal.log_error(f\"Is fatal job error: {is_fatal}\")\n        unreal.log_error(\n            f\"An error occurred executing task `{self.current_task_id}`: \\n\\t{error}\"\n        )\n        self.proxy.fail_render(error)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_rpc.MRQRender.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Constructor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Constructor\n    \"\"\"\n    super(MRQRender, self).__init__(*args, **kwargs)\n\n    self._render_cmd = [\"mrq_cli.py\"]\n\n    # Keep track of the task data\n    self._shot_data = None\n    self._queue = None\n    self._manifest = None\n    self._sequence_data = None\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_rpc.MRQRender.execute","title":"<code>execute()</code>","text":"<p>Starts the render execution</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.py</code> <pre><code>def execute(self):\n    \"\"\"\n    Starts the render execution\n    \"\"\"\n\n    # shots are listed as a dictionary of task id -&gt; shotnames\n    # i.e {\"O\": \"my_new_shot\"} or {\"20\", \"shot_1,shot_2,shot_4\"}\n\n    # Get the task data and cache it\n    if not self._shot_data:\n        self._shot_data = json.loads(\n            self.proxy.get_job_extra_info_key_value(\"shot_info\")\n        )\n\n    # Get any output overrides\n    output_dir = self.proxy.get_job_extra_info_key_value(\n        \"output_directory_override\"\n    )\n\n    # Resolve any path mappings in the directory name. The server expects\n    # a list of paths, but we only ever expect one. So wrap it in a list\n    # if we have an output directory\n    if output_dir:\n        output_dir = self.proxy.check_path_mappings([output_dir])\n        output_dir = output_dir[0]\n\n    # Get the filename format\n    filename_format = self.proxy.get_job_extra_info_key_value(\n        \"filename_format_override\"\n    )\n\n    # Resolve any path mappings in the filename. The server expects\n    # a list of paths, but we only ever expect one. So wrap it in a list\n    if filename_format:\n        filename_format = self.proxy.check_path_mappings([filename_format])\n        filename_format = filename_format[0]\n\n    # get the shots for the current task\n    current_task_data = self._shot_data.get(str(self.current_task_id), None)\n\n    if not current_task_data:\n        self.proxy.fail_render(\"There are no task data to execute!\")\n        return\n\n    shots = current_task_data.split(\",\")\n\n    if self._get_queue():\n        return self.render_queue(\n            self._get_queue(),\n            shots,\n            output_dir_override=output_dir if output_dir else None,\n            filename_format_override=filename_format if filename_format else None\n        )\n\n    if self._get_serialized_pipeline():\n        return self.render_serialized_pipeline(\n            self._get_serialized_pipeline(),\n            shots,\n            output_dir_override=output_dir if output_dir else None,\n            filename_format_override=filename_format if filename_format else None\n        )\n\n    if self._get_sequence_data():\n        render_data = json.loads(self._get_sequence_data())\n        sequence = render_data.get(\"sequence_name\")\n        level = render_data.get(\"level_name\")\n        mrq_preset = render_data.get(\"mrq_preset_name\")\n        return self.render_sequence(\n            sequence,\n            level,\n            mrq_preset,\n            shots,\n            output_dir_override=output_dir if output_dir else None,\n            filename_format_override=filename_format if filename_format else None\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_rpc.MRQRender.render_queue","title":"<code>render_queue(queue_path, shots, output_dir_override=None, filename_format_override=None)</code>","text":"<p>Executes a render from a queue</p> <p>:param str queue_path: Name/path of the queue asset :param list shots: Shots to render :param str output_dir_override: Movie Pipeline output directory :param str filename_format_override: Movie Pipeline filename format override</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.py</code> <pre><code>def render_queue(\n    self,\n    queue_path,\n    shots,\n    output_dir_override=None,\n    filename_format_override=None\n):\n    \"\"\"\n    Executes a render from a queue\n\n    :param str queue_path: Name/path of the queue asset\n    :param list shots: Shots to render\n    :param str output_dir_override: Movie Pipeline output directory\n    :param str filename_format_override: Movie Pipeline filename format override\n    \"\"\"\n    unreal.log(f\"Executing Queue asset `{queue_path}`\")\n    unreal.log(f\"Rendering shots: {shots}\")\n\n    # Get an executor instance\n    executor = self._get_executor_instance()\n\n    # Set executor callbacks\n\n    # Set shot finished callbacks\n    executor.on_individual_shot_work_finished_delegate.add_callable(\n        self._on_individual_shot_finished_callback\n    )\n\n    # Set executor finished callbacks\n    executor.on_executor_finished_delegate.add_callable(\n        self._on_job_finished\n    )\n    executor.on_executor_errored_delegate.add_callable(self._on_job_failed)\n\n    # Render queue with executor\n    render_queue_asset(\n        queue_path,\n        shots=shots,\n        user=self.proxy.get_job_user(),\n        executor_instance=executor,\n        output_dir_override=output_dir_override,\n        output_filename_override=filename_format_override\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_rpc.MRQRender.render_sequence","title":"<code>render_sequence(sequence, level, mrq_preset, shots, output_dir_override=None, filename_format_override=None)</code>","text":"<p>Executes a render using a sequence level and map</p> <p>:param str sequence: Level Sequence name :param str level: Level :param str mrq_preset: MovieRenderQueue preset :param list shots: Shots to render :param str output_dir_override: Movie Pipeline output directory :param str filename_format_override: Movie Pipeline filename format override</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.py</code> <pre><code>def render_sequence(\n    self,\n    sequence,\n    level,\n    mrq_preset,\n    shots,\n    output_dir_override=None,\n    filename_format_override=None\n):\n    \"\"\"\n    Executes a render using a sequence level and map\n\n    :param str sequence: Level Sequence name\n    :param str level: Level\n    :param str mrq_preset: MovieRenderQueue preset\n    :param list shots: Shots to render\n    :param str output_dir_override: Movie Pipeline output directory\n    :param str filename_format_override: Movie Pipeline filename format override\n    \"\"\"\n    unreal.log(\n        f\"Executing sequence `{sequence}` with map `{level}` \"\n        f\"and mrq preset `{mrq_preset}`\"\n    )\n    unreal.log(f\"Rendering shots: {shots}\")\n\n    # Get an executor instance\n    executor = self._get_executor_instance()\n\n    # Set executor callbacks\n\n    # Set shot finished callbacks\n    executor.on_individual_shot_work_finished_delegate.add_callable(\n        self._on_individual_shot_finished_callback\n    )\n\n    # Set executor finished callbacks\n    executor.on_executor_finished_delegate.add_callable(\n        self._on_job_finished\n    )\n    executor.on_executor_errored_delegate.add_callable(self._on_job_failed)\n\n    render_current_sequence(\n        sequence,\n        level,\n        mrq_preset,\n        shots=shots,\n        user=self.proxy.get_job_user(),\n        executor_instance=executor,\n        output_dir_override=output_dir_override,\n        output_filename_override=filename_format_override\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_rpc.MRQRender.render_serialized_pipeline","title":"<code>render_serialized_pipeline(manifest_file, shots, output_dir_override=None, filename_format_override=None)</code>","text":"<p>Executes a render using a manifest file</p> <p>:param str manifest_file: serialized pipeline used to render a manifest file :param list shots: Shots to render :param str output_dir_override: Movie Pipeline output directory :param str filename_format_override: Movie Pipeline filename format override</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_rpc.py</code> <pre><code>def render_serialized_pipeline(\n    self,\n    manifest_file,\n    shots,\n    output_dir_override=None,\n    filename_format_override=None\n):\n    \"\"\"\n    Executes a render using a manifest file\n\n    :param str manifest_file: serialized pipeline used to render a manifest file\n    :param list shots: Shots to render\n    :param str output_dir_override: Movie Pipeline output directory\n    :param str filename_format_override: Movie Pipeline filename format override\n    \"\"\"\n    unreal.log(f\"Rendering shots: {shots}\")\n\n    # Get an executor instance\n    executor = self._get_executor_instance()\n\n    # Set executor callbacks\n\n    # Set shot finished callbacks\n    executor.on_individual_shot_work_finished_delegate.add_callable(\n        self._on_individual_shot_finished_callback\n    )\n\n    # Set executor finished callbacks\n    executor.on_executor_finished_delegate.add_callable(\n        self._on_job_finished\n    )\n    executor.on_executor_errored_delegate.add_callable(self._on_job_failed)\n\n    render_queue_manifest(\n        manifest_file,\n        shots=shots,\n        user=self.proxy.get_job_user(),\n        executor_instance=executor,\n        output_dir_override=output_dir_override,\n        output_filename_override=filename_format_override\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/remote_executor.html","title":"remote_executor","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/remote_executor.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.remote_executor.MoviePipelineDeadlineRemoteExecutor","title":"<code>MoviePipelineDeadlineRemoteExecutor</code>","text":"<p>               Bases: <code>MoviePipelineExecutorBase</code></p> <p>This class defines the editor implementation for Deadline (what happens when you press 'Render (Remote)', which is in charge of taking a movie queue from the UI and processing it into something Deadline can handle.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/remote_executor.py</code> <pre><code>@unreal.uclass()\nclass MoviePipelineDeadlineRemoteExecutor(unreal.MoviePipelineExecutorBase):\n    \"\"\"\n    This class defines the editor implementation for Deadline (what happens when you\n    press 'Render (Remote)', which is in charge of taking a movie queue from the UI\n    and processing it into something Deadline can handle.\n    \"\"\"\n\n    # The queue we are working on, null if no queue has been provided.\n    pipeline_queue = unreal.uproperty(unreal.MoviePipelineQueue)\n    job_ids = unreal.uproperty(unreal.Array(str))\n\n    # A MoviePipelineExecutor implementation must override this.\n    @unreal.ufunction(override=True)\n    def execute(self, pipeline_queue):\n        \"\"\"\n        This is called when the user presses Render (Remote) in the UI. We will\n        split the queue up into multiple jobs. Each job will be submitted to\n        deadline separately, with each shot within the job split into one Deadline\n        task per shot.\n        \"\"\"\n\n        unreal.log(f\"Asked to execute Queue: {pipeline_queue}\")\n        unreal.log(f\"Queue has {len(pipeline_queue.get_jobs())} jobs\")\n\n        # Don't try to process empty/null Queues, no need to send them to\n        # Deadline.\n        if not pipeline_queue or (not pipeline_queue.get_jobs()):\n            self.on_executor_finished_impl()\n            return\n\n        # The user must save their work and check it in so that Deadline\n        # can sync it.\n        dirty_packages = []\n        dirty_packages.extend(\n            unreal.EditorLoadingAndSavingUtils.get_dirty_content_packages()\n        )\n        dirty_packages.extend(\n            unreal.EditorLoadingAndSavingUtils.get_dirty_map_packages()\n        )\n\n        # Sometimes the dialog will return `False`\n        # even when there are no packages to save. so we are\n        # being explict about the packages we need to save\n        if dirty_packages:\n            if not unreal.EditorLoadingAndSavingUtils.save_dirty_packages_with_dialog(\n                True, True\n            ):\n                message = (\n                    \"One or more jobs in the queue have an unsaved map/content. \"\n                    \"{packages} \"\n                    \"Please save and check-in all work before submission.\".format(\n                        packages=\"\\n\".join(dirty_packages)\n                    )\n                )\n\n                unreal.log_error(message)\n                unreal.EditorDialog.show_message(\n                    \"Unsaved Maps/Content\", message, unreal.AppMsgType.OK\n                )\n                self.on_executor_finished_impl()\n                return\n\n        # Make sure all the maps in the queue exist on disk somewhere,\n        # unsaved maps can't be loaded on the remote machine, and it's common\n        # to have the wrong map name if you submit without loading the map.\n        has_valid_map = (\n            unreal.MoviePipelineEditorLibrary.is_map_valid_for_remote_render(\n                pipeline_queue.get_jobs()\n            )\n        )\n        if not has_valid_map:\n            message = (\n                \"One or more jobs in the queue have an unsaved map as \"\n                \"their target map. \"\n                \"These unsaved maps cannot be loaded by an external process, \"\n                \"and the render has been aborted.\"\n            )\n            unreal.log_error(message)\n            unreal.EditorDialog.show_message(\n                \"Unsaved Maps\", message, unreal.AppMsgType.OK\n            )\n            self.on_executor_finished_impl()\n            return\n\n        self.pipeline_queue = pipeline_queue\n\n        deadline_settings = unreal.get_default_object(\n            unreal.MoviePipelineDeadlineSettings\n        )\n\n        # Arguments to pass to the executable. This can be modified by settings\n        # in the event a setting needs to be applied early.\n        # In the format of -foo -bar\n        # commandLineArgs = \"\"\n        command_args = []\n\n        # Append all of our inherited command line arguments from the editor.\n        in_process_executor_settings = unreal.get_default_object(\n            unreal.MoviePipelineInProcessExecutorSettings\n        )\n        inherited_cmds = in_process_executor_settings.inherited_command_line_arguments\n\n        # Sanitize the commandline by removing any execcmds that may\n        # have passed through the commandline.\n        # We remove the execcmds because, in some cases, users may execute a\n        # script that is local to their editor build for some automated\n        # workflow but this is not ideal on the farm. We will expect all\n        # custom startup commands for rendering to go through the `Start\n        # Command` in the MRQ settings.\n        inherited_cmds = re.sub(\n            \".*(?P&lt;cmds&gt;-execcmds=[\\s\\S]+[\\'\\\"])\",\n            \"\",\n            inherited_cmds\n        )\n\n        command_args.extend(inherited_cmds.split(\" \"))\n        command_args.extend(\n            in_process_executor_settings.additional_command_line_arguments.split(\n                \" \"\n            )\n        )\n\n        command_args.extend(\n            [\"-nohmd\", \"-windowed\", f\"-ResX=1280\", f\"-ResY=720\"]\n        )\n\n        # Get the project level preset\n        project_preset = deadline_settings.default_job_preset\n\n        # Get the job and plugin info string.\n        # Note:\n        #   Sometimes a project level default may not be set,\n        #   so if this returns an empty dictionary, that is okay\n        #   as we primarily care about the job level preset.\n        #   Catch any exceptions here and continue\n        try:\n            project_job_info, project_plugin_info = get_deadline_info_from_preset(job_preset=project_preset)\n\n        except Exception:\n            pass\n\n        deadline_service = get_global_deadline_service_instance()\n\n        for job in self.pipeline_queue.get_jobs():\n\n            unreal.log(f\"Submitting Job `{job.job_name}` to Deadline...\")\n\n            try:\n                # Create a Deadline job object with the default project level\n                # job info and plugin info\n                deadline_job = DeadlineJob(project_job_info, project_plugin_info)\n\n                deadline_job_id = self.submit_job(\n                    job, deadline_job, command_args, deadline_service\n                )\n\n            except Exception as err:\n                unreal.log_error(\n                    f\"Failed to submit job `{job.job_name}` to Deadline, aborting render. \\n\\tError: {str(err)}\"\n                )\n                unreal.log_error(traceback.format_exc())\n                self.on_executor_errored_impl(None, True, str(err))\n                unreal.EditorDialog.show_message(\n                    \"Submission Result\",\n                    f\"Failed to submit job `{job.job_name}` to Deadline with error: {str(err)}. \"\n                    f\"See log for more details.\",\n                    unreal.AppMsgType.OK,\n                )\n                self.on_executor_finished_impl()\n                return\n\n            if not deadline_job_id:\n                message = (\n                    f\"A problem occurred submitting `{job.job_name}`. \"\n                    f\"Either the job doesn't have any data to submit, \"\n                    f\"or an error occurred getting the Deadline JobID. \"\n                    f\"This job status would not be reflected in the UI. \"\n                    f\"Check the logs for more details.\"\n                )\n                unreal.log_warning(message)\n                unreal.EditorDialog.show_message(\n                    \"Submission Result\", message, unreal.AppMsgType.OK\n                )\n                return\n\n            else:\n                unreal.log(f\"Deadline JobId: {deadline_job_id}\")\n                self.job_ids.append(deadline_job_id)\n\n                # Store the Deadline JobId in our job (the one that exists in\n                # the queue, not the duplicate) so we can match up Movie\n                # Pipeline jobs with status updates from Deadline.\n                job.user_data = deadline_job_id\n\n        # Now that we've sent a job to Deadline, we're going to request a status\n        # update on them so that they transition from \"Ready\" to \"Queued\" or\n        # their actual status in Deadline. self.request_job_status_update(\n        # deadline_service)\n\n        message = (\n            f\"Successfully submitted {len(self.job_ids)} jobs to Deadline. JobIds: {', '.join(self.job_ids)}. \"\n            f\"\\nPlease use Deadline Monitor to track render job statuses\"\n        )\n        unreal.log(message)\n\n        unreal.EditorDialog.show_message(\n            \"Submission Result\", message, unreal.AppMsgType.OK\n        )\n\n        # Set the executor to finished\n        self.on_executor_finished_impl()\n\n    @unreal.ufunction(override=True)\n    def is_rendering(self):\n        # Because we forward unfinished jobs onto another service when the\n        # button is pressed, they can always submit what is in the queue and\n        # there's no need to block the queue.\n        # A MoviePipelineExecutor implementation must override this. If you\n        # override a ufunction from a base class you don't specify the return\n        # type or parameter types.\n        return False\n\n    def submit_job(self, job, deadline_job, command_args, deadline_service):\n        \"\"\"\n        Submit a new Job to Deadline\n        :param job: Queued job to submit\n        :param deadline_job: Deadline job object\n        :param list[str] command_args: Commandline arguments to configure for the Deadline Job\n        :param deadline_service: An instance of the deadline service object\n        :returns: Deadline Job ID\n        :rtype: str\n        \"\"\"\n\n        # Get the Job Info and plugin Info\n        # If we have a preset set on the job, get the deadline submission details\n        try:\n            job_info, plugin_info = get_deadline_info_from_preset(job_preset_struct=job.get_deadline_job_preset_struct_with_overrides())\n\n        # Fail the submission if any errors occur\n        except Exception as err:\n            raise RuntimeError(\n                f\"An error occurred getting the deadline job and plugin \"\n                f\"details. \\n\\tError: {err} \"\n            )\n\n        # check for required fields in pluginInfo\n        if \"Executable\" not in plugin_info:\n            raise RuntimeError(\"An error occurred formatting the Plugin Info string. \\n\\tMissing \\\"Executable\\\" key\")\n        elif not plugin_info[\"Executable\"]:\n            raise RuntimeError(f\"An error occurred formatting the Plugin Info string. \\n\\tExecutable value cannot be empty\")\n        if \"ProjectFile\" not in plugin_info:\n            raise RuntimeError(\"An error occurred formatting the Plugin Info string. \\n\\tMissing \\\"ProjectFile\\\" key\")\n        elif not plugin_info[\"ProjectFile\"]:\n            raise RuntimeError(f\"An error occurred formatting the Plugin Info string. \\n\\tProjectFile value cannot be empty\")\n\n        # Update the job info with overrides from the UI\n        if job.batch_name:\n            job_info[\"BatchName\"] = job.batch_name\n\n        if hasattr(job, \"comment\") and not job_info.get(\"Comment\"):\n            job_info[\"Comment\"] = job.comment\n\n        if not job_info.get(\"Name\") or job_info[\"Name\"] == \"Untitled\":\n            job_info[\"Name\"] = job.job_name\n\n        if job.author:\n            job_info[\"UserName\"] = job.author\n\n        if unreal.Paths.is_project_file_path_set():\n            # Trim down to just \"Game.uproject\" instead of absolute path.\n            game_name_or_project_file = (\n                unreal.Paths.convert_relative_path_to_full(\n                    unreal.Paths.get_project_file_path()\n                )\n            )\n\n        else:\n            raise RuntimeError(\n                \"Failed to get a project name. Please set a project!\"\n            )\n\n        # Create a new queue with only this job in it and save it to disk,\n        # then load it, so we can send it with the REST API\n        new_queue = unreal.MoviePipelineQueue()\n        new_job = new_queue.duplicate_job(job)\n\n        duplicated_queue, manifest_path = unreal.MoviePipelineEditorLibrary.save_queue_to_manifest_file(\n            new_queue\n        )\n\n        # Convert the queue to text (load the serialized json from disk) so we\n        # can send it via deadline, and deadline will write the queue to the\n        # local machines on job startup.\n        serialized_pipeline = unreal.MoviePipelineEditorLibrary.convert_manifest_file_to_string(\n            manifest_path\n        )\n\n        # Loop through our settings in the job and let them modify the command\n        # line arguments/params.\n        new_job.get_configuration().initialize_transient_settings()\n        # Look for our Game Override setting to pull the game mode to start\n        # with. We start with this game mode even on a blank map to override\n        # the project default from kicking in.\n        game_override_class = None\n\n        out_url_params = []\n        out_command_line_args = []\n        out_device_profile_cvars = []\n        out_exec_cmds = []\n        for setting in new_job.get_configuration().get_all_settings():\n\n            out_url_params, out_command_line_args, out_device_profile_cvars, out_exec_cmds = setting.build_new_process_command_line_args(\n                out_url_params,\n                out_command_line_args,\n                out_device_profile_cvars,\n                out_exec_cmds,\n            )\n\n            # Set the game override\n            if setting.get_class() == unreal.MoviePipelineGameOverrideSetting.static_class():\n                game_override_class = setting.game_mode_override\n\n        # This triggers the editor to start looking for render jobs when it\n        # finishes loading.\n        out_exec_cmds.append(\"py mrq_rpc.py\")\n\n        # Convert the arrays of command line args, device profile cvars,\n        # and exec cmds into actual commands for our command line.\n        command_args.extend(out_command_line_args)\n\n        if out_device_profile_cvars:\n            # -dpcvars=\"arg0,arg1,...\"\n            command_args.append(\n                '-dpcvars=\"{dpcvars}\"'.format(\n                    dpcvars=\",\".join(out_device_profile_cvars)\n                )\n            )\n\n        if out_exec_cmds:\n            # -execcmds=\"cmd0,cmd1,...\"\n            command_args.append(\n                '-execcmds=\"{cmds}\"'.format(cmds=\",\".join(out_exec_cmds))\n            )\n\n        # Add support for telling the remote process to wait for the\n        # asset registry to complete synchronously\n        command_args.append(\"-waitonassetregistry\")\n\n        # Build a shot-mask from this sequence, to split into the appropriate\n        # number of tasks. Remove any already-disabled shots before we\n        # generate a list, otherwise we make unneeded tasks which get sent to\n        # machines\n        shots_to_render = []\n        for shot_index, shot in enumerate(new_job.shot_info):\n            if not shot.enabled:\n                unreal.log(\n                    f\"Skipped submitting shot {shot_index} in {job.job_name} \"\n                    f\"to server due to being already disabled!\"\n                )\n            else:\n                shots_to_render.append(shot.outer_name)\n\n        # If there are no shots enabled,\n        # \"these are not the droids we are looking for\", move along ;)\n        # We will catch this later and deal with it\n        if not shots_to_render:\n            unreal.log_warning(\"No shots enabled in shot mask, not submitting.\")\n            return\n\n        # Divide the job to render by the chunk size\n        # i.e {\"O\": \"my_new_shot\"} or {\"0\", \"shot_1,shot_2,shot_4\"}\n        chunk_size = int(job_info.get(\"ChunkSize\", 1))\n        shots = {}\n        frame_list = []\n        for index in range(0, len(shots_to_render), chunk_size):\n\n            shots[str(index)] = \",\".join(shots_to_render[index : index + chunk_size])\n\n            frame_list.append(str(index))\n\n        job_info[\"Frames\"] = \",\".join(frame_list)\n\n        # Get the current index of the ExtraInfoKeyValue pair, we will\n        # increment the index, so we do not stomp other settings\n        extra_info_key_indexs = set()\n        for key in job_info.keys():\n            if key.startswith(\"ExtraInfoKeyValue\"):\n                _, index = key.split(\"ExtraInfoKeyValue\")\n                extra_info_key_indexs.add(int(index))\n\n        # Get the highest number in the index list and increment the number\n        # by one\n        current_index = max(extra_info_key_indexs) + 1 if extra_info_key_indexs else 0\n\n        # Put the serialized Queue into the Job data but hidden from\n        # Deadline UI\n        job_info[f\"ExtraInfoKeyValue{current_index}\"] = f\"serialized_pipeline={serialized_pipeline}\"\n\n        # Increment the index\n        current_index += 1\n\n        # Put the shot info in the job extra info keys\n        job_info[f\"ExtraInfoKeyValue{current_index}\"] = f\"shot_info={json.dumps(shots)}\"\n        current_index += 1\n\n        # Set the job output directory override on the deadline job\n        if hasattr(new_job, \"output_directory_override\"):\n            if new_job.output_directory_override.path:\n                job_info[f\"ExtraInfoKeyValue{current_index}\"] = f\"output_directory_override={new_job.output_directory_override.path}\"\n\n                current_index += 1\n\n        # Set the job filename format override on the deadline job\n        if hasattr(new_job, \"filename_format_override\"):\n            if new_job.filename_format_override:\n                job_info[f\"ExtraInfoKeyValue{current_index}\"] = f\"filename_format_override={new_job.filename_format_override}\"\n\n                current_index += 1\n\n        # Build the command line arguments the remote machine will use.\n        # The Deadline plugin will provide the executable since it is local to\n        # the machine. It will also write out queue manifest to the correct\n        # location relative to the Saved folder\n\n        # Get the current commandline args from the plugin info\n        plugin_info_cmd_args = [plugin_info.get(\"CommandLineArguments\", \"\")]\n\n        if not plugin_info.get(\"ProjectFile\"):\n            project_file = plugin_info.get(\"ProjectFile\", game_name_or_project_file)\n            plugin_info[\"ProjectFile\"] = project_file\n\n        # This is the map included in the plugin to boot up to.\n        project_cmd_args = [\n            f\"MoviePipelineEntryMap?game={game_override_class.get_path_name()}\"\n        ]\n\n        # Combine all the compiled arguments\n        full_cmd_args = project_cmd_args + command_args + plugin_info_cmd_args\n\n        # Remove any duplicates in the commandline args and convert to a string\n        full_cmd_args = \" \".join(list(OrderedDict.fromkeys(full_cmd_args))).strip()\n\n        unreal.log(f\"Deadline job command line args: {full_cmd_args}\")\n\n        # Update the plugin info with the commandline arguments\n        plugin_info.update(\n            {\n                \"CommandLineArguments\": full_cmd_args,\n                \"CommandLineMode\": \"false\",\n            }\n        )\n\n        deadline_job.job_info = job_info\n        deadline_job.plugin_info = plugin_info\n\n        # Submit the deadline job\n        return deadline_service.submit_job(deadline_job)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/remote_executor.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.remote_executor.MoviePipelineDeadlineRemoteExecutor.execute","title":"<code>execute(pipeline_queue)</code>","text":"<p>This is called when the user presses Render (Remote) in the UI. We will split the queue up into multiple jobs. Each job will be submitted to deadline separately, with each shot within the job split into one Deadline task per shot.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/remote_executor.py</code> <pre><code>@unreal.ufunction(override=True)\ndef execute(self, pipeline_queue):\n    \"\"\"\n    This is called when the user presses Render (Remote) in the UI. We will\n    split the queue up into multiple jobs. Each job will be submitted to\n    deadline separately, with each shot within the job split into one Deadline\n    task per shot.\n    \"\"\"\n\n    unreal.log(f\"Asked to execute Queue: {pipeline_queue}\")\n    unreal.log(f\"Queue has {len(pipeline_queue.get_jobs())} jobs\")\n\n    # Don't try to process empty/null Queues, no need to send them to\n    # Deadline.\n    if not pipeline_queue or (not pipeline_queue.get_jobs()):\n        self.on_executor_finished_impl()\n        return\n\n    # The user must save their work and check it in so that Deadline\n    # can sync it.\n    dirty_packages = []\n    dirty_packages.extend(\n        unreal.EditorLoadingAndSavingUtils.get_dirty_content_packages()\n    )\n    dirty_packages.extend(\n        unreal.EditorLoadingAndSavingUtils.get_dirty_map_packages()\n    )\n\n    # Sometimes the dialog will return `False`\n    # even when there are no packages to save. so we are\n    # being explict about the packages we need to save\n    if dirty_packages:\n        if not unreal.EditorLoadingAndSavingUtils.save_dirty_packages_with_dialog(\n            True, True\n        ):\n            message = (\n                \"One or more jobs in the queue have an unsaved map/content. \"\n                \"{packages} \"\n                \"Please save and check-in all work before submission.\".format(\n                    packages=\"\\n\".join(dirty_packages)\n                )\n            )\n\n            unreal.log_error(message)\n            unreal.EditorDialog.show_message(\n                \"Unsaved Maps/Content\", message, unreal.AppMsgType.OK\n            )\n            self.on_executor_finished_impl()\n            return\n\n    # Make sure all the maps in the queue exist on disk somewhere,\n    # unsaved maps can't be loaded on the remote machine, and it's common\n    # to have the wrong map name if you submit without loading the map.\n    has_valid_map = (\n        unreal.MoviePipelineEditorLibrary.is_map_valid_for_remote_render(\n            pipeline_queue.get_jobs()\n        )\n    )\n    if not has_valid_map:\n        message = (\n            \"One or more jobs in the queue have an unsaved map as \"\n            \"their target map. \"\n            \"These unsaved maps cannot be loaded by an external process, \"\n            \"and the render has been aborted.\"\n        )\n        unreal.log_error(message)\n        unreal.EditorDialog.show_message(\n            \"Unsaved Maps\", message, unreal.AppMsgType.OK\n        )\n        self.on_executor_finished_impl()\n        return\n\n    self.pipeline_queue = pipeline_queue\n\n    deadline_settings = unreal.get_default_object(\n        unreal.MoviePipelineDeadlineSettings\n    )\n\n    # Arguments to pass to the executable. This can be modified by settings\n    # in the event a setting needs to be applied early.\n    # In the format of -foo -bar\n    # commandLineArgs = \"\"\n    command_args = []\n\n    # Append all of our inherited command line arguments from the editor.\n    in_process_executor_settings = unreal.get_default_object(\n        unreal.MoviePipelineInProcessExecutorSettings\n    )\n    inherited_cmds = in_process_executor_settings.inherited_command_line_arguments\n\n    # Sanitize the commandline by removing any execcmds that may\n    # have passed through the commandline.\n    # We remove the execcmds because, in some cases, users may execute a\n    # script that is local to their editor build for some automated\n    # workflow but this is not ideal on the farm. We will expect all\n    # custom startup commands for rendering to go through the `Start\n    # Command` in the MRQ settings.\n    inherited_cmds = re.sub(\n        \".*(?P&lt;cmds&gt;-execcmds=[\\s\\S]+[\\'\\\"])\",\n        \"\",\n        inherited_cmds\n    )\n\n    command_args.extend(inherited_cmds.split(\" \"))\n    command_args.extend(\n        in_process_executor_settings.additional_command_line_arguments.split(\n            \" \"\n        )\n    )\n\n    command_args.extend(\n        [\"-nohmd\", \"-windowed\", f\"-ResX=1280\", f\"-ResY=720\"]\n    )\n\n    # Get the project level preset\n    project_preset = deadline_settings.default_job_preset\n\n    # Get the job and plugin info string.\n    # Note:\n    #   Sometimes a project level default may not be set,\n    #   so if this returns an empty dictionary, that is okay\n    #   as we primarily care about the job level preset.\n    #   Catch any exceptions here and continue\n    try:\n        project_job_info, project_plugin_info = get_deadline_info_from_preset(job_preset=project_preset)\n\n    except Exception:\n        pass\n\n    deadline_service = get_global_deadline_service_instance()\n\n    for job in self.pipeline_queue.get_jobs():\n\n        unreal.log(f\"Submitting Job `{job.job_name}` to Deadline...\")\n\n        try:\n            # Create a Deadline job object with the default project level\n            # job info and plugin info\n            deadline_job = DeadlineJob(project_job_info, project_plugin_info)\n\n            deadline_job_id = self.submit_job(\n                job, deadline_job, command_args, deadline_service\n            )\n\n        except Exception as err:\n            unreal.log_error(\n                f\"Failed to submit job `{job.job_name}` to Deadline, aborting render. \\n\\tError: {str(err)}\"\n            )\n            unreal.log_error(traceback.format_exc())\n            self.on_executor_errored_impl(None, True, str(err))\n            unreal.EditorDialog.show_message(\n                \"Submission Result\",\n                f\"Failed to submit job `{job.job_name}` to Deadline with error: {str(err)}. \"\n                f\"See log for more details.\",\n                unreal.AppMsgType.OK,\n            )\n            self.on_executor_finished_impl()\n            return\n\n        if not deadline_job_id:\n            message = (\n                f\"A problem occurred submitting `{job.job_name}`. \"\n                f\"Either the job doesn't have any data to submit, \"\n                f\"or an error occurred getting the Deadline JobID. \"\n                f\"This job status would not be reflected in the UI. \"\n                f\"Check the logs for more details.\"\n            )\n            unreal.log_warning(message)\n            unreal.EditorDialog.show_message(\n                \"Submission Result\", message, unreal.AppMsgType.OK\n            )\n            return\n\n        else:\n            unreal.log(f\"Deadline JobId: {deadline_job_id}\")\n            self.job_ids.append(deadline_job_id)\n\n            # Store the Deadline JobId in our job (the one that exists in\n            # the queue, not the duplicate) so we can match up Movie\n            # Pipeline jobs with status updates from Deadline.\n            job.user_data = deadline_job_id\n\n    # Now that we've sent a job to Deadline, we're going to request a status\n    # update on them so that they transition from \"Ready\" to \"Queued\" or\n    # their actual status in Deadline. self.request_job_status_update(\n    # deadline_service)\n\n    message = (\n        f\"Successfully submitted {len(self.job_ids)} jobs to Deadline. JobIds: {', '.join(self.job_ids)}. \"\n        f\"\\nPlease use Deadline Monitor to track render job statuses\"\n    )\n    unreal.log(message)\n\n    unreal.EditorDialog.show_message(\n        \"Submission Result\", message, unreal.AppMsgType.OK\n    )\n\n    # Set the executor to finished\n    self.on_executor_finished_impl()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/remote_executor.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.remote_executor.MoviePipelineDeadlineRemoteExecutor.submit_job","title":"<code>submit_job(job, deadline_job, command_args, deadline_service)</code>","text":"<p>Submit a new Job to Deadline :param job: Queued job to submit :param deadline_job: Deadline job object :param list[str] command_args: Commandline arguments to configure for the Deadline Job :param deadline_service: An instance of the deadline service object :returns: Deadline Job ID :rtype: str</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/remote_executor.py</code> <pre><code>def submit_job(self, job, deadline_job, command_args, deadline_service):\n    \"\"\"\n    Submit a new Job to Deadline\n    :param job: Queued job to submit\n    :param deadline_job: Deadline job object\n    :param list[str] command_args: Commandline arguments to configure for the Deadline Job\n    :param deadline_service: An instance of the deadline service object\n    :returns: Deadline Job ID\n    :rtype: str\n    \"\"\"\n\n    # Get the Job Info and plugin Info\n    # If we have a preset set on the job, get the deadline submission details\n    try:\n        job_info, plugin_info = get_deadline_info_from_preset(job_preset_struct=job.get_deadline_job_preset_struct_with_overrides())\n\n    # Fail the submission if any errors occur\n    except Exception as err:\n        raise RuntimeError(\n            f\"An error occurred getting the deadline job and plugin \"\n            f\"details. \\n\\tError: {err} \"\n        )\n\n    # check for required fields in pluginInfo\n    if \"Executable\" not in plugin_info:\n        raise RuntimeError(\"An error occurred formatting the Plugin Info string. \\n\\tMissing \\\"Executable\\\" key\")\n    elif not plugin_info[\"Executable\"]:\n        raise RuntimeError(f\"An error occurred formatting the Plugin Info string. \\n\\tExecutable value cannot be empty\")\n    if \"ProjectFile\" not in plugin_info:\n        raise RuntimeError(\"An error occurred formatting the Plugin Info string. \\n\\tMissing \\\"ProjectFile\\\" key\")\n    elif not plugin_info[\"ProjectFile\"]:\n        raise RuntimeError(f\"An error occurred formatting the Plugin Info string. \\n\\tProjectFile value cannot be empty\")\n\n    # Update the job info with overrides from the UI\n    if job.batch_name:\n        job_info[\"BatchName\"] = job.batch_name\n\n    if hasattr(job, \"comment\") and not job_info.get(\"Comment\"):\n        job_info[\"Comment\"] = job.comment\n\n    if not job_info.get(\"Name\") or job_info[\"Name\"] == \"Untitled\":\n        job_info[\"Name\"] = job.job_name\n\n    if job.author:\n        job_info[\"UserName\"] = job.author\n\n    if unreal.Paths.is_project_file_path_set():\n        # Trim down to just \"Game.uproject\" instead of absolute path.\n        game_name_or_project_file = (\n            unreal.Paths.convert_relative_path_to_full(\n                unreal.Paths.get_project_file_path()\n            )\n        )\n\n    else:\n        raise RuntimeError(\n            \"Failed to get a project name. Please set a project!\"\n        )\n\n    # Create a new queue with only this job in it and save it to disk,\n    # then load it, so we can send it with the REST API\n    new_queue = unreal.MoviePipelineQueue()\n    new_job = new_queue.duplicate_job(job)\n\n    duplicated_queue, manifest_path = unreal.MoviePipelineEditorLibrary.save_queue_to_manifest_file(\n        new_queue\n    )\n\n    # Convert the queue to text (load the serialized json from disk) so we\n    # can send it via deadline, and deadline will write the queue to the\n    # local machines on job startup.\n    serialized_pipeline = unreal.MoviePipelineEditorLibrary.convert_manifest_file_to_string(\n        manifest_path\n    )\n\n    # Loop through our settings in the job and let them modify the command\n    # line arguments/params.\n    new_job.get_configuration().initialize_transient_settings()\n    # Look for our Game Override setting to pull the game mode to start\n    # with. We start with this game mode even on a blank map to override\n    # the project default from kicking in.\n    game_override_class = None\n\n    out_url_params = []\n    out_command_line_args = []\n    out_device_profile_cvars = []\n    out_exec_cmds = []\n    for setting in new_job.get_configuration().get_all_settings():\n\n        out_url_params, out_command_line_args, out_device_profile_cvars, out_exec_cmds = setting.build_new_process_command_line_args(\n            out_url_params,\n            out_command_line_args,\n            out_device_profile_cvars,\n            out_exec_cmds,\n        )\n\n        # Set the game override\n        if setting.get_class() == unreal.MoviePipelineGameOverrideSetting.static_class():\n            game_override_class = setting.game_mode_override\n\n    # This triggers the editor to start looking for render jobs when it\n    # finishes loading.\n    out_exec_cmds.append(\"py mrq_rpc.py\")\n\n    # Convert the arrays of command line args, device profile cvars,\n    # and exec cmds into actual commands for our command line.\n    command_args.extend(out_command_line_args)\n\n    if out_device_profile_cvars:\n        # -dpcvars=\"arg0,arg1,...\"\n        command_args.append(\n            '-dpcvars=\"{dpcvars}\"'.format(\n                dpcvars=\",\".join(out_device_profile_cvars)\n            )\n        )\n\n    if out_exec_cmds:\n        # -execcmds=\"cmd0,cmd1,...\"\n        command_args.append(\n            '-execcmds=\"{cmds}\"'.format(cmds=\",\".join(out_exec_cmds))\n        )\n\n    # Add support for telling the remote process to wait for the\n    # asset registry to complete synchronously\n    command_args.append(\"-waitonassetregistry\")\n\n    # Build a shot-mask from this sequence, to split into the appropriate\n    # number of tasks. Remove any already-disabled shots before we\n    # generate a list, otherwise we make unneeded tasks which get sent to\n    # machines\n    shots_to_render = []\n    for shot_index, shot in enumerate(new_job.shot_info):\n        if not shot.enabled:\n            unreal.log(\n                f\"Skipped submitting shot {shot_index} in {job.job_name} \"\n                f\"to server due to being already disabled!\"\n            )\n        else:\n            shots_to_render.append(shot.outer_name)\n\n    # If there are no shots enabled,\n    # \"these are not the droids we are looking for\", move along ;)\n    # We will catch this later and deal with it\n    if not shots_to_render:\n        unreal.log_warning(\"No shots enabled in shot mask, not submitting.\")\n        return\n\n    # Divide the job to render by the chunk size\n    # i.e {\"O\": \"my_new_shot\"} or {\"0\", \"shot_1,shot_2,shot_4\"}\n    chunk_size = int(job_info.get(\"ChunkSize\", 1))\n    shots = {}\n    frame_list = []\n    for index in range(0, len(shots_to_render), chunk_size):\n\n        shots[str(index)] = \",\".join(shots_to_render[index : index + chunk_size])\n\n        frame_list.append(str(index))\n\n    job_info[\"Frames\"] = \",\".join(frame_list)\n\n    # Get the current index of the ExtraInfoKeyValue pair, we will\n    # increment the index, so we do not stomp other settings\n    extra_info_key_indexs = set()\n    for key in job_info.keys():\n        if key.startswith(\"ExtraInfoKeyValue\"):\n            _, index = key.split(\"ExtraInfoKeyValue\")\n            extra_info_key_indexs.add(int(index))\n\n    # Get the highest number in the index list and increment the number\n    # by one\n    current_index = max(extra_info_key_indexs) + 1 if extra_info_key_indexs else 0\n\n    # Put the serialized Queue into the Job data but hidden from\n    # Deadline UI\n    job_info[f\"ExtraInfoKeyValue{current_index}\"] = f\"serialized_pipeline={serialized_pipeline}\"\n\n    # Increment the index\n    current_index += 1\n\n    # Put the shot info in the job extra info keys\n    job_info[f\"ExtraInfoKeyValue{current_index}\"] = f\"shot_info={json.dumps(shots)}\"\n    current_index += 1\n\n    # Set the job output directory override on the deadline job\n    if hasattr(new_job, \"output_directory_override\"):\n        if new_job.output_directory_override.path:\n            job_info[f\"ExtraInfoKeyValue{current_index}\"] = f\"output_directory_override={new_job.output_directory_override.path}\"\n\n            current_index += 1\n\n    # Set the job filename format override on the deadline job\n    if hasattr(new_job, \"filename_format_override\"):\n        if new_job.filename_format_override:\n            job_info[f\"ExtraInfoKeyValue{current_index}\"] = f\"filename_format_override={new_job.filename_format_override}\"\n\n            current_index += 1\n\n    # Build the command line arguments the remote machine will use.\n    # The Deadline plugin will provide the executable since it is local to\n    # the machine. It will also write out queue manifest to the correct\n    # location relative to the Saved folder\n\n    # Get the current commandline args from the plugin info\n    plugin_info_cmd_args = [plugin_info.get(\"CommandLineArguments\", \"\")]\n\n    if not plugin_info.get(\"ProjectFile\"):\n        project_file = plugin_info.get(\"ProjectFile\", game_name_or_project_file)\n        plugin_info[\"ProjectFile\"] = project_file\n\n    # This is the map included in the plugin to boot up to.\n    project_cmd_args = [\n        f\"MoviePipelineEntryMap?game={game_override_class.get_path_name()}\"\n    ]\n\n    # Combine all the compiled arguments\n    full_cmd_args = project_cmd_args + command_args + plugin_info_cmd_args\n\n    # Remove any duplicates in the commandline args and convert to a string\n    full_cmd_args = \" \".join(list(OrderedDict.fromkeys(full_cmd_args))).strip()\n\n    unreal.log(f\"Deadline job command line args: {full_cmd_args}\")\n\n    # Update the plugin info with the commandline arguments\n    plugin_info.update(\n        {\n            \"CommandLineArguments\": full_cmd_args,\n            \"CommandLineMode\": \"false\",\n        }\n    )\n\n    deadline_job.job_info = job_info\n    deadline_job.plugin_info = plugin_info\n\n    # Submit the deadline job\n    return deadline_service.submit_job(deadline_job)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/index.html","title":"mrq_cli_modes","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_current_sequence","title":"<code>render_current_sequence(sequence_name, sequence_map, mrq_preset, user=None, shots=None, is_remote=False, is_cmdline=False, remote_batch_name=None, remote_job_preset=None, executor_instance=None, output_dir_override=None, output_filename_override=None)</code>","text":"<p>Renders a sequence with a map and mrq preset</p> <p>:param str sequence_name: Sequence to render :param str sequence_map: Map to load sequence :param str mrq_preset: MRQ preset for rendering sequence :param str user: Render user :param list shots: Shots to render :param bool is_remote: Flag to determine if the job should be executed remotely :param bool is_cmdline: Flag to determine if the render was executed via commandline :param str remote_batch_name: Remote render batch name :param str remote_job_preset:  deadline job Preset Library :param executor_instance: Movie Pipeline executor Instance :param str output_dir_override: Movie Pipeline output directory override :param str output_filename_override: Movie Pipeline filename format override :return: MRQ executor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_sequence.py</code> <pre><code>def render_current_sequence(\n    sequence_name,\n    sequence_map,\n    mrq_preset,\n    user=None,\n    shots=None,\n    is_remote=False,\n    is_cmdline=False,\n    remote_batch_name=None,\n    remote_job_preset=None,\n    executor_instance=None,\n    output_dir_override=None,\n    output_filename_override=None\n):\n    \"\"\"\n    Renders a sequence with a map and mrq preset\n\n    :param str sequence_name: Sequence to render\n    :param str sequence_map: Map to load sequence\n    :param str mrq_preset: MRQ preset for rendering sequence\n    :param str user: Render user\n    :param list shots: Shots to render\n    :param bool is_remote: Flag to determine if the job should be executed remotely\n    :param bool is_cmdline: Flag to determine if the render was executed via commandline\n    :param str remote_batch_name: Remote render batch name\n    :param str remote_job_preset:  deadline job Preset Library\n    :param executor_instance: Movie Pipeline executor Instance\n    :param str output_dir_override: Movie Pipeline output directory override\n    :param str output_filename_override: Movie Pipeline filename format override\n    :return: MRQ executor\n    \"\"\"\n\n    # The queue subsystem behaves like a singleton so\n    # clear all the jobs in the current queue.\n    movie_pipeline_queue.delete_all_jobs()\n\n    render_job = movie_pipeline_queue.allocate_new_job(\n        unreal.SystemLibrary.conv_soft_class_path_to_soft_class_ref(\n            project_settings.default_executor_job\n        )\n    )\n\n    # Set the author on the job\n    render_job.author = user or getuser()\n\n    sequence_data_asset = get_asset_data(sequence_name, \"LevelSequence\")\n\n    # Create a job in the queue\n    unreal.log(f\"Creating render job for `{sequence_data_asset.asset_name}`\")\n    render_job.job_name = sequence_data_asset.asset_name\n\n    unreal.log(\n        f\"Setting the job sequence to `{sequence_data_asset.asset_name}`\"\n    )\n    render_job.sequence = sequence_data_asset.to_soft_object_path()\n\n    map_data_asset = get_asset_data(sequence_map, \"World\")\n    unreal.log(f\"Setting the job map to `{map_data_asset.asset_name}`\")\n    render_job.map = map_data_asset.to_soft_object_path()\n\n    mrq_preset_data_asset = get_asset_data(\n        mrq_preset, \"MoviePipelineMasterConfig\"\n    )\n    unreal.log(\n        f\"Setting the movie pipeline preset to `{mrq_preset_data_asset.asset_name}`\"\n    )\n    render_job.set_configuration(mrq_preset_data_asset.get_asset())\n\n    # MRQ added the ability to enable and disable jobs. Check to see is a job\n    # is disabled and enable it. The assumption is we want to render this\n    # particular job.\n    # Note this try/except block is for backwards compatibility\n    try:\n        if not render_job.enabled:\n            render_job.enabled = True\n    except AttributeError:\n        pass\n\n    # If we have a shot list, iterate over the shots in the sequence\n    # and disable anything that's not in the shot list. If no shot list is\n    # provided render all the shots in the sequence\n    if shots:\n        for shot in render_job.shot_info:\n            if shot.inner_name in shots or (shot.outer_name in shots):\n                shot.enabled = True\n            else:\n                unreal.log_warning(\n                    f\"Disabling shot `{shot.inner_name}` from current render job `{render_job.job_name}`\"\n                )\n                shot.enabled = False\n\n    try:\n        # Execute the render. This will execute the render based on whether\n        # its remote or local\n        executor = render_jobs(\n            is_remote,\n            remote_batch_name=remote_batch_name,\n            remote_job_preset=remote_job_preset,\n            is_cmdline=is_cmdline,\n            executor_instance=executor_instance,\n            output_dir_override=output_dir_override,\n            output_filename_override=output_filename_override\n        )\n\n    except Exception as err:\n        unreal.log_error(\n            f\"An error occurred executing the render.\\n\\tError: {err}\"\n        )\n        raise\n\n    return executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_jobs","title":"<code>render_jobs(is_remote=False, is_cmdline=False, executor_instance=None, remote_batch_name=None, remote_job_preset=None, output_dir_override=None, output_filename_override=None)</code>","text":"<p>This renders the current state of the queue</p> <p>:param bool is_remote: Is this a remote render :param bool is_cmdline: Is this a commandline render :param executor_instance: Movie Pipeline Executor instance :param str remote_batch_name: Batch name for remote renders :param str remote_job_preset: Remote render job preset :param str output_dir_override: Movie Pipeline output directory override :param str output_filename_override: Movie Pipeline filename format override :return: MRQ executor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue_jobs.py</code> <pre><code>def render_jobs(\n    is_remote=False,\n    is_cmdline=False,\n    executor_instance=None,\n    remote_batch_name=None,\n    remote_job_preset=None,\n    output_dir_override=None,\n    output_filename_override=None\n):\n    \"\"\"\n    This renders the current state of the queue\n\n    :param bool is_remote: Is this a remote render\n    :param bool is_cmdline: Is this a commandline render\n    :param executor_instance: Movie Pipeline Executor instance\n    :param str remote_batch_name: Batch name for remote renders\n    :param str remote_job_preset: Remote render job preset\n    :param str output_dir_override: Movie Pipeline output directory override\n    :param str output_filename_override: Movie Pipeline filename format override\n    :return: MRQ executor\n    \"\"\"\n\n    if not movie_pipeline_queue.get_jobs():\n        # Make sure we have jobs in the queue to work with\n        raise RuntimeError(\"There are no jobs in the queue!!\")\n\n    # Update the job\n    for job in movie_pipeline_queue.get_jobs():\n\n        # If we have output job overrides and filename overrides, update it on\n        # the job\n        if output_dir_override or output_filename_override:\n            update_render_output(\n                job,\n                output_dir=output_dir_override,\n                output_filename=output_filename_override\n            )\n\n        # Get the job output settings\n        output_setting = job.get_configuration().find_setting_by_class(\n            unreal.MoviePipelineOutputSetting\n        )\n\n        # Allow flushing flies to disk per shot.\n        # Required for the OnIndividualShotFinishedCallback to get called.\n        output_setting.flush_disk_writes_per_shot = True\n\n    if is_remote:\n        setup_remote_render_jobs(\n            remote_batch_name,\n            remote_job_preset,\n            movie_pipeline_queue.get_jobs(),\n        )\n\n    try:\n        # Execute the render.\n        # This will execute the render based on whether its remote or local\n        executor = execute_render(\n            is_remote,\n            executor_instance=executor_instance,\n            is_cmdline=is_cmdline,\n        )\n\n    except Exception as err:\n        unreal.log_error(\n            f\"An error occurred executing the render.\\n\\tError: {err}\"\n        )\n        raise\n\n    return executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_queue_asset","title":"<code>render_queue_asset(queue_name, only_load=False, shots=None, jobs=None, all_shots=False, is_cmdline=False, is_remote=False, user=None, remote_batch_name=None, remote_job_preset=None, executor_instance=None, output_dir_override=None, output_filename_override=None)</code>","text":"<p>Render using a Movie Render Queue asset</p> <p>:param str queue_name: The name of the Queue asset :param bool only_load: Only load the queue asset. This is usually used when you need to process intermediary steps before rendering :param list shots: Shots to render from the queue. :param list jobs: The list job to render in the Queue asset. :param bool all_shots: Flag to render all shots in a job in the queue. :param bool is_cmdline: Flag to determine if the job is a commandline job :param bool is_remote: Flag to determine if the jobs should be rendered remote :param str user: Render user :param str remote_batch_name: Batch name for remote renders :param str remote_job_preset: Remote render job preset :param executor_instance: Movie Pipeline executor instance :param str output_dir_override: Movie Pipeline output directory override :param str output_filename_override: Movie Pipeline filename format override :return: MRQ Executor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue.py</code> <pre><code>def render_queue_asset(\n    queue_name,\n    only_load=False,\n    shots=None,\n    jobs=None,\n    all_shots=False,\n    is_cmdline=False,\n    is_remote=False,\n    user=None,\n    remote_batch_name=None,\n    remote_job_preset=None,\n    executor_instance=None,\n    output_dir_override=None,\n    output_filename_override=None\n):\n    \"\"\"\n    Render using a Movie Render Queue asset\n\n    :param str queue_name: The name of the Queue asset\n    :param bool only_load: Only load the queue asset. This is usually used when you need to process intermediary steps before rendering\n    :param list shots: Shots to render from the queue.\n    :param list jobs: The list job to render in the Queue asset.\n    :param bool all_shots: Flag to render all shots in a job in the queue.\n    :param bool is_cmdline: Flag to determine if the job is a commandline job\n    :param bool is_remote: Flag to determine if the jobs should be rendered remote\n    :param str user: Render user\n    :param str remote_batch_name: Batch name for remote renders\n    :param str remote_job_preset: Remote render job preset\n    :param executor_instance: Movie Pipeline executor instance\n    :param str output_dir_override: Movie Pipeline output directory override\n    :param str output_filename_override: Movie Pipeline filename format override\n    :return: MRQ Executor\n    \"\"\"\n\n    # The queue subsystem behaves like a singleton so\n    # clear all the jobs in the current queue.\n    movie_pipeline_queue.delete_all_jobs()\n\n    # Get the queue data asset package path by name or by path\n    # Create a new queue from the queue asset\n    movie_pipeline_queue.copy_from(\n        get_asset_data(queue_name, \"MoviePipelineQueue\").get_asset()\n    )\n\n    # If we only want to load the queue asset, then exit after loading.\n    # If we want to shut down the editor as well, then do so\n    if only_load:\n\n        if is_cmdline:\n            unreal.SystemLibrary.quit_editor()\n\n        return None\n\n    if not movie_pipeline_queue.get_jobs():\n        # Make sure we have jobs in the queue to work with\n        raise RuntimeError(\"There are no jobs in the queue!!\")\n\n    # Allow executing the render queue in its current loaded state\n    if all_shots or (any([shots, jobs])):\n        update_queue(\n            jobs=jobs,\n            shots=shots,\n            all_shots=all_shots,\n            user=user\n        )\n\n    try:\n        # Execute the render. This will execute the render based on whether\n        # its remote or local\n        executor = render_jobs(\n            is_remote,\n            remote_batch_name=remote_batch_name,\n            remote_job_preset=remote_job_preset,\n            is_cmdline=is_cmdline,\n            executor_instance=executor_instance,\n            output_dir_override=output_dir_override,\n            output_filename_override=output_filename_override\n        )\n\n    except Exception:\n        raise\n\n    return executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_queue_manifest","title":"<code>render_queue_manifest(manifest, load_only=False, shots=None, user=None, is_remote=False, is_cmdline=False, remote_batch_name=None, remote_job_preset=None, executor_instance=None, output_dir_override=None, output_filename_override=None)</code>","text":"<p>Function to execute a render using a manifest file</p> <p>:param str manifest: Manifest file to render :param bool load_only: Only load the manifest file :param list shots: Shots to render from the queue :param str user: Render user :param bool is_remote: Flag to determine if the jobs should be rendered remote :param bool is_cmdline: Flag to determine if the job is a commandline job :param str remote_batch_name: Batch name for remote renders :param str remote_job_preset: Remote render preset library :param executor_instance: Movie Pipeline executor instance :param str output_dir_override: Movie Pipeline output directory override :param str output_filename_override: Movie Pipeline filename format override :return: MRQ Executor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_manifest.py</code> <pre><code>def render_queue_manifest(\n    manifest,\n    load_only=False,\n    shots=None,\n    user=None,\n    is_remote=False,\n    is_cmdline=False,\n    remote_batch_name=None,\n    remote_job_preset=None,\n    executor_instance=None,\n    output_dir_override=None,\n    output_filename_override=None\n):\n    \"\"\"\n    Function to execute a render using a manifest file\n\n    :param str manifest: Manifest file to render\n    :param bool load_only: Only load the manifest file\n    :param list shots: Shots to render from the queue\n    :param str user: Render user\n    :param bool is_remote: Flag to determine if the jobs should be rendered remote\n    :param bool is_cmdline: Flag to determine if the job is a commandline job\n    :param str remote_batch_name: Batch name for remote renders\n    :param str remote_job_preset: Remote render preset library\n    :param executor_instance: Movie Pipeline executor instance\n    :param str output_dir_override: Movie Pipeline output directory override\n    :param str output_filename_override: Movie Pipeline filename format override\n    :return: MRQ Executor\n    \"\"\"\n    # The queue subsystem behaves like a singleton so\n    # clear all the jobs in the current queue.\n    movie_pipeline_queue.delete_all_jobs()\n\n    # Manifest args returns a Pathlib object, get the results as a string and\n    # load the manifest\n    movie_pipeline_queue.copy_from(\n        unreal.MoviePipelineLibrary.load_manifest_file_from_string(manifest)\n    )\n\n    # If we only want to load the manifest file, then exit after loading\n    # the manifest.\n    # If we want to shut down the editor as well, then do so\n    if load_only:\n\n        if is_cmdline:\n            unreal.SystemLibrary.quit_editor()\n\n        return None\n\n    # Manifest files are a per job configuration. So there should only be one\n    # job in a manifest file\n\n    # Todo: Make sure there are always only one job in the manifest file\n    if movie_pipeline_queue.get_jobs():\n        render_job = movie_pipeline_queue.get_jobs()[0]\n    else:\n        raise RuntimeError(\"There are no jobs in the queue!!\")\n\n    # MRQ added the ability to enable and disable jobs. Check to see if a job\n    # is disabled and enable it.\n    # The assumption is we want to render this particular job.\n    # Note this try except block is for backwards compatibility\n    try:\n        if not render_job.enabled:\n            render_job.enabled = True\n    except AttributeError:\n        pass\n\n    # Set the author on the job\n    render_job.author = user or getuser()\n\n    # If we have a shot list, iterate over the shots in the sequence\n    # and disable anything that's not in the shot list. If no shot list is\n    # provided render all the shots in the sequence\n    if shots:\n        for shot in render_job.shot_info:\n            if shot.inner_name in shots or (shot.outer_name in shots):\n                shot.enabled = True\n            else:\n                unreal.log_warning(\n                    f\"Disabling shot `{shot.inner_name}` from current render job `{render_job.job_name}`\"\n                )\n                shot.enabled = False\n\n    try:\n        # Execute the render.\n        # This will execute the render based on whether its remote or local\n        executor = render_jobs(\n            is_remote,\n            remote_batch_name=remote_batch_name,\n            remote_job_preset=remote_job_preset,\n            executor_instance=executor_instance,\n            is_cmdline=is_cmdline,\n            output_dir_override=output_dir_override,\n            output_filename_override=output_filename_override\n        )\n\n    except Exception as err:\n        unreal.log_error(\n            f\"An error occurred executing the render.\\n\\tError: {err}\"\n        )\n        raise\n\n    return executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_manifest.html","title":"render_manifest","text":"<p>This script handles processing manifest files for rendering in MRQ</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_manifest.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_manifest.render_queue_manifest","title":"<code>render_queue_manifest(manifest, load_only=False, shots=None, user=None, is_remote=False, is_cmdline=False, remote_batch_name=None, remote_job_preset=None, executor_instance=None, output_dir_override=None, output_filename_override=None)</code>","text":"<p>Function to execute a render using a manifest file</p> <p>:param str manifest: Manifest file to render :param bool load_only: Only load the manifest file :param list shots: Shots to render from the queue :param str user: Render user :param bool is_remote: Flag to determine if the jobs should be rendered remote :param bool is_cmdline: Flag to determine if the job is a commandline job :param str remote_batch_name: Batch name for remote renders :param str remote_job_preset: Remote render preset library :param executor_instance: Movie Pipeline executor instance :param str output_dir_override: Movie Pipeline output directory override :param str output_filename_override: Movie Pipeline filename format override :return: MRQ Executor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_manifest.py</code> <pre><code>def render_queue_manifest(\n    manifest,\n    load_only=False,\n    shots=None,\n    user=None,\n    is_remote=False,\n    is_cmdline=False,\n    remote_batch_name=None,\n    remote_job_preset=None,\n    executor_instance=None,\n    output_dir_override=None,\n    output_filename_override=None\n):\n    \"\"\"\n    Function to execute a render using a manifest file\n\n    :param str manifest: Manifest file to render\n    :param bool load_only: Only load the manifest file\n    :param list shots: Shots to render from the queue\n    :param str user: Render user\n    :param bool is_remote: Flag to determine if the jobs should be rendered remote\n    :param bool is_cmdline: Flag to determine if the job is a commandline job\n    :param str remote_batch_name: Batch name for remote renders\n    :param str remote_job_preset: Remote render preset library\n    :param executor_instance: Movie Pipeline executor instance\n    :param str output_dir_override: Movie Pipeline output directory override\n    :param str output_filename_override: Movie Pipeline filename format override\n    :return: MRQ Executor\n    \"\"\"\n    # The queue subsystem behaves like a singleton so\n    # clear all the jobs in the current queue.\n    movie_pipeline_queue.delete_all_jobs()\n\n    # Manifest args returns a Pathlib object, get the results as a string and\n    # load the manifest\n    movie_pipeline_queue.copy_from(\n        unreal.MoviePipelineLibrary.load_manifest_file_from_string(manifest)\n    )\n\n    # If we only want to load the manifest file, then exit after loading\n    # the manifest.\n    # If we want to shut down the editor as well, then do so\n    if load_only:\n\n        if is_cmdline:\n            unreal.SystemLibrary.quit_editor()\n\n        return None\n\n    # Manifest files are a per job configuration. So there should only be one\n    # job in a manifest file\n\n    # Todo: Make sure there are always only one job in the manifest file\n    if movie_pipeline_queue.get_jobs():\n        render_job = movie_pipeline_queue.get_jobs()[0]\n    else:\n        raise RuntimeError(\"There are no jobs in the queue!!\")\n\n    # MRQ added the ability to enable and disable jobs. Check to see if a job\n    # is disabled and enable it.\n    # The assumption is we want to render this particular job.\n    # Note this try except block is for backwards compatibility\n    try:\n        if not render_job.enabled:\n            render_job.enabled = True\n    except AttributeError:\n        pass\n\n    # Set the author on the job\n    render_job.author = user or getuser()\n\n    # If we have a shot list, iterate over the shots in the sequence\n    # and disable anything that's not in the shot list. If no shot list is\n    # provided render all the shots in the sequence\n    if shots:\n        for shot in render_job.shot_info:\n            if shot.inner_name in shots or (shot.outer_name in shots):\n                shot.enabled = True\n            else:\n                unreal.log_warning(\n                    f\"Disabling shot `{shot.inner_name}` from current render job `{render_job.job_name}`\"\n                )\n                shot.enabled = False\n\n    try:\n        # Execute the render.\n        # This will execute the render based on whether its remote or local\n        executor = render_jobs(\n            is_remote,\n            remote_batch_name=remote_batch_name,\n            remote_job_preset=remote_job_preset,\n            executor_instance=executor_instance,\n            is_cmdline=is_cmdline,\n            output_dir_override=output_dir_override,\n            output_filename_override=output_filename_override\n        )\n\n    except Exception as err:\n        unreal.log_error(\n            f\"An error occurred executing the render.\\n\\tError: {err}\"\n        )\n        raise\n\n    return executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_manifest.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_manifest.setup_manifest_parser","title":"<code>setup_manifest_parser(subparser)</code>","text":"<p>This method adds a custom execution function and args to a subparser</p> <p>:param subparser: Subparser for processing manifest files</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_manifest.py</code> <pre><code>def setup_manifest_parser(subparser):\n    \"\"\"\n    This method adds a custom execution function and args to a subparser\n\n    :param subparser: Subparser for processing manifest files\n    \"\"\"\n    # Movie pipeline manifest file from disk\n    subparser.add_argument(\n        \"manifest\", type=Path, help=\"Full local path to a MRQ manifest file.\"\n    )\n\n    # Add option to only load the contents of the manifest file. By default,\n    # this will render after loading the manifest file\n    subparser.add_argument(\n        \"--load\",\n        action=\"store_true\",\n        help=\"Only load the contents of the manifest file. \"\n        \"By default the manifest will be loaded and rendered.\",\n    )\n\n    # Function to process arguments\n    subparser.set_defaults(func=_process_args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue.html","title":"render_queue","text":"<p>This script handles processing jobs for a specific queue asset</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_queue.render_queue_asset","title":"<code>render_queue_asset(queue_name, only_load=False, shots=None, jobs=None, all_shots=False, is_cmdline=False, is_remote=False, user=None, remote_batch_name=None, remote_job_preset=None, executor_instance=None, output_dir_override=None, output_filename_override=None)</code>","text":"<p>Render using a Movie Render Queue asset</p> <p>:param str queue_name: The name of the Queue asset :param bool only_load: Only load the queue asset. This is usually used when you need to process intermediary steps before rendering :param list shots: Shots to render from the queue. :param list jobs: The list job to render in the Queue asset. :param bool all_shots: Flag to render all shots in a job in the queue. :param bool is_cmdline: Flag to determine if the job is a commandline job :param bool is_remote: Flag to determine if the jobs should be rendered remote :param str user: Render user :param str remote_batch_name: Batch name for remote renders :param str remote_job_preset: Remote render job preset :param executor_instance: Movie Pipeline executor instance :param str output_dir_override: Movie Pipeline output directory override :param str output_filename_override: Movie Pipeline filename format override :return: MRQ Executor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue.py</code> <pre><code>def render_queue_asset(\n    queue_name,\n    only_load=False,\n    shots=None,\n    jobs=None,\n    all_shots=False,\n    is_cmdline=False,\n    is_remote=False,\n    user=None,\n    remote_batch_name=None,\n    remote_job_preset=None,\n    executor_instance=None,\n    output_dir_override=None,\n    output_filename_override=None\n):\n    \"\"\"\n    Render using a Movie Render Queue asset\n\n    :param str queue_name: The name of the Queue asset\n    :param bool only_load: Only load the queue asset. This is usually used when you need to process intermediary steps before rendering\n    :param list shots: Shots to render from the queue.\n    :param list jobs: The list job to render in the Queue asset.\n    :param bool all_shots: Flag to render all shots in a job in the queue.\n    :param bool is_cmdline: Flag to determine if the job is a commandline job\n    :param bool is_remote: Flag to determine if the jobs should be rendered remote\n    :param str user: Render user\n    :param str remote_batch_name: Batch name for remote renders\n    :param str remote_job_preset: Remote render job preset\n    :param executor_instance: Movie Pipeline executor instance\n    :param str output_dir_override: Movie Pipeline output directory override\n    :param str output_filename_override: Movie Pipeline filename format override\n    :return: MRQ Executor\n    \"\"\"\n\n    # The queue subsystem behaves like a singleton so\n    # clear all the jobs in the current queue.\n    movie_pipeline_queue.delete_all_jobs()\n\n    # Get the queue data asset package path by name or by path\n    # Create a new queue from the queue asset\n    movie_pipeline_queue.copy_from(\n        get_asset_data(queue_name, \"MoviePipelineQueue\").get_asset()\n    )\n\n    # If we only want to load the queue asset, then exit after loading.\n    # If we want to shut down the editor as well, then do so\n    if only_load:\n\n        if is_cmdline:\n            unreal.SystemLibrary.quit_editor()\n\n        return None\n\n    if not movie_pipeline_queue.get_jobs():\n        # Make sure we have jobs in the queue to work with\n        raise RuntimeError(\"There are no jobs in the queue!!\")\n\n    # Allow executing the render queue in its current loaded state\n    if all_shots or (any([shots, jobs])):\n        update_queue(\n            jobs=jobs,\n            shots=shots,\n            all_shots=all_shots,\n            user=user\n        )\n\n    try:\n        # Execute the render. This will execute the render based on whether\n        # its remote or local\n        executor = render_jobs(\n            is_remote,\n            remote_batch_name=remote_batch_name,\n            remote_job_preset=remote_job_preset,\n            is_cmdline=is_cmdline,\n            executor_instance=executor_instance,\n            output_dir_override=output_dir_override,\n            output_filename_override=output_filename_override\n        )\n\n    except Exception:\n        raise\n\n    return executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_queue.setup_queue_parser","title":"<code>setup_queue_parser(subparser)</code>","text":"<p>This method adds a custom execution function and args to a queue subparser</p> <p>:param subparser: Subparser for processing custom sequences</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue.py</code> <pre><code>def setup_queue_parser(subparser):\n    \"\"\"\n    This method adds a custom execution function and args to a queue subparser\n\n    :param subparser: Subparser for processing custom sequences\n    \"\"\"\n    # Set the name of the job\n    subparser.add_argument(\n        \"queue\",\n        type=str,\n        help=\"The name or path to a movie pipeline queue.\"\n    )\n\n    # Add option to only load the contents of the queue. By default,\n    # this will only load the queue and render its contents\n    subparser.add_argument(\n        \"--load\",\n        action=\"store_true\",\n        help=\"Load the contents of the queue asset. By default the queue asset will loaded and render its contents.\",\n    )\n\n    # We will use the level sequence and the map as our context for\n    # other subsequence arguments.\n    subparser.add_argument(\n        \"--jobs\",\n        type=str,\n        nargs=\"+\",\n        help=\"A list of jobs to execute in the queue. \"\n        \"If no jobs are provided, all jobs in the queue will be rendered.\",\n    )\n\n    # Function to process arguments\n    subparser.set_defaults(func=_process_args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue_jobs.html","title":"render_queue_jobs","text":"<p>This script handles processing jobs and shots in the current loaded queue</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue_jobs.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_queue_jobs.render_jobs","title":"<code>render_jobs(is_remote=False, is_cmdline=False, executor_instance=None, remote_batch_name=None, remote_job_preset=None, output_dir_override=None, output_filename_override=None)</code>","text":"<p>This renders the current state of the queue</p> <p>:param bool is_remote: Is this a remote render :param bool is_cmdline: Is this a commandline render :param executor_instance: Movie Pipeline Executor instance :param str remote_batch_name: Batch name for remote renders :param str remote_job_preset: Remote render job preset :param str output_dir_override: Movie Pipeline output directory override :param str output_filename_override: Movie Pipeline filename format override :return: MRQ executor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue_jobs.py</code> <pre><code>def render_jobs(\n    is_remote=False,\n    is_cmdline=False,\n    executor_instance=None,\n    remote_batch_name=None,\n    remote_job_preset=None,\n    output_dir_override=None,\n    output_filename_override=None\n):\n    \"\"\"\n    This renders the current state of the queue\n\n    :param bool is_remote: Is this a remote render\n    :param bool is_cmdline: Is this a commandline render\n    :param executor_instance: Movie Pipeline Executor instance\n    :param str remote_batch_name: Batch name for remote renders\n    :param str remote_job_preset: Remote render job preset\n    :param str output_dir_override: Movie Pipeline output directory override\n    :param str output_filename_override: Movie Pipeline filename format override\n    :return: MRQ executor\n    \"\"\"\n\n    if not movie_pipeline_queue.get_jobs():\n        # Make sure we have jobs in the queue to work with\n        raise RuntimeError(\"There are no jobs in the queue!!\")\n\n    # Update the job\n    for job in movie_pipeline_queue.get_jobs():\n\n        # If we have output job overrides and filename overrides, update it on\n        # the job\n        if output_dir_override or output_filename_override:\n            update_render_output(\n                job,\n                output_dir=output_dir_override,\n                output_filename=output_filename_override\n            )\n\n        # Get the job output settings\n        output_setting = job.get_configuration().find_setting_by_class(\n            unreal.MoviePipelineOutputSetting\n        )\n\n        # Allow flushing flies to disk per shot.\n        # Required for the OnIndividualShotFinishedCallback to get called.\n        output_setting.flush_disk_writes_per_shot = True\n\n    if is_remote:\n        setup_remote_render_jobs(\n            remote_batch_name,\n            remote_job_preset,\n            movie_pipeline_queue.get_jobs(),\n        )\n\n    try:\n        # Execute the render.\n        # This will execute the render based on whether its remote or local\n        executor = execute_render(\n            is_remote,\n            executor_instance=executor_instance,\n            is_cmdline=is_cmdline,\n        )\n\n    except Exception as err:\n        unreal.log_error(\n            f\"An error occurred executing the render.\\n\\tError: {err}\"\n        )\n        raise\n\n    return executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue_jobs.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_queue_jobs.setup_render_parser","title":"<code>setup_render_parser(subparser)</code>","text":"<p>This method adds a custom execution function and args to a render subparser</p> <p>:param subparser: Subparser for processing custom sequences</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_queue_jobs.py</code> <pre><code>def setup_render_parser(subparser):\n    \"\"\"\n    This method adds a custom execution function and args to a render subparser\n\n    :param subparser: Subparser for processing custom sequences\n    \"\"\"\n\n    # Function to process arguments\n    subparser.set_defaults(func=_process_args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_sequence.html","title":"render_sequence","text":"<p>This script handles processing jobs for a specific sequence</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_sequence.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_sequence.render_current_sequence","title":"<code>render_current_sequence(sequence_name, sequence_map, mrq_preset, user=None, shots=None, is_remote=False, is_cmdline=False, remote_batch_name=None, remote_job_preset=None, executor_instance=None, output_dir_override=None, output_filename_override=None)</code>","text":"<p>Renders a sequence with a map and mrq preset</p> <p>:param str sequence_name: Sequence to render :param str sequence_map: Map to load sequence :param str mrq_preset: MRQ preset for rendering sequence :param str user: Render user :param list shots: Shots to render :param bool is_remote: Flag to determine if the job should be executed remotely :param bool is_cmdline: Flag to determine if the render was executed via commandline :param str remote_batch_name: Remote render batch name :param str remote_job_preset:  deadline job Preset Library :param executor_instance: Movie Pipeline executor Instance :param str output_dir_override: Movie Pipeline output directory override :param str output_filename_override: Movie Pipeline filename format override :return: MRQ executor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_sequence.py</code> <pre><code>def render_current_sequence(\n    sequence_name,\n    sequence_map,\n    mrq_preset,\n    user=None,\n    shots=None,\n    is_remote=False,\n    is_cmdline=False,\n    remote_batch_name=None,\n    remote_job_preset=None,\n    executor_instance=None,\n    output_dir_override=None,\n    output_filename_override=None\n):\n    \"\"\"\n    Renders a sequence with a map and mrq preset\n\n    :param str sequence_name: Sequence to render\n    :param str sequence_map: Map to load sequence\n    :param str mrq_preset: MRQ preset for rendering sequence\n    :param str user: Render user\n    :param list shots: Shots to render\n    :param bool is_remote: Flag to determine if the job should be executed remotely\n    :param bool is_cmdline: Flag to determine if the render was executed via commandline\n    :param str remote_batch_name: Remote render batch name\n    :param str remote_job_preset:  deadline job Preset Library\n    :param executor_instance: Movie Pipeline executor Instance\n    :param str output_dir_override: Movie Pipeline output directory override\n    :param str output_filename_override: Movie Pipeline filename format override\n    :return: MRQ executor\n    \"\"\"\n\n    # The queue subsystem behaves like a singleton so\n    # clear all the jobs in the current queue.\n    movie_pipeline_queue.delete_all_jobs()\n\n    render_job = movie_pipeline_queue.allocate_new_job(\n        unreal.SystemLibrary.conv_soft_class_path_to_soft_class_ref(\n            project_settings.default_executor_job\n        )\n    )\n\n    # Set the author on the job\n    render_job.author = user or getuser()\n\n    sequence_data_asset = get_asset_data(sequence_name, \"LevelSequence\")\n\n    # Create a job in the queue\n    unreal.log(f\"Creating render job for `{sequence_data_asset.asset_name}`\")\n    render_job.job_name = sequence_data_asset.asset_name\n\n    unreal.log(\n        f\"Setting the job sequence to `{sequence_data_asset.asset_name}`\"\n    )\n    render_job.sequence = sequence_data_asset.to_soft_object_path()\n\n    map_data_asset = get_asset_data(sequence_map, \"World\")\n    unreal.log(f\"Setting the job map to `{map_data_asset.asset_name}`\")\n    render_job.map = map_data_asset.to_soft_object_path()\n\n    mrq_preset_data_asset = get_asset_data(\n        mrq_preset, \"MoviePipelineMasterConfig\"\n    )\n    unreal.log(\n        f\"Setting the movie pipeline preset to `{mrq_preset_data_asset.asset_name}`\"\n    )\n    render_job.set_configuration(mrq_preset_data_asset.get_asset())\n\n    # MRQ added the ability to enable and disable jobs. Check to see is a job\n    # is disabled and enable it. The assumption is we want to render this\n    # particular job.\n    # Note this try/except block is for backwards compatibility\n    try:\n        if not render_job.enabled:\n            render_job.enabled = True\n    except AttributeError:\n        pass\n\n    # If we have a shot list, iterate over the shots in the sequence\n    # and disable anything that's not in the shot list. If no shot list is\n    # provided render all the shots in the sequence\n    if shots:\n        for shot in render_job.shot_info:\n            if shot.inner_name in shots or (shot.outer_name in shots):\n                shot.enabled = True\n            else:\n                unreal.log_warning(\n                    f\"Disabling shot `{shot.inner_name}` from current render job `{render_job.job_name}`\"\n                )\n                shot.enabled = False\n\n    try:\n        # Execute the render. This will execute the render based on whether\n        # its remote or local\n        executor = render_jobs(\n            is_remote,\n            remote_batch_name=remote_batch_name,\n            remote_job_preset=remote_job_preset,\n            is_cmdline=is_cmdline,\n            executor_instance=executor_instance,\n            output_dir_override=output_dir_override,\n            output_filename_override=output_filename_override\n        )\n\n    except Exception as err:\n        unreal.log_error(\n            f\"An error occurred executing the render.\\n\\tError: {err}\"\n        )\n        raise\n\n    return executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_sequence.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.render_sequence.setup_sequence_parser","title":"<code>setup_sequence_parser(subparser)</code>","text":"<p>This method adds a custom execution function and args to a sequence subparser</p> <p>:param subparser: Subparser for processing custom sequences</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/render_sequence.py</code> <pre><code>def setup_sequence_parser(subparser):\n    \"\"\"\n    This method adds a custom execution function and args to a sequence subparser\n\n    :param subparser: Subparser for processing custom sequences\n    \"\"\"\n    # We will use the level sequence and the map as our context for\n    # other subsequence arguments.\n    subparser.add_argument(\n        \"sequence\", type=str, help=\"The level sequence that will be rendered.\"\n    )\n    subparser.add_argument(\n        \"map\",\n        type=str,\n        help=\"The map the level sequence will be loaded with for rendering.\",\n    )\n\n    # Get some information for the render queue\n    subparser.add_argument(\n        \"mrq_preset\",\n        type=str,\n        help=\"The MRQ preset used to render the current job.\",\n    )\n\n    # Function to process arguments\n    subparser.set_defaults(func=_process_args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html","title":"utils","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.execute_render","title":"<code>execute_render(is_remote=False, executor_instance=None, is_cmdline=False)</code>","text":"<p>Starts a render</p> <p>:param bool is_remote: Flag to use the local or remote executor class :param executor_instance: Executor instance used for rendering :param bool is_cmdline: Flag to determine if the render was executed from a commandline.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def execute_render(is_remote=False, executor_instance=None, is_cmdline=False):\n    \"\"\"\n    Starts a render\n\n    :param bool is_remote: Flag to use the local or remote executor class\n    :param executor_instance: Executor instance used for rendering\n    :param bool is_cmdline: Flag to determine if the render was executed from a commandline.\n    \"\"\"\n\n    if not executor_instance:\n        executor_instance = get_executor_instance(is_remote)\n\n    if is_cmdline:\n        setup_editor_exit_callback(executor_instance)\n\n    # Start the Render\n    unreal.log(\"MRQ job started...\")\n    unreal.log(f\"Is remote render: {is_remote}\")\n\n    pipeline_subsystem.render_queue_with_executor_instance(executor_instance)\n\n    return executor_instance\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.executor_failed_callback","title":"<code>executor_failed_callback(executor, pipeline, is_fatal, error)</code>","text":"<p>Callback executed when a job fails in the editor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def executor_failed_callback(executor, pipeline, is_fatal, error):\n    \"\"\"\n    Callback executed when a job fails in the editor\n    \"\"\"\n    unreal.log_error(\n        f\"An error occurred while executing a render.\\n\\tError: {error}\"\n    )\n\n    unreal.SystemLibrary.quit_editor()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.get_asset_data","title":"<code>get_asset_data(name_or_path, asset_class)</code>","text":"<p>Get the asset data for the asset name or path based on its class.</p> <p>:param str name_or_path: asset name or package name :param str asset_class: Asset class filter to use when looking for assets in registry :raises RuntimeError :return: Asset package if it exists</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def get_asset_data(name_or_path, asset_class):\n    \"\"\"\n    Get the asset data for the asset name or path based on its class.\n\n    :param str name_or_path: asset name or package name\n    :param str asset_class: Asset class filter to use when looking for assets in registry\n    :raises RuntimeError\n    :return: Asset package if it exists\n    \"\"\"\n    # Get all the specified class assets in the project.\n    # This is the only mechanism we can think of at the moment to allow\n    # shorter path names in the commandline interface. This will allow users\n    # to only provide the asset name or the package path in the commandline\n    # interface based on the assumption that all assets are unique\n    asset_registry = unreal.AssetRegistryHelpers.get_asset_registry()\n\n    # If the asset registry is still loading, wait for it to finish\n    if asset_registry.is_loading_assets():\n        unreal.log_warning(\"Asset Registry is loading, waiting to complete...\")\n        asset_registry.wait_for_completion()\n\n        unreal.log(\"Asset Registry load complete!\")\n\n    assets = asset_registry.get_assets(\n        unreal.ARFilter(class_names=[asset_class])\n    )\n\n    # This lookup could potentially be very slow\n    for asset in assets:\n        # If a package name is provided lookup the package path. If a\n        # packages startwith a \"/\" this signifies a content package. Content\n        # packages can either be Game or plugin. Game content paths start\n        # with \"/Game\" and plugin contents startswith /&lt;PluginName&gt;\n        if name_or_path.startswith(\"/\"):\n            # Reconstruct the package path into a package name. eg.\n            # /my/package_name.package_name -&gt; /my/package_name\n            name_or_path = name_or_path.split(\".\")[0]\n            if asset.package_name == name_or_path:\n                return asset\n        else:\n            if asset.asset_name == name_or_path:\n                return asset\n    else:\n        raise RuntimeError(f\"`{name_or_path}` could not be found!\")\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.get_executor_instance","title":"<code>get_executor_instance(is_remote)</code>","text":"<p>Method to return an instance of a render executor</p> <p>:param bool is_remote: Flag to use the local or remote executor class :return: Executor instance</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def get_executor_instance(is_remote):\n    \"\"\"\n    Method to return an instance of a render executor\n\n    :param bool is_remote: Flag to use the local or remote executor class\n    :return: Executor instance\n    \"\"\"\n    is_soft_class_object = True\n    # Convert the SoftClassPath into a SoftClassReference.\n    # local executor class from the project settings\n    try:\n        class_ref = unreal.SystemLibrary.conv_soft_class_path_to_soft_class_ref(\n            project_settings.default_local_executor\n        )\n    # For Backwards compatibility. Older version returned a class object from\n    # the project settings\n    except TypeError:\n        class_ref = project_settings.default_local_executor\n        is_soft_class_object = False\n\n    if is_remote:\n        try:\n            # Get the remote executor class\n            class_ref = (\n                unreal.SystemLibrary.conv_soft_class_path_to_soft_class_ref(\n                    project_settings.default_remote_executor\n                )\n            )\n        except TypeError:\n            class_ref = project_settings.default_remote_executor\n            is_soft_class_object = False\n\n    if not class_ref:\n        raise RuntimeError(\n            \"Failed to get a class reference to the default executor from the \"\n            \"project settings. Check the logs for more details.\"\n        )\n\n    if is_soft_class_object:\n        # Get the executor class as this is required to get an instance of\n        # the executor\n        executor_class = unreal.SystemLibrary.load_class_asset_blocking(\n            class_ref\n        )\n    else:\n        executor_class = class_ref\n\n    global pipeline_executor\n    pipeline_executor = unreal.new_object(executor_class)\n\n    return pipeline_executor\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.set_job_state","title":"<code>set_job_state(job, enable=False)</code>","text":"<p>This method sets the state on a current job to enabled or disabled</p> <p>:param job: MoviePipeline job to enable/disable :param bool enable: Flag to determine if a job should be or not</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def set_job_state(job, enable=False):\n    \"\"\"\n    This method sets the state on a current job to enabled or disabled\n\n    :param job: MoviePipeline job to enable/disable\n    :param bool enable: Flag to determine if a job should be or not\n    \"\"\"\n\n    if enable:\n        # Check for an enable attribute on the job and if not move along.\n        # Note: `Enabled` was added to MRQ that allows disabling all shots in\n        #  a job. This also enables backwards compatibility.\n        try:\n            if not job.enabled:\n                job.enabled = True\n        except AttributeError:\n            # Legacy implementations assumes the presence of a job means its\n            # enabled\n            return\n\n    try:\n        if job.enabled:\n            job.enabled = False\n    except AttributeError:\n        # If the attribute is not available, go through and disable all the\n        # associated shots. This behaves like a disabled job\n        for shot in job.shot_info:\n            unreal.log_warning(\n                f\"Disabling shot `{shot.inner_name}` from current render job `{job.job_name}`\"\n            )\n            shot.enabled = False\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.setup_editor_exit_callback","title":"<code>setup_editor_exit_callback(executor_instance)</code>","text":"<p>Setup callbacks for when you need to close the editor after a render</p> <p>:param executor_instance: Movie Pipeline executor instance</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def setup_editor_exit_callback(executor_instance):\n    \"\"\"\n    Setup callbacks for when you need to close the editor after a render\n\n    :param executor_instance: Movie Pipeline executor instance\n    \"\"\"\n\n    unreal.log(\"Executed job from commandline, setting up shutdown callback..\")\n\n    # add a callable to the executor to be executed when the pipeline is done rendering\n    executor_instance.on_executor_finished_delegate.add_callable(\n        shutdown_editor\n    )\n    # add a callable to the executor to be executed when the pipeline fails to render\n    executor_instance.on_executor_errored_delegate.add_callable(\n        executor_failed_callback\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.setup_remote_render_jobs","title":"<code>setup_remote_render_jobs(batch_name, job_preset, render_jobs)</code>","text":"<p>This function sets up a render job with the options for a remote render. This is configured currently for deadline jobs.</p> <p>:param str batch_name: Remote render batch name :param str job_preset: Job Preset to use for job details :param list render_jobs: The list of render jobs to apply the ars to</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def setup_remote_render_jobs(batch_name, job_preset, render_jobs):\n    \"\"\"\n    This function sets up a render job with the options for a remote render.\n    This is configured currently for deadline jobs.\n\n    :param str batch_name: Remote render batch name\n    :param str job_preset: Job Preset to use for job details\n    :param list render_jobs: The list of render jobs to apply the ars to\n    \"\"\"\n\n    unreal.log(\"Setting up Remote render executor.. \")\n\n    # Update the settings on the render job.\n    # Currently, this is designed to work with deadline\n\n    # Make sure we have the relevant attribute on the jobs. This remote cli\n    # setup can be used with out-of-process rendering and not just deadline.\n    unset_job_properties = []\n    for job in render_jobs:\n        if hasattr(job, \"batch_name\") and not batch_name:\n            unset_job_properties.append(job.name)\n\n        if hasattr(job, \"job_preset\") and not job_preset:\n            unset_job_properties.append(job.name)\n\n    # If we find a deadline property on the job, and it's not set, raise an\n    # error\n    if unset_job_properties:\n        raise RuntimeError(\n            \"These jobs did not have a batch name, preset name or preset \"\n            \"library set. This is a requirement for deadline remote rendering. \"\n            \"{jobs}\".format(\n                jobs=\"\\n\".join(unset_job_properties))\n        )\n\n    for render_job in render_jobs:\n        render_job.batch_name = batch_name\n        render_job.job_preset = get_asset_data(\n            job_preset,\n            \"DeadlineJobPreset\"\n        ).get_asset()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.shutdown_editor","title":"<code>shutdown_editor(movie_pipeline=None, results=None)</code>","text":"<p>This method shutdown the editor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def shutdown_editor(movie_pipeline=None, results=None):\n    \"\"\"\n    This method shutdown the editor\n    \"\"\"\n    unreal.log(\"Rendering is complete! Exiting...\")\n    unreal.SystemLibrary.quit_editor()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.update_queue","title":"<code>update_queue(jobs=None, shots=None, all_shots=False, user=None)</code>","text":"<p>This function configures and renders a job based on the arguments</p> <p>:param list jobs: MRQ jobs to render :param list shots: Shots to render from jobs :param bool all_shots: Flag for rendering all shots :param str user: Render user</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def update_queue(\n    jobs=None,\n    shots=None,\n    all_shots=False,\n    user=None,\n):\n    \"\"\"\n    This function configures and renders a job based on the arguments\n\n    :param list jobs: MRQ jobs to render\n    :param list shots: Shots to render from jobs\n    :param bool all_shots: Flag for rendering all shots\n    :param str user: Render user\n    \"\"\"\n\n    # Iterate over all the jobs and make sure the jobs we want to\n    # render are enabled.\n    # All jobs that are not going to be rendered will be disabled if the\n    # job enabled attribute is not set or their shots disabled.\n    # The expectation is, If a job name is specified, we want to render the\n    # current state of that job.\n    # If a shot list is specified, we want to only render that shot alongside\n    # any other whole jobs (job states) that are explicitly specified,\n    # else other jobs or shots that are not\n    # needed are disabled\n    for job in movie_pipeline_queue.get_jobs():\n        enable_job = False\n\n        # Get a list of jobs to enable.\n        # This will enable jobs in their current queue state awaiting other\n        # modifications if shots are provided, if only the job name is\n        # specified, the job will be rendered in its current state\n        if jobs and (job.job_name in jobs):\n            enable_job = True\n\n        # If we are told to render all shots. Enable all shots for all jobs\n        if all_shots:\n            for shot in job.shot_info:\n                shot.enabled = True\n\n            # set the user for the current job\n            job.author = user or getuser()\n\n            # Set the job to enabled and move on to the next job\n            set_job_state(job, enable=True)\n\n            continue\n\n        # If we have a list of shots, go through the shots associated\n        # with this job, enable the shots that need to be rendered and\n        # disable the others\n        if shots and (not enable_job):\n            for shot in job.shot_info:\n                if shot.inner_name in shots or (shot.outer_name in shots):\n                    shot.enabled = True\n                    enable_job = True\n                else:\n                    unreal.log_warning(\n                        f\"Disabling shot `{shot.inner_name}` from current render job `{job.job_name}`\"\n                    )\n                    shot.enabled = False\n\n        if enable_job:\n            # Set the author on the job\n            job.author = user or getuser()\n\n        # Set the state of the job by enabling or disabling it.\n        set_job_state(job, enable=enable_job)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.mrq_cli_modes.utils.update_render_output","title":"<code>update_render_output(job, output_dir=None, output_filename=None)</code>","text":"<p>Updates that output directory and filename on a render job</p> <p>:param job: MRQ job :param str output_dir: Output directory for renders :param str output_filename: Output filename</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/mrq_cli_modes/utils.py</code> <pre><code>def update_render_output(job, output_dir=None, output_filename=None):\n    \"\"\"\n    Updates that output directory and filename on a render job\n\n    :param job: MRQ job\n    :param str output_dir: Output directory for renders\n    :param str output_filename: Output filename\n    \"\"\"\n\n    # Get the job output settings\n    output_setting = job.get_configuration().find_setting_by_class(\n        unreal.MoviePipelineOutputSetting\n    )\n\n    if output_dir:\n        new_output_dir = unreal.DirectoryPath()\n        new_output_dir.set_editor_property(\n            \"path\",\n            output_dir\n        )\n        unreal.log_warning(\n            f\"Overriding output directory! New output directory is `{output_dir}`.\"\n        )\n        output_setting.output_directory = new_output_dir\n\n    if output_filename:\n        unreal.log_warning(\n            \"Overriding filename format! New format is `{output_filename}`.\"\n        )\n\n        output_setting.file_name_format = output_filename\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/pipeline_actions/index.html","title":"pipeline_actions","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/pipeline_actions/render_queue_action.html","title":"render_queue_action","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/pipeline_actions/render_queue_action.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.MoviePipelineDeadline.Content.Python.pipeline_actions.render_queue_action.register_menu_action","title":"<code>register_menu_action()</code>","text":"<p>Creates the toolbar menu</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/MoviePipelineDeadline/Content/Python/pipeline_actions/render_queue_action.py</code> <pre><code>def register_menu_action():\n    \"\"\"\n    Creates the toolbar menu\n    \"\"\"\n\n    if not _validate_euw_asset_exists():\n        unreal.log_warning(\n            f\"EUW `{EDITOR_UTILITY_WIDGET}` does not exist in the Asset registry!\"\n        )\n        return\n\n    toolbar = DeadlineToolBarMenu()\n\n    toolbar.register_submenu(\n        \"SubmitMRQAsset\",\n        _launch_queue_asset_submitter,\n        label_name=\"Submit Movie Render Queue Asset\",\n        description=\"Submits a Movie Render Queue asset to Deadline\"\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/index.html","title":"UnrealDeadlineService","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/index.html","title":"Content","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/index.html","title":"Python","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_command.html","title":"deadline_command","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_command.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_command.DeadlineCommand","title":"<code>DeadlineCommand</code>","text":"<p>Class to manage use of DeadlineCommand</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_command.py</code> <pre><code>class DeadlineCommand:\n    \"\"\"\n    Class to manage use of DeadlineCommand\n    \"\"\"\n    def __init__(self):\n        self.deadlineCommand = self._get_DeadlineCommand()\n\n    def _get_DeadlineCommand(self):\n        # type: () -&gt; str\n        deadlineBin = \"\" # type: str\n        try:\n            deadlineBin = os.environ['DEADLINE_PATH']\n        except KeyError:\n            #if the error is a key error it means that DEADLINE_PATH is not set. however Deadline command may be in the PATH or on OSX it could be in the file /Users/Shared/Thinkbox/DEADLINE_PATH\n            pass\n\n        # On OSX, we look for the DEADLINE_PATH file if the environment variable does not exist.\n        if deadlineBin == \"\" and  os.path.exists( \"/Users/Shared/Thinkbox/DEADLINE_PATH\" ):\n            with open( \"/Users/Shared/Thinkbox/DEADLINE_PATH\" ) as f:\n                deadlineBin = f.read().strip()\n\n        deadlineCommand = os.path.join(deadlineBin, \"deadlinecommand\") # type: str\n\n        return deadlineCommand\n\n    def get_repository_path(self, subdir = None):\n\n        startupinfo = None\n\n        args = [self.deadlineCommand, \"-GetRepositoryPath \"]   \n        if subdir != None and subdir != \"\":\n            args.append(subdir)\n\n        # Specifying PIPE for all handles to workaround a Python bug on Windows. The unused handles are then closed immediatley afterwards.\n        logger.debug(f\"Getting repository path via deadlinecommand with subprocess args: {args}\")\n        proc = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, startupinfo=startupinfo)\n\n        proc.stdin.close()\n        proc.stderr.close()\n\n        output = proc.stdout.read()\n\n        path = output.decode(\"utf_8\")\n        path = path.replace(\"\\r\",\"\").replace(\"\\n\",\"\").replace(\"\\\\\",\"/\")\n\n        return path\n\n    def get_pools(self):\n        startupinfo = None\n\n        args = [self.deadlineCommand, \"-GetPoolNames\"]   \n\n        # Specifying PIPE for all handles to workaround a Python bug on Windows. The unused handles are then closed immediatley afterwards.\n        logger.debug(f\"Getting pools via deadlinecommand with subprocess args: {args}\")\n        proc = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, startupinfo=startupinfo)\n\n        proc.stdin.close()\n        proc.stderr.close()\n\n        output = proc.stdout.read()\n\n        path = output.decode(\"utf_8\")\n\n        return path.split(os.linesep)\n\n    def get_groups(self):\n        startupinfo = None\n\n        args = [self.deadlineCommand, \"-GetGroupNames\"]   \n\n        # Specifying PIPE for all handles to workaround a Python bug on Windows. The unused handles are then closed immediatley afterwards.\n        logger.debug(f\"Getting groupsvia deadlinecommand with subprocess args: {args}\")\n        proc = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, startupinfo=startupinfo)\n\n        proc.stdin.close()\n        proc.stderr.close()\n\n        output = proc.stdout.read()\n\n        path = output.decode(\"utf_8\")\n\n        return path.split(os.linesep)\n\n    def submit_job(self, job_data):\n        startupinfo = None\n\n        # cast dict to list of strings equivilent to job file and plugin file\n        job_info = [k+'='+v.replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\"\\t\",\"\")+'\\n' for k, v in job_data[\"JobInfo\"].items()]\n        plugin_info = [k+'='+v.replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\"\\t\",\"\")+'\\n' for k, v in job_data[\"PluginInfo\"].items()]\n\n        with tempfile.NamedTemporaryFile(mode = \"w\", delete=False) as f_job, tempfile.NamedTemporaryFile(mode = \"w\", delete=False) as f_plugin:\n            logger.debug(f\"Creating temporary job file {f_job.name}\")\n            logger.debug(f\"Creating temporary plugin file {f_plugin.name}\")\n            f_job.writelines(job_info)\n            f_plugin.writelines(plugin_info)\n\n            f_job.close()\n            f_plugin.close()\n\n            args = [self.deadlineCommand, \"-SubmitJob\", f_job.name, f_plugin.name]   \n            args.extend(job_data[\"aux_files\"]) if \"aux_files\" in job_data else None  #  If aux files present extend args\n            # Specifying PIPE for all handles to workaround a Python bug on Windows. The unused handles are then closed immediatley afterwards.\n            logger.debug(f\"Submitting job via deadlinecommand with subprocess args: {args}\")\n            proc = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, startupinfo=startupinfo)\n\n            # On windows machines Temproary files cannot be opened by multiple processes so we cann use the delete=True flag and must clean up the tmp files ourselves.\n            # https://docs.python.org/3/library/tempfile.html#tempfile.NamedTemporaryFile\n            proc.wait()\n            os.remove(f_job.name)\n            os.remove(f_plugin.name)\n            logger.debug(f\"Removed temporary job file {f_job.name}\")\n            logger.debug(f\"Removed temporary plugin file {f_plugin.name}\")\n\n\n        proc.stdin.close()\n        proc.stderr.close()\n\n        output = proc.stdout.read()\n        job_ids = []\n        for line in output.decode(\"utf_8\").split(os.linesep):\n            if line.startswith(\"JobID\"):\n                job_ids.append(line.split(\"=\")[1].strip())\n\n        return min(job_ids)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.html","title":"deadline_enums","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_enums.AutoRequestName","title":"<code>AutoRequestName</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Function to auto generate the enum value from its name. Reference: https://docs.python.org/3/library/enum.html#using-automatic-values</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.py</code> <pre><code>class AutoRequestName(Enum):\n    \"\"\"\n    Function to auto generate the enum value from its name.\n    Reference: https://docs.python.org/3/library/enum.html#using-automatic-values\n    \"\"\"\n    def _generate_next_value_(name, start, count, last_values):\n        return name\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_enums.DeadlineJobState","title":"<code>DeadlineJobState</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum class for deadline states</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.py</code> <pre><code>class DeadlineJobState(Enum):\n    \"\"\"Enum class for deadline states\"\"\"\n\n    SUSPEND = \"suspend\"\n    RESUME = \"resume\"\n    REQUEUE = \"requeue\"\n    PEND = \"pend\"\n    ARCHIVE = \"archive\"\n    RESUME_FAILED = \"resumefailed\"\n    SUSPEND_NON_RENDERING = \"suspendnonrendering\"\n    RELEASE_PENDING = \"releasepending\"\n    COMPLETE = \"complete\"\n    FAIL = \"fail\"\n    UPDATE_SUBMISSION_DATE = \"updatesubmissiondate\"\n    UNDELETE = \"undelete\"\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_enums.DeadlineJobStatus","title":"<code>DeadlineJobStatus</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum class for deadline job status Reference: https://docs.thinkboxsoftware.com/products/deadline/10.1/1_User%20Manual/manual/rest-jobs.html#job-property-values</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.py</code> <pre><code>class DeadlineJobStatus(Enum):\n    \"\"\"\n    Enum class for deadline job status\n    Reference: https://docs.thinkboxsoftware.com/products/deadline/10.1/1_User%20Manual/manual/rest-jobs.html#job-property-values\n    \"\"\"\n\n    UNKNOWN = \"Unknown\"\n    ACTIVE = \"Active\"\n    SUSPENDED = \"Suspended\"\n    COMPLETED = \"Completed\"\n    FAILED = \"Failed\"\n    RENDERING = \"Rendering\"\n    PENDING = \"Pending\"\n    IDLE = \"Idle\"\n    QUEUED = \"Queued\"\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_enums.HttpRequestType","title":"<code>HttpRequestType</code>","text":"<p>               Bases: <code>AutoRequestName</code></p> <p>Enum class for HTTP request types</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_enums.py</code> <pre><code>class HttpRequestType(AutoRequestName):\n    \"\"\"\n    Enum class for HTTP request types\n    \"\"\"\n    GET = auto()\n    PUT = auto()\n    POST = auto()\n    DELETE = auto()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.html","title":"deadline_http","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_http.DeadlineHttp","title":"<code>DeadlineHttp</code>","text":"<p>Class to send requests to deadline server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.py</code> <pre><code>class DeadlineHttp:\n    \"\"\"\n    Class to send requests to deadline server\n    \"\"\"\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Magic Methods\n\n    def __init__(self, host):\n        \"\"\"\n        Constructor\n        :param str host: Deadline server host\n        \"\"\"\n        self.host = host\n\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Public Methods\n\n    def send_http_request(self, request_type, api_url, payload=None, fields=None, headers=None, retries=0):\n        \"\"\"\n        This method is used to upload or receive data from the Deadline server.\n        :param HttpRequestType request_type: HTTP request verb. i.e GET/POST/PUT/DELETE\n        :param str api_url: URL relative path queries. Example: /jobs , /pools, /jobs?JobID=0000\n        :param payload: Data object to POST/PUT to Deadline server\n        :param dict fields: Request fields. This is typically used in files and binary uploads\n        :param dict headers: Header data for request\n        :param int retries: The number of retries to attempt before failing request. Defaults to 0.\n        :return: JSON object response from the server.\n        \"\"\"\n        self._http_manager = PoolManager(cert_reqs='CERT_NONE')   # Disable SSL certificate check\n        # Validate request type\n        if not isinstance(request_type, HttpRequestType):\n            raise ValueError(f\"Request type must be of type {type(HttpRequestType)}\")\n\n        response = self._http_manager.request(\n            request_type.value,\n            urljoin(self.host, api_url),\n            body=payload,\n            fields=fields,\n            headers=headers,\n            retries=retries\n        )\n\n        return response.data\n\n    def get_job_details(self, job_id):\n        \"\"\"\n        This method gets the job details for the deadline job\n        :param str job_id: Deadline JobID\n        :return: Job details object returned from the server. Usually a Json object\n        \"\"\"\n\n        if not job_id:\n            raise ValueError(f\"A JobID is required to get job details from Deadline. Got {job_id}.\")\n\n        api_query_string = f\"api/jobs?JobID={job_id}&amp;Details=true\"\n\n        job_details = self.send_http_request(\n            HttpRequestType.GET,\n            api_query_string\n        )\n\n        try:\n            job_details = json.loads(job_details.decode('utf-8'))[job_id]\n\n        # If an error occurs trying to decode the json data, most likely an error occurred server side thereby\n        # returning a string instead of the data requested.\n        # Raise the decoded error\n        except Exception as err:\n            raise RuntimeError(\n                f\"An error occurred getting the server data for {job_id}: \\n{job_details.decode('utf-8')}\"\n            )\n        else:\n            return job_details\n\n    def send_job_command(self, job_id, command):\n        \"\"\"\n        Send a command to the Deadline server for the job\n        :param str job_id: Deadline JobID\n        :param dict command: Command to send to the deadline server\n        :return: Returns the response from the server\n        \"\"\"\n        api_string = urljoin(self.host, \"/api/jobs\")\n\n        if not job_id:\n            raise RuntimeError(\"There is no deadline job ID to send this command for.\")\n\n        # Add the job id to the command dictionary\n        command.update(JobID=job_id)\n\n        response = self.send_http_request(\n            HttpRequestType.PUT,\n            api_string,\n            payload=json.dumps(command).encode('utf-8'),\n            headers={'Content-Type': 'application/json'}\n        )\n\n        return response.decode('utf-8')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_http.DeadlineHttp.__init__","title":"<code>__init__(host)</code>","text":"<p>Constructor :param str host: Deadline server host</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.py</code> <pre><code>def __init__(self, host):\n    \"\"\"\n    Constructor\n    :param str host: Deadline server host\n    \"\"\"\n    self.host = host\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_http.DeadlineHttp.get_job_details","title":"<code>get_job_details(job_id)</code>","text":"<p>This method gets the job details for the deadline job :param str job_id: Deadline JobID :return: Job details object returned from the server. Usually a Json object</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.py</code> <pre><code>def get_job_details(self, job_id):\n    \"\"\"\n    This method gets the job details for the deadline job\n    :param str job_id: Deadline JobID\n    :return: Job details object returned from the server. Usually a Json object\n    \"\"\"\n\n    if not job_id:\n        raise ValueError(f\"A JobID is required to get job details from Deadline. Got {job_id}.\")\n\n    api_query_string = f\"api/jobs?JobID={job_id}&amp;Details=true\"\n\n    job_details = self.send_http_request(\n        HttpRequestType.GET,\n        api_query_string\n    )\n\n    try:\n        job_details = json.loads(job_details.decode('utf-8'))[job_id]\n\n    # If an error occurs trying to decode the json data, most likely an error occurred server side thereby\n    # returning a string instead of the data requested.\n    # Raise the decoded error\n    except Exception as err:\n        raise RuntimeError(\n            f\"An error occurred getting the server data for {job_id}: \\n{job_details.decode('utf-8')}\"\n        )\n    else:\n        return job_details\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_http.DeadlineHttp.send_http_request","title":"<code>send_http_request(request_type, api_url, payload=None, fields=None, headers=None, retries=0)</code>","text":"<p>This method is used to upload or receive data from the Deadline server. :param HttpRequestType request_type: HTTP request verb. i.e GET/POST/PUT/DELETE :param str api_url: URL relative path queries. Example: /jobs , /pools, /jobs?JobID=0000 :param payload: Data object to POST/PUT to Deadline server :param dict fields: Request fields. This is typically used in files and binary uploads :param dict headers: Header data for request :param int retries: The number of retries to attempt before failing request. Defaults to 0. :return: JSON object response from the server.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.py</code> <pre><code>def send_http_request(self, request_type, api_url, payload=None, fields=None, headers=None, retries=0):\n    \"\"\"\n    This method is used to upload or receive data from the Deadline server.\n    :param HttpRequestType request_type: HTTP request verb. i.e GET/POST/PUT/DELETE\n    :param str api_url: URL relative path queries. Example: /jobs , /pools, /jobs?JobID=0000\n    :param payload: Data object to POST/PUT to Deadline server\n    :param dict fields: Request fields. This is typically used in files and binary uploads\n    :param dict headers: Header data for request\n    :param int retries: The number of retries to attempt before failing request. Defaults to 0.\n    :return: JSON object response from the server.\n    \"\"\"\n    self._http_manager = PoolManager(cert_reqs='CERT_NONE')   # Disable SSL certificate check\n    # Validate request type\n    if not isinstance(request_type, HttpRequestType):\n        raise ValueError(f\"Request type must be of type {type(HttpRequestType)}\")\n\n    response = self._http_manager.request(\n        request_type.value,\n        urljoin(self.host, api_url),\n        body=payload,\n        fields=fields,\n        headers=headers,\n        retries=retries\n    )\n\n    return response.data\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_http.DeadlineHttp.send_job_command","title":"<code>send_job_command(job_id, command)</code>","text":"<p>Send a command to the Deadline server for the job :param str job_id: Deadline JobID :param dict command: Command to send to the deadline server :return: Returns the response from the server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_http.py</code> <pre><code>def send_job_command(self, job_id, command):\n    \"\"\"\n    Send a command to the Deadline server for the job\n    :param str job_id: Deadline JobID\n    :param dict command: Command to send to the deadline server\n    :return: Returns the response from the server\n    \"\"\"\n    api_string = urljoin(self.host, \"/api/jobs\")\n\n    if not job_id:\n        raise RuntimeError(\"There is no deadline job ID to send this command for.\")\n\n    # Add the job id to the command dictionary\n    command.update(JobID=job_id)\n\n    response = self.send_http_request(\n        HttpRequestType.PUT,\n        api_string,\n        payload=json.dumps(command).encode('utf-8'),\n        headers={'Content-Type': 'application/json'}\n    )\n\n    return response.decode('utf-8')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html","title":"deadline_job","text":"<p>Deadline Job object used to submit jobs to the render farm</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob","title":"<code>DeadlineJob</code>","text":"<p>Unreal Deadline Job object</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.py</code> <pre><code>class DeadlineJob:\n    \"\"\" Unreal Deadline Job object \"\"\"\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Magic Methods\n\n    def __init__(self, job_info=None, plugin_info=None, job_preset: unreal.DeadlineJobPreset=None):\n        \"\"\" Constructor \"\"\"\n        self._job_id = None\n        self._job_info = {}\n        self._plugin_info = {}\n        self._aux_files = []\n        self._job_status: DeadlineJobStatus = DeadlineJobStatus.UNKNOWN\n        self._job_progress = 0.0\n\n        # Jobs details updated by server after submission\n        self._job_details = None\n\n        # Update the job, plugin and aux file info from the data asset\n        if job_info and plugin_info:\n            self.job_info = job_info\n            self.plugin_info = plugin_info\n\n        if job_preset:\n            self.job_info, self.plugin_info = get_deadline_info_from_preset(job_preset=job_preset)\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.job_name}, {self.job_id})\"\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Public Properties\n\n    @property\n    def job_info(self):\n        \"\"\"\n        Returns the Deadline job info\n        :return: Deadline job Info as a dictionary\n        :rtype: dict\n        \"\"\"\n        return self._job_info\n\n    @job_info.setter\n    def job_info(self, value: dict):\n        \"\"\"\n        Sets the Deadline Job Info\n        :param value:  Value to set on the job info.\n        \"\"\"\n        if not isinstance(value, dict):\n            raise TypeError(f\"Expected `dict` found {type(value)}\")\n\n        self._job_info = merge_dictionaries(self.job_info, value)\n\n        if \"AuxFiles\" in self._job_info:\n            # Set the auxiliary files for this instance\n            self._aux_files = self._job_info.get(\"AuxFiles\", [])\n\n            # Remove the aux files array from the dictionary, doesn't belong there\n            self._job_info.pop(\"AuxFiles\")\n\n    @property\n    def plugin_info(self):\n        \"\"\"\n        Returns the Deadline plugin info\n        :return: Deadline plugin Info as a dictionary\n        :rtype: dict\n        \"\"\"\n        return self._plugin_info\n\n    @plugin_info.setter\n    def plugin_info(self, value: dict):\n        \"\"\"\n        Sets the Deadline Plugin Info\n        :param value: Value to set on plugin info.\n        \"\"\"\n        if not isinstance(value, dict):\n            raise TypeError(f\"Expected `dict` found {type(value)}\")\n\n        self._plugin_info = merge_dictionaries(self.plugin_info, value)\n\n    @property\n    def job_id(self):\n        \"\"\"\n        Return the deadline job ID. This is the ID returned by the service after the job has been submitted\n        \"\"\"\n        return self._job_id\n\n    @property\n    def job_name(self):\n        \"\"\"\n        Return the deadline job name.\n        \"\"\"\n        return self.job_info.get(\"Name\", \"Unnamed Job\")\n\n    @job_name.setter\n    def job_name(self, value):\n        \"\"\"\n        Updates the job name on the instance. This also updates the job name in the job info dictionary\n        :param str value: job name\n        \"\"\"\n        self.job_info.update({\"Name\": value})\n\n    @property\n    def aux_files(self):\n        \"\"\"\n        Returns the Auxiliary files for this job\n        :return: List of Auxiliary files\n        \"\"\"\n        return self._aux_files\n\n    @property\n    def job_status(self):\n        \"\"\"\n        Return the current job status\n        :return: Deadline status\n        \"\"\"\n\n        if not self.job_details:\n            return DeadlineJobStatus.UNKNOWN\n\n        if \"Job\" not in self.job_details and \"Status\" not in self.job_details[\"Job\"]:\n            return DeadlineJobStatus.UNKNOWN\n\n        # Some Job statuses are represented as \"Rendering (1)\" to indicate the\n        # current status of the job and the number of tasks performing the\n        # current status. We only care about the job status so strip out the\n        # extra information. Task details are returned to the job details\n        # object which can be queried in a different implementation\n        return self.get_job_status_enum(self.job_details[\"Job\"][\"Status\"].split()[0])\n\n    @job_status.setter\n    def job_status(self, value):\n        \"\"\"\n        Return the current job status\n        :param DeadlineJobStatus value: Job status to set on the object.\n        :return: Deadline status\n        \"\"\"\n\n        # Statuses are expected to live in the job details object. Usually this\n        # property is only explicitly set if the status of a job is unknown.\n        # for example if the service detects a queried job is non-existent on\n        # the farm\n\n        # NOTE: If the structure of how job status are represented in the job\n        #  details changes, this implementation will need to be updated.\n        #  Currently job statuses are represented in the jobs details as\n        #  {\"Job\": {\"Status\": \"Unknown\"}}\n\n        # \"value\" is expected to be an Enum so get the name of the Enum and set\n        # it on the job details. When the status property is called,\n        # this will be re-translated back into an enum. The reason for this is,\n        # the native job details object returned from the service has no\n        # concept of the job status enum. This is an internal\n        # representation which allows for more robust comparison operator logic\n        if self.job_details and isinstance(self.job_details, dict):\n            self.job_details.update({\"Job\": {\"Status\": value.name}})\n\n    @property\n    def job_progress(self):\n        \"\"\"\n        Returns the current job progress\n        :return: Deadline job progress as a float value\n        \"\"\"\n\n        if not self.job_details:\n            return 0.0\n\n        if \"Job\" in self.job_details and \"Progress\" in self.job_details[\"Job\"]:\n            progress_str = self._job_details[\"Job\"][\"Progress\"]\n            progress_str = progress_str.split()[0]\n\n            return float(progress_str) / 100  # 0-1 progress\n\n    @property\n    def job_details(self):\n        \"\"\"\n        Returns the job details from the deadline service.\n        :return: Deadline Job details\n        \"\"\"\n        return self._job_details\n\n    @job_details.setter\n    def job_details(self, value):\n        \"\"\"\n        Sets the job details from the deadline service. This is typically set\n        by the service, but can be used as a general container for job\n        information.\n        \"\"\"\n        self._job_details = value\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Public Methods\n\n    def get_submission_data(self):\n        \"\"\"\n        Returns the submission data used by the Deadline service to submit a job\n        :return: Dictionary with job, plugin, auxiliary info\n        :rtype: dict\n        \"\"\"\n        return {\n            \"JobInfo\": self.job_info,\n            \"PluginInfo\": self.plugin_info,\n            \"AuxFiles\": self.aux_files\n        }\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Protected Methods\n\n    @staticmethod\n    def get_job_status_enum(job_status):\n        \"\"\"\n        This method returns an enum representing the job status from the server\n        :param job_status: Deadline job status\n        :return: Returns the job_status as an  enum\n        :rtype DeadlineJobStatus\n        \"\"\"\n        # Convert this job status returned by the server into the job status\n        # enum representation\n\n        # Check if the job status name has an enum representation, if not check\n        # the value of the job_status.\n        # Reference: https://docs.thinkboxsoftware.com/products/deadline/10.1/1_User%20Manual/manual/rest-jobs.html#job-property-values\n        try:\n            status = DeadlineJobStatus(job_status)\n        except ValueError:\n            try:\n                status = getattr(DeadlineJobStatus, job_status)\n            except Exception as exp:\n                raise RuntimeError(f\"An error occurred getting the Enum status type of {job_status}. Error: \\n\\t{exp}\")\n\n        return status\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.aux_files","title":"<code>aux_files</code>  <code>property</code>","text":"<p>Returns the Auxiliary files for this job :return: List of Auxiliary files</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.job_details","title":"<code>job_details</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the job details from the deadline service. :return: Deadline Job details</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.job_id","title":"<code>job_id</code>  <code>property</code>","text":"<p>Return the deadline job ID. This is the ID returned by the service after the job has been submitted</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.job_info","title":"<code>job_info</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the Deadline job info :return: Deadline job Info as a dictionary :rtype: dict</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.job_name","title":"<code>job_name</code>  <code>property</code> <code>writable</code>","text":"<p>Return the deadline job name.</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.job_progress","title":"<code>job_progress</code>  <code>property</code>","text":"<p>Returns the current job progress :return: Deadline job progress as a float value</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.job_status","title":"<code>job_status</code>  <code>property</code> <code>writable</code>","text":"<p>Return the current job status :return: Deadline status</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.plugin_info","title":"<code>plugin_info</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the Deadline plugin info :return: Deadline plugin Info as a dictionary :rtype: dict</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.__init__","title":"<code>__init__(job_info=None, plugin_info=None, job_preset=None)</code>","text":"<p>Constructor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.py</code> <pre><code>def __init__(self, job_info=None, plugin_info=None, job_preset: unreal.DeadlineJobPreset=None):\n    \"\"\" Constructor \"\"\"\n    self._job_id = None\n    self._job_info = {}\n    self._plugin_info = {}\n    self._aux_files = []\n    self._job_status: DeadlineJobStatus = DeadlineJobStatus.UNKNOWN\n    self._job_progress = 0.0\n\n    # Jobs details updated by server after submission\n    self._job_details = None\n\n    # Update the job, plugin and aux file info from the data asset\n    if job_info and plugin_info:\n        self.job_info = job_info\n        self.plugin_info = plugin_info\n\n    if job_preset:\n        self.job_info, self.plugin_info = get_deadline_info_from_preset(job_preset=job_preset)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.get_job_status_enum","title":"<code>get_job_status_enum(job_status)</code>  <code>staticmethod</code>","text":"<p>This method returns an enum representing the job status from the server :param job_status: Deadline job status :return: Returns the job_status as an  enum :rtype DeadlineJobStatus</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.py</code> <pre><code>@staticmethod\ndef get_job_status_enum(job_status):\n    \"\"\"\n    This method returns an enum representing the job status from the server\n    :param job_status: Deadline job status\n    :return: Returns the job_status as an  enum\n    :rtype DeadlineJobStatus\n    \"\"\"\n    # Convert this job status returned by the server into the job status\n    # enum representation\n\n    # Check if the job status name has an enum representation, if not check\n    # the value of the job_status.\n    # Reference: https://docs.thinkboxsoftware.com/products/deadline/10.1/1_User%20Manual/manual/rest-jobs.html#job-property-values\n    try:\n        status = DeadlineJobStatus(job_status)\n    except ValueError:\n        try:\n            status = getattr(DeadlineJobStatus, job_status)\n        except Exception as exp:\n            raise RuntimeError(f\"An error occurred getting the Enum status type of {job_status}. Error: \\n\\t{exp}\")\n\n    return status\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_job.DeadlineJob.get_submission_data","title":"<code>get_submission_data()</code>","text":"<p>Returns the submission data used by the Deadline service to submit a job :return: Dictionary with job, plugin, auxiliary info :rtype: dict</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_job.py</code> <pre><code>def get_submission_data(self):\n    \"\"\"\n    Returns the submission data used by the Deadline service to submit a job\n    :return: Dictionary with job, plugin, auxiliary info\n    :rtype: dict\n    \"\"\"\n    return {\n        \"JobInfo\": self.job_info,\n        \"PluginInfo\": self.plugin_info,\n        \"AuxFiles\": self.aux_files\n    }\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html","title":"deadline_service","text":"<p>Thinkbox Deadline REST API service plugin used to submit and query jobs from a Deadline server</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService","title":"<code>DeadlineService</code>","text":"<p>Singleton class to handle Deadline submissions. We are using a singleton class as there is no need to have multiple instances of the service. This allows job queries and submissions to be tracked by a single entity and be a source of truth on the client about all jobs created in the current session.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>class DeadlineService(metaclass=_Singleton):\n    \"\"\"\n    Singleton class to handle Deadline submissions.\n    We are using a singleton class as there is no need to have multiple instances of the service. This allows job\n    queries and submissions to be tracked by a single entity and be a source of truth on the client about all jobs\n    created in the current session.\n    \"\"\"\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Magic Methods\n\n    def __init__(self, host=None, auto_start_job_updates=False, service_update_interval=1.0):\n        \"\"\"\n        Deadline service class for submitting jobs to deadline and querying data from deadline\n        :param str host: Deadline host\n        :param bool auto_start_job_updates: This flag auto starts processing jobs when the service is initialized\n            tracked by the service\n        :param float service_update_interval: Interval(seconds) for job update frequency. Default is 2.0 seconds\n        \"\"\"\n\n        # Track a dictionary of jobs registered with the service. This dictionary contains job object instance ID and a\n        # reference to the job instance object and deadline job ID.\n        # i.e {\"instance_object_id\": {\"object\": &lt;job class instance&gt;, \"job_id\": 0001 or None}}\n        self._current_jobs = {}\n        self._submitted_jobs = {} # Similar to the current jobs, this tracks all jobs submitted\n        self._failed_jobs = set()\n        self._completed_jobs = set()\n\n        # This flag determines if the service should deregister a job when it fails on the server\n        self.deregister_job_on_failure = True\n\n        # Thread execution variables\n        self._event_thread = None\n        self._exit_auto_update = False\n        self._update_thread_event = Event()\n\n        self._service_update_interval = service_update_interval\n\n        # A timer for executing job update functions on an interval\n        self._event_timer_manager = self.get_event_manager()\n        self._event_handler = None\n\n        # Use DeadlineCommand by defaut\n        self._use_deadline_command = self._get_use_deadline_cmd() # True  # TODO: hardcoded for testing, change to project read setting\n\n        # Get/Set service host\n        self._host = host or self._get_deadline_host()\n\n        # Get deadline https instance\n        self._http_server = DeadlineHttp(self.host)\n\n        if auto_start_job_updates:\n            self.start_job_updates()\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Public Properties\n\n    @property\n    def pools(self):\n        \"\"\"\n        Returns the current list of pools found on the server\n        :return: List of pools on the server\n        \"\"\"\n        return self._get_pools()\n\n    @property\n    def groups(self):\n        \"\"\"\n        Returns the current list of groups found on the server\n        :return: List of groups  on the server\n        \"\"\"\n        return self._get_groups()\n\n    @property\n    def use_deadline_command(self):\n        \"\"\"\n        Returns the current value of the use deadline command flag\n        :return: True if the service uses the deadline command, False otherwise\n        \"\"\"\n        return self._use_deadline_command\n\n    @use_deadline_command.setter\n    def use_deadline_command(self, value):\n        \"\"\"\n        Sets the use deadline command flag\n        :param value: True if the service uses the deadline command, False otherwise\n        \"\"\"\n        self._use_deadline_command = value\n\n    @property\n    def host(self):\n        \"\"\"\n        Returns the server url used by the service\n        :return: Service url\n        \"\"\"\n        return self._host\n\n    @host.setter\n    def host(self, value):\n        \"\"\"\n        Set the server host on the service\n        :param value: host value\n        \"\"\"\n        self._host = value\n\n        # When the host service is updated, get a new connection to that host\n        self._http_server = DeadlineHttp(self._host)\n\n    @property\n    def current_jobs(self):\n        \"\"\"\n        Returns the global current jobs tracked by the service\n        :return: List of Jobs tracked by the service\n        \"\"\"\n        return [value[\"object\"] for value in self._current_jobs.values()]\n\n    @property\n    def failed_jobs(self):\n        \"\"\"\n        Returns the failed jobs tracked by the service\n        :return: List of failed Jobs tracked by the service\n        \"\"\"\n        return self._failed_jobs\n\n    @property\n    def completed_jobs(self):\n        \"\"\"\n        Returns the completed jobs tracked by the service\n        :return: List of completed Jobs tracked by the service\n        \"\"\"\n        return self._completed_jobs\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Protected Methods\n\n    def _get_pools(self):\n        \"\"\"\n        This method updates the set of pools tracked by the service\n        \"\"\"\n        if self._get_use_deadline_cmd(): # if self._use_deadline_command:\n            return DeadlineCommand().get_pools()\n        else:\n            response = self.send_http_request(\n                HttpRequestType.GET,\n                \"api/pools\",\n                headers={'Content-Type': 'application/json'}\n            )\n            return json.loads(response.decode('utf-8'))\n\n    def _get_groups(self):\n        \"\"\"\n        This method updates the set of groups tracked by the service\n        \"\"\"\n        if self._get_use_deadline_cmd(): # if self._use_deadline_command:\n            return DeadlineCommand().get_groups()\n        else:\n            response = self.send_http_request(\n                HttpRequestType.GET,\n                \"api/groups\",\n                headers={'Content-Type': 'application/json'}\n            )\n            return json.loads(response.decode('utf-8'))\n\n    def _register_job(self, job_object, deadline_job_id=None):\n        \"\"\"\n        This method registers the job object with the service\n        :param DeadlineJob job_object: Deadline Job object\n        :param str deadline_job_id: ID of job returned from the server\n        \"\"\"\n\n        # Set the job Id on the job. The service\n        # should be allowed to set this protected property on the job object as this property should natively\n        # not be allowed to be set externally\n        job_object._job_id = deadline_job_id\n\n        job_data = {\n            str(id(job_object)):\n                {\n                    \"object\": job_object,\n                    \"job_id\": deadline_job_id\n                }\n        }\n\n        self._submitted_jobs.update(job_data)\n        self._current_jobs.update(job_data)\n\n    def _deregister_job(self, job_object):\n        \"\"\"\n        This method removes the current job object from the tracked jobs\n        :param DeadlineJob job_object: Deadline job object\n        \"\"\"\n\n        if str(id(job_object)) in self._current_jobs:\n            self._current_jobs.pop(str(id(job_object)), f\"{job_object} could not be found\")\n\n    def _update_tracked_job_by_status(self, job_object, job_status, update_job=False):\n        \"\"\"\n        This method moves the job object from the tracked list based on the current job status\n        :param DeadlineJob job_object: Deadline job object\n        :param DeadlineJobStatus job_status: Deadline job status\n        :param bool update_job: Flag to update the job object's status to the passed in job status\n        \"\"\"\n\n        # Convert the job status into the appropriate enum. This will raise an error if the status enum does not exist.\n        # If a valid enum is passed into this function, the enum is return\n        job_status = job_object.get_job_status_enum(job_status)\n\n        # If the job has an unknown status, remove it from the currently tracked jobs by the service. Note we are not\n        # de-registering failed jobs unless explicitly set, that's because a failed job can be re-queued and\n        # completed on the next try.\n        # So we do not want to preemptively remove this job from the tracked jobs by the service.\n        if job_status is DeadlineJobStatus.UNKNOWN:\n            self._deregister_job(job_object)\n            self._failed_jobs.add(job_object)\n\n        elif job_status is DeadlineJobStatus.COMPLETED:\n            self._deregister_job(job_object)\n            self._completed_jobs.add(job_object)\n\n        elif job_status is DeadlineJobStatus.FAILED:\n            if self.deregister_job_on_failure:\n                self._deregister_job(job_object)\n                self._failed_jobs.add(job_object)\n\n        if update_job:\n            job_object.job_status = job_status\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Public Methods\n\n    def send_http_request(self, request_type, api_url, payload=None, fields=None, headers=None, retries=0):\n        \"\"\"\n        This method is used to upload or receive data from the Deadline server.\n        :param HttpRequestType request_type: HTTP request verb. i.e GET/POST/PUT/DELETE\n        :param str api_url: URL relative path queries. Example: /jobs , /pools, /jobs?JobID=0000\n        :param payload: Data object to POST/PUT to Deadline server\n        :param dict fields: Request fields. This is typically used in files and binary uploads\n        :param dict headers: Header data for request\n        :param int retries: The number of retries to attempt before failing request. Defaults to 0.\n        :return: JSON object response from the server\n        \"\"\"\n\n        # Make sure we always have the most up-to-date host\n        if not self.host or (self.host != self._get_deadline_host()):\n            self.host = self._get_deadline_host()\n\n        try:\n            response = self._http_server.send_http_request(\n                request_type,\n                api_url,\n                payload=payload,\n                fields=fields,\n                headers=headers,\n                retries=retries\n            )\n\n        except Exception as err:\n            raise DeadlineServiceError(f\"Communication with {self.host} failed with err: \\n{err}\")\n        else:\n            return response\n\n    def submit_job(self, job_object):\n        \"\"\"\n        This method submits the tracked job to the Deadline server\n        :param DeadlineJob job_object: Deadline Job object\n        :returns: Deadline `JobID` if an id was returned from the server\n        \"\"\"\n        self._validate_job_object(job_object)\n\n        logger.debug(f\"Submitting {job_object} to {self.host}..\")\n\n        if str(id(job_object)) in self._current_jobs:\n            logger.warning(f\"{job_object} has already been added to the service\")\n\n            # Return the job ID of the submitted job\n            return job_object.job_id\n\n        job_id = None\n\n        job_data = job_object.get_submission_data()\n\n        # Set the job data to return the job ID on submission\n        job_data.update(IdOnly=\"true\")\n\n        # Update the job data to include the user and machine submitting the job\n        # Update the username if one is not supplied\n        if \"UserName\" not in job_data[\"JobInfo\"]:\n\n            # NOTE: Make sure this matches the expected naming convention by the server else the user will get\n            #  permission errors on job submission\n            # Todo: Make sure the username convention matches the username on the server\n            job_data[\"JobInfo\"].update(UserName=getuser())\n\n        job_data[\"JobInfo\"].update(MachineName=platform.node())\n\n        self._validate_job_info(job_data[\"JobInfo\"])\n\n        if self._get_use_deadline_cmd(): # if self._use_deadline_command:\n            # Submit the job to the Deadline server using the Deadline command\n            # Todo: Add support for the Deadline command\n            job_id = DeadlineCommand().submit_job(job_data)\n\n        else:\n            # Submit the job to the Deadline server using the HTTP API\n            try:\n                response = self.send_http_request(\n                    HttpRequestType.POST,\n                    \"api/jobs\",\n                    payload=json.dumps(job_data).encode('utf-8'),\n                    headers={'Content-Type': 'application/json'}\n                )\n\n            except DeadlineServiceError as exp:\n                logger.error(\n                    f\"An error occurred submitting {job_object} to Deadline host `{self.host}`.\\n\\t{str(exp)}\"\n                )\n                self._failed_jobs.add(job_object)\n\n            else:\n                try:\n                    response = json.loads(response.decode('utf-8'))\n\n                # If an error occurs trying to decode the json data, most likely an error occurred server side thereby\n                # returning a string instead of the data requested.\n                # Raise the decoded error\n                except Exception as err:\n                    raise DeadlineServiceError(f\"An error occurred getting the server data:\\n\\t{response.decode('utf-8')}\")\n\n                job_id = response.get('_id', None)\n            if not job_id:\n                logger.warning(\n                    f\"No JobId was returned from the server for {job_object}. \"\n                    f\"The service will not be able to get job details for this job!\"\n                )\n            else:\n                # Register the job with the service.\n                self._register_job(job_object, job_id)\n\n            logger.info(f\"Submitted `{job_object.job_name}` to Deadline. JobID: {job_id}\")\n\n        return job_id\n\n    def get_job_details(self, job_object):\n        \"\"\"\n        This method gets the job details for the Deadline job\n        :param DeadlineJob job_object: Custom Deadline job object\n        :return: Job details object returned from the server. Usually a Json object\n        \"\"\"\n\n        self._validate_job_object(job_object)\n\n        if str(id(job_object)) not in self._current_jobs:\n            logger.warning(\n                f\"{job_object} is currently not tracked by the service. The job has either not been submitted, \"\n                f\"its already completed or there was a problem with the job!\"\n            )\n        elif not job_object.job_id:\n            logger.error(\n                f\"There is no JobID for {job_object}!\"\n            )\n        else:\n\n            try:\n                job_details = self._http_server.get_job_details(job_object.job_id)\n\n            except (Exception, RuntimeError):\n                # If an error occurred, most likely the job does not exist on the server anymore. Mark the job as\n                # unknown\n                self._update_tracked_job_by_status(job_object, DeadlineJobStatus.UNKNOWN, update_job=True)\n            else:\n                # Sometimes Deadline returns a status with a parenthesis after the status indicating the number of tasks\n                # executing. We only care about the status here so lets split the number of tasks out.\n                self._update_tracked_job_by_status(job_object, job_details[\"Job\"][\"Status\"].split()[0])\n                return job_details\n\n    def send_job_command(self, job_object, command):\n        \"\"\"\n        Send a command to the Deadline server for the job\n        :param DeadlineJob job_object: Deadline job object\n        :param dict command: Command to send to the Deadline server\n        :return: Returns the response from the server\n        \"\"\"\n        self._validate_job_object(job_object)\n\n        if not job_object.job_id:\n            raise RuntimeError(\"There is no Deadline job ID to send this command for.\")\n\n        try:\n            response = self._http_server.send_job_command(\n                job_object.job_id,\n                command\n            )\n        except Exception as exp:\n            logger.error(\n                f\"An error occurred getting the command result for {job_object} from Deadline host {self.host}. \"\n                f\"\\n{exp}\"\n            )\n            return \"Fail\"\n        else:\n            if response != \"Success\":\n                logger.error(f\"An error occurred executing command for {job_object}. \\nError: {response}\")\n                return \"Fail\"\n\n            return response\n\n    def change_job_state(self, job_object, state):\n        \"\"\"\n        This modifies a submitted job's state on the Deadline server. This can be used in job orchestration. For example\n        a job can be submitted as suspended/pending and this command can be used to update the state of the job to\n        active after submission.\n        :param DeadlineJob job_object: Deadline job object\n        :param DeadlineJobState state: State to set the job\n        :return: Submission results\n        \"\"\"\n\n        self._validate_job_object(job_object)\n\n        # Validate jobs state\n        if not isinstance(state, DeadlineJobState):\n            raise ValueError(f\"`{state}` is not a valid state.\")\n\n        return self.send_job_command(job_object, {\"Command\": state.value})\n\n    def start_job_updates(self):\n        \"\"\"\n        This method starts an auto update on jobs in the service.\n\n        The purpose of this system is to allow the service to automatically update the job details from the server.\n        This allows you to submit a job from your implementation and periodically poll the changes on the job as the\n        service will continuously update the job details.\n        Note: This function must explicitly be called or the `auto_start_job_updates` flag must be passed to the service\n        instance for this functionality to happen.\n        \"\"\"\n        # Prevent the event from being executed several times in succession\n        if not self._event_handler:\n            if not self._event_thread:\n\n                # Create a thread for the job update function. This function takes the current list of jobs\n                # tracked by the service. The Thread owns an instance of the http connection. This allows the thread\n                # to have its own pool of http connections separate from the main service. A thread event is passed\n                # into the thread which allows the process events from the timer to reactivate the function. The\n                # purpose of this is to prevent unnecessary re-execution while jobs are being processed.\n                # This also allows the main service to stop function execution within the thread and allow it to cleanly\n                # exit.\n\n                # HACK: For some odd reason, passing an instance of the service into the thread seems to work as\n                # opposed to passing in explicit variables. I would prefer explicit variables as the thread does not\n                # need to have access to the entire service object\n\n                # Threading is used here as the editor runs python on the game thread. If a function call is\n                # executed on an interval (as this part of the service is designed to do), this will halt the editor\n                # every n interval to process the update event. A separate thread for processing events allows the\n                # editor to continue functions without interfering with the editor\n\n                # TODO: Figure out a way to have updated variables in the thread vs passing the whole service instance\n                self._event_thread = Thread(\n                    target=self._update_all_jobs,\n                    args=(self,),\n                    name=\"deadline_service_auto_update_thread\",\n                    daemon=True\n                )\n\n                # Start the thread\n                self._event_thread.start()\n\n            else:\n                # If the thread is stopped, restart it.\n                if not self._event_thread.is_alive():\n                    self._event_thread.start()\n\n            def process_events():\n                \"\"\"\n                Function ran by the tick event for monitoring function execution inside of the auto update thread.\n                \"\"\"\n                # Since the editor ticks at a high rate, this monitors the current state of the function execution in\n                # the update thread. When a function is done executing, this resets the event on the function.\n                logger.debug(\"Processing current jobs.\")\n                if self._update_thread_event.is_set():\n\n                    logger.debug(\"Job processing complete, restarting..\")\n                    # Send an event to tell the thread to start the job processing loop\n                    self._update_thread_event.clear()\n\n            # Attach the thread executions to a timer event\n            self._event_timer_manager.on_timer_interval_delegate.add_callable(process_events)\n\n            # Start the timer on an interval\n            self._event_handler = self._event_timer_manager.start_timer(self._service_update_interval)\n\n            # Allow the thread to stop when a python shutdown is detected\n            unreal.register_python_shutdown_callback(self.stop_job_updates)\n\n    def stop_job_updates(self):\n        \"\"\"\n        This method stops the auto update thread. This method should be explicitly called to stop the service from\n        continuously updating the current tracked jobs.\n        \"\"\"\n        if self._event_handler:\n\n            # Remove the event handle to the tick event\n            self.stop_function_timer(self._event_timer_manager, self._event_handler)\n            self._event_handler = None\n\n            if self._event_thread and self._event_thread.is_alive():\n                # Force stop the thread\n                self._exit_auto_update = True\n\n                # immediately stop the thread. Do not wait for jobs to complete.\n                self._event_thread.join(1.0)\n\n                # Usually if a thread is still alive after a timeout, then something went wrong\n                if self._event_thread.is_alive():\n                    logger.error(\"An error occurred closing the auto update Thread!\")\n\n                # Reset the event, thread and tick handler\n                self._update_thread_event.set()\n                self._event_thread = None\n\n    def get_job_object_by_job_id(self, job_id):\n        \"\"\"\n        This method returns the job object tracked by the service based on the deadline job ID\n        :param job_id: Deadline job ID\n        :return: DeadlineJob object\n        :rtype DeadlineJob\n        \"\"\"\n\n        job_object = None\n\n        for job in self._submitted_jobs.values():\n            if job_id == job[\"job_id\"]:\n                job_object = job[\"object\"]\n                break\n\n        return job_object\n\n    # ------------------------------------------------------------------------------------------------------------------\n    # Static Methods\n\n    @staticmethod\n    def _validate_job_info(job_info):\n        \"\"\"\n        This method validates the job info dictionary to make sure\n        the information provided meets a specific standard\n        :param dict job_info: Deadline job info dictionary\n        :raises ValueError\n        \"\"\"\n\n        # validate the job info plugin settings\n        if \"Plugin\" not in job_info or (not job_info[\"Plugin\"]):\n            raise ValueError(\"No plugin was specified in the Job info dictionary\")\n\n    @staticmethod\n    def _get_use_deadline_cmd():\n        \"\"\"\n        Returns the deadline command flag settings from the unreal project settings\n        :return: Deadline command settings unreal project\n        \"\"\"\n        try:\n            # This will be set on the deadline editor project settings\n            deadline_settings = unreal.get_default_object(unreal.DeadlineServiceEditorSettings)\n\n        # Catch any other general exceptions\n        except Exception as exc:\n            unreal.log(\n                f\"Caught Exception while getting use deadline command flag. Error: {exc}\"\n            )\n\n        else:\n            return deadline_settings.deadline_command\n\n    @staticmethod\n    def _get_deadline_host():\n        \"\"\"\n        Returns the host settings from the unreal project settings\n        :return: Deadline host settings unreal project\n        \"\"\"\n        try:\n            # This will be set on the deadline editor project settings\n            deadline_settings = unreal.get_default_object(unreal.DeadlineServiceEditorSettings)\n\n        # Catch any other general exceptions\n        except Exception as exc:\n            unreal.log(\n                f\"Caught Exception while getting deadline host. Error: {exc}\"\n            )\n\n        else:\n            return deadline_settings.deadline_host\n\n    @staticmethod\n    def _validate_job_object(job_object):\n        \"\"\"\n        This method ensures the object passed in is of type DeadlineJob\n        :param DeadlineJob job_object: Python object\n        :raises: RuntimeError if the job object is not of type DeadlineJob\n        \"\"\"\n        # Using type checking instead of isinstance to prevent cyclical imports\n        if not isinstance(job_object, DeadlineJob):\n            raise DeadlineServiceError(f\"Job is not of type DeadlineJob. Found {type(job_object)}!\")\n\n    @staticmethod\n    def _update_all_jobs(service):\n        \"\"\"\n        This method updates current running job properties in a thread.\n        :param DeadlineService service: Deadline service instance\n        \"\"\"\n        # Get a Deadline http instance inside for this function. This function is expected to be executed in a thread.\n        deadline_http = DeadlineHttp(service.host)\n\n        while not service._exit_auto_update:\n\n            while not service._update_thread_event.is_set():\n\n                # Execute the job update properties on the job object\n                for job_object in service.current_jobs:\n\n                    logger.debug(f\"Updating {job_object} job properties\")\n\n                    # Get the job details for this job and update the job details on the job object. The service\n                    # should be allowed to set this protected property on the job object as this property should\n                    # natively not be allowed to be set externally\n                    try:\n                        if job_object.job_id:\n                            job_object.job_details = deadline_http.get_job_details(job_object.job_id)\n\n                    # If a job fails to get job details, log it, mark it unknown\n                    except Exception as err:\n                        logger.exception(f\"An error occurred getting job details for {job_object}:\\n\\t{err}\")\n                        service._update_tracked_job_by_status(\n                            job_object,\n                            DeadlineJobStatus.UNKNOWN,\n                            update_job=True\n                        )\n\n                # Iterate over the jobs and update the tracked jobs by the service\n                for job in service.current_jobs:\n                    service._update_tracked_job_by_status(job, job.job_status)\n\n                service._update_thread_event.set()\n\n    @staticmethod\n    def get_event_manager():\n        \"\"\"\n        Returns an instance of an event timer manager\n        \"\"\"\n        return unreal.DeadlineServiceTimerManager()\n\n    @staticmethod\n    def start_function_timer(event_manager, function, interval_in_seconds=2.0):\n        \"\"\"\n        Start a timer on a function within an interval\n        :param unreal.DeadlineServiceTimerManager event_manager: Unreal Deadline service timer manager\n        :param object function: Function to execute\n        :param float interval_in_seconds: Interval in seconds between function execution. Default is 2.0 seconds\n        :return: Event timer handle\n        \"\"\"\n        if not isinstance(event_manager, unreal.DeadlineServiceTimerManager):\n            raise TypeError(\n                f\"The event manager is not of type `unreal.DeadlineServiceTimerManager`. Got {type(event_manager)}\"\n            )\n\n        event_manager.on_timer_interval_delegate.add_callable(function)\n\n        return event_manager.start_timer(interval_in_seconds)\n\n    @staticmethod\n    def stop_function_timer(event_manager, time_handle):\n        \"\"\"\n        Stops the timer event\n        :param unreal.DeadlineServiceTimerManager event_manager: Service Event manager\n        :param time_handle: Time handle returned from the event manager\n        \"\"\"\n        event_manager.stop_timer(time_handle)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.completed_jobs","title":"<code>completed_jobs</code>  <code>property</code>","text":"<p>Returns the completed jobs tracked by the service :return: List of completed Jobs tracked by the service</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.current_jobs","title":"<code>current_jobs</code>  <code>property</code>","text":"<p>Returns the global current jobs tracked by the service :return: List of Jobs tracked by the service</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.failed_jobs","title":"<code>failed_jobs</code>  <code>property</code>","text":"<p>Returns the failed jobs tracked by the service :return: List of failed Jobs tracked by the service</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.groups","title":"<code>groups</code>  <code>property</code>","text":"<p>Returns the current list of groups found on the server :return: List of groups  on the server</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.host","title":"<code>host</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the server url used by the service :return: Service url</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.pools","title":"<code>pools</code>  <code>property</code>","text":"<p>Returns the current list of pools found on the server :return: List of pools on the server</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.use_deadline_command","title":"<code>use_deadline_command</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the current value of the use deadline command flag :return: True if the service uses the deadline command, False otherwise</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.__init__","title":"<code>__init__(host=None, auto_start_job_updates=False, service_update_interval=1.0)</code>","text":"<p>Deadline service class for submitting jobs to deadline and querying data from deadline :param str host: Deadline host :param bool auto_start_job_updates: This flag auto starts processing jobs when the service is initialized     tracked by the service :param float service_update_interval: Interval(seconds) for job update frequency. Default is 2.0 seconds</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def __init__(self, host=None, auto_start_job_updates=False, service_update_interval=1.0):\n    \"\"\"\n    Deadline service class for submitting jobs to deadline and querying data from deadline\n    :param str host: Deadline host\n    :param bool auto_start_job_updates: This flag auto starts processing jobs when the service is initialized\n        tracked by the service\n    :param float service_update_interval: Interval(seconds) for job update frequency. Default is 2.0 seconds\n    \"\"\"\n\n    # Track a dictionary of jobs registered with the service. This dictionary contains job object instance ID and a\n    # reference to the job instance object and deadline job ID.\n    # i.e {\"instance_object_id\": {\"object\": &lt;job class instance&gt;, \"job_id\": 0001 or None}}\n    self._current_jobs = {}\n    self._submitted_jobs = {} # Similar to the current jobs, this tracks all jobs submitted\n    self._failed_jobs = set()\n    self._completed_jobs = set()\n\n    # This flag determines if the service should deregister a job when it fails on the server\n    self.deregister_job_on_failure = True\n\n    # Thread execution variables\n    self._event_thread = None\n    self._exit_auto_update = False\n    self._update_thread_event = Event()\n\n    self._service_update_interval = service_update_interval\n\n    # A timer for executing job update functions on an interval\n    self._event_timer_manager = self.get_event_manager()\n    self._event_handler = None\n\n    # Use DeadlineCommand by defaut\n    self._use_deadline_command = self._get_use_deadline_cmd() # True  # TODO: hardcoded for testing, change to project read setting\n\n    # Get/Set service host\n    self._host = host or self._get_deadline_host()\n\n    # Get deadline https instance\n    self._http_server = DeadlineHttp(self.host)\n\n    if auto_start_job_updates:\n        self.start_job_updates()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.change_job_state","title":"<code>change_job_state(job_object, state)</code>","text":"<p>This modifies a submitted job's state on the Deadline server. This can be used in job orchestration. For example a job can be submitted as suspended/pending and this command can be used to update the state of the job to active after submission. :param DeadlineJob job_object: Deadline job object :param DeadlineJobState state: State to set the job :return: Submission results</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def change_job_state(self, job_object, state):\n    \"\"\"\n    This modifies a submitted job's state on the Deadline server. This can be used in job orchestration. For example\n    a job can be submitted as suspended/pending and this command can be used to update the state of the job to\n    active after submission.\n    :param DeadlineJob job_object: Deadline job object\n    :param DeadlineJobState state: State to set the job\n    :return: Submission results\n    \"\"\"\n\n    self._validate_job_object(job_object)\n\n    # Validate jobs state\n    if not isinstance(state, DeadlineJobState):\n        raise ValueError(f\"`{state}` is not a valid state.\")\n\n    return self.send_job_command(job_object, {\"Command\": state.value})\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.get_event_manager","title":"<code>get_event_manager()</code>  <code>staticmethod</code>","text":"<p>Returns an instance of an event timer manager</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>@staticmethod\ndef get_event_manager():\n    \"\"\"\n    Returns an instance of an event timer manager\n    \"\"\"\n    return unreal.DeadlineServiceTimerManager()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.get_job_details","title":"<code>get_job_details(job_object)</code>","text":"<p>This method gets the job details for the Deadline job :param DeadlineJob job_object: Custom Deadline job object :return: Job details object returned from the server. Usually a Json object</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def get_job_details(self, job_object):\n    \"\"\"\n    This method gets the job details for the Deadline job\n    :param DeadlineJob job_object: Custom Deadline job object\n    :return: Job details object returned from the server. Usually a Json object\n    \"\"\"\n\n    self._validate_job_object(job_object)\n\n    if str(id(job_object)) not in self._current_jobs:\n        logger.warning(\n            f\"{job_object} is currently not tracked by the service. The job has either not been submitted, \"\n            f\"its already completed or there was a problem with the job!\"\n        )\n    elif not job_object.job_id:\n        logger.error(\n            f\"There is no JobID for {job_object}!\"\n        )\n    else:\n\n        try:\n            job_details = self._http_server.get_job_details(job_object.job_id)\n\n        except (Exception, RuntimeError):\n            # If an error occurred, most likely the job does not exist on the server anymore. Mark the job as\n            # unknown\n            self._update_tracked_job_by_status(job_object, DeadlineJobStatus.UNKNOWN, update_job=True)\n        else:\n            # Sometimes Deadline returns a status with a parenthesis after the status indicating the number of tasks\n            # executing. We only care about the status here so lets split the number of tasks out.\n            self._update_tracked_job_by_status(job_object, job_details[\"Job\"][\"Status\"].split()[0])\n            return job_details\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.get_job_object_by_job_id","title":"<code>get_job_object_by_job_id(job_id)</code>","text":"<p>This method returns the job object tracked by the service based on the deadline job ID :param job_id: Deadline job ID :return: DeadlineJob object :rtype DeadlineJob</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def get_job_object_by_job_id(self, job_id):\n    \"\"\"\n    This method returns the job object tracked by the service based on the deadline job ID\n    :param job_id: Deadline job ID\n    :return: DeadlineJob object\n    :rtype DeadlineJob\n    \"\"\"\n\n    job_object = None\n\n    for job in self._submitted_jobs.values():\n        if job_id == job[\"job_id\"]:\n            job_object = job[\"object\"]\n            break\n\n    return job_object\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.send_http_request","title":"<code>send_http_request(request_type, api_url, payload=None, fields=None, headers=None, retries=0)</code>","text":"<p>This method is used to upload or receive data from the Deadline server. :param HttpRequestType request_type: HTTP request verb. i.e GET/POST/PUT/DELETE :param str api_url: URL relative path queries. Example: /jobs , /pools, /jobs?JobID=0000 :param payload: Data object to POST/PUT to Deadline server :param dict fields: Request fields. This is typically used in files and binary uploads :param dict headers: Header data for request :param int retries: The number of retries to attempt before failing request. Defaults to 0. :return: JSON object response from the server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def send_http_request(self, request_type, api_url, payload=None, fields=None, headers=None, retries=0):\n    \"\"\"\n    This method is used to upload or receive data from the Deadline server.\n    :param HttpRequestType request_type: HTTP request verb. i.e GET/POST/PUT/DELETE\n    :param str api_url: URL relative path queries. Example: /jobs , /pools, /jobs?JobID=0000\n    :param payload: Data object to POST/PUT to Deadline server\n    :param dict fields: Request fields. This is typically used in files and binary uploads\n    :param dict headers: Header data for request\n    :param int retries: The number of retries to attempt before failing request. Defaults to 0.\n    :return: JSON object response from the server\n    \"\"\"\n\n    # Make sure we always have the most up-to-date host\n    if not self.host or (self.host != self._get_deadline_host()):\n        self.host = self._get_deadline_host()\n\n    try:\n        response = self._http_server.send_http_request(\n            request_type,\n            api_url,\n            payload=payload,\n            fields=fields,\n            headers=headers,\n            retries=retries\n        )\n\n    except Exception as err:\n        raise DeadlineServiceError(f\"Communication with {self.host} failed with err: \\n{err}\")\n    else:\n        return response\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.send_job_command","title":"<code>send_job_command(job_object, command)</code>","text":"<p>Send a command to the Deadline server for the job :param DeadlineJob job_object: Deadline job object :param dict command: Command to send to the Deadline server :return: Returns the response from the server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def send_job_command(self, job_object, command):\n    \"\"\"\n    Send a command to the Deadline server for the job\n    :param DeadlineJob job_object: Deadline job object\n    :param dict command: Command to send to the Deadline server\n    :return: Returns the response from the server\n    \"\"\"\n    self._validate_job_object(job_object)\n\n    if not job_object.job_id:\n        raise RuntimeError(\"There is no Deadline job ID to send this command for.\")\n\n    try:\n        response = self._http_server.send_job_command(\n            job_object.job_id,\n            command\n        )\n    except Exception as exp:\n        logger.error(\n            f\"An error occurred getting the command result for {job_object} from Deadline host {self.host}. \"\n            f\"\\n{exp}\"\n        )\n        return \"Fail\"\n    else:\n        if response != \"Success\":\n            logger.error(f\"An error occurred executing command for {job_object}. \\nError: {response}\")\n            return \"Fail\"\n\n        return response\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.start_function_timer","title":"<code>start_function_timer(event_manager, function, interval_in_seconds=2.0)</code>  <code>staticmethod</code>","text":"<p>Start a timer on a function within an interval :param unreal.DeadlineServiceTimerManager event_manager: Unreal Deadline service timer manager :param object function: Function to execute :param float interval_in_seconds: Interval in seconds between function execution. Default is 2.0 seconds :return: Event timer handle</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>@staticmethod\ndef start_function_timer(event_manager, function, interval_in_seconds=2.0):\n    \"\"\"\n    Start a timer on a function within an interval\n    :param unreal.DeadlineServiceTimerManager event_manager: Unreal Deadline service timer manager\n    :param object function: Function to execute\n    :param float interval_in_seconds: Interval in seconds between function execution. Default is 2.0 seconds\n    :return: Event timer handle\n    \"\"\"\n    if not isinstance(event_manager, unreal.DeadlineServiceTimerManager):\n        raise TypeError(\n            f\"The event manager is not of type `unreal.DeadlineServiceTimerManager`. Got {type(event_manager)}\"\n        )\n\n    event_manager.on_timer_interval_delegate.add_callable(function)\n\n    return event_manager.start_timer(interval_in_seconds)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.start_job_updates","title":"<code>start_job_updates()</code>","text":"<p>This method starts an auto update on jobs in the service.</p> <p>The purpose of this system is to allow the service to automatically update the job details from the server. This allows you to submit a job from your implementation and periodically poll the changes on the job as the service will continuously update the job details. Note: This function must explicitly be called or the <code>auto_start_job_updates</code> flag must be passed to the service instance for this functionality to happen.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def start_job_updates(self):\n    \"\"\"\n    This method starts an auto update on jobs in the service.\n\n    The purpose of this system is to allow the service to automatically update the job details from the server.\n    This allows you to submit a job from your implementation and periodically poll the changes on the job as the\n    service will continuously update the job details.\n    Note: This function must explicitly be called or the `auto_start_job_updates` flag must be passed to the service\n    instance for this functionality to happen.\n    \"\"\"\n    # Prevent the event from being executed several times in succession\n    if not self._event_handler:\n        if not self._event_thread:\n\n            # Create a thread for the job update function. This function takes the current list of jobs\n            # tracked by the service. The Thread owns an instance of the http connection. This allows the thread\n            # to have its own pool of http connections separate from the main service. A thread event is passed\n            # into the thread which allows the process events from the timer to reactivate the function. The\n            # purpose of this is to prevent unnecessary re-execution while jobs are being processed.\n            # This also allows the main service to stop function execution within the thread and allow it to cleanly\n            # exit.\n\n            # HACK: For some odd reason, passing an instance of the service into the thread seems to work as\n            # opposed to passing in explicit variables. I would prefer explicit variables as the thread does not\n            # need to have access to the entire service object\n\n            # Threading is used here as the editor runs python on the game thread. If a function call is\n            # executed on an interval (as this part of the service is designed to do), this will halt the editor\n            # every n interval to process the update event. A separate thread for processing events allows the\n            # editor to continue functions without interfering with the editor\n\n            # TODO: Figure out a way to have updated variables in the thread vs passing the whole service instance\n            self._event_thread = Thread(\n                target=self._update_all_jobs,\n                args=(self,),\n                name=\"deadline_service_auto_update_thread\",\n                daemon=True\n            )\n\n            # Start the thread\n            self._event_thread.start()\n\n        else:\n            # If the thread is stopped, restart it.\n            if not self._event_thread.is_alive():\n                self._event_thread.start()\n\n        def process_events():\n            \"\"\"\n            Function ran by the tick event for monitoring function execution inside of the auto update thread.\n            \"\"\"\n            # Since the editor ticks at a high rate, this monitors the current state of the function execution in\n            # the update thread. When a function is done executing, this resets the event on the function.\n            logger.debug(\"Processing current jobs.\")\n            if self._update_thread_event.is_set():\n\n                logger.debug(\"Job processing complete, restarting..\")\n                # Send an event to tell the thread to start the job processing loop\n                self._update_thread_event.clear()\n\n        # Attach the thread executions to a timer event\n        self._event_timer_manager.on_timer_interval_delegate.add_callable(process_events)\n\n        # Start the timer on an interval\n        self._event_handler = self._event_timer_manager.start_timer(self._service_update_interval)\n\n        # Allow the thread to stop when a python shutdown is detected\n        unreal.register_python_shutdown_callback(self.stop_job_updates)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.stop_function_timer","title":"<code>stop_function_timer(event_manager, time_handle)</code>  <code>staticmethod</code>","text":"<p>Stops the timer event :param unreal.DeadlineServiceTimerManager event_manager: Service Event manager :param time_handle: Time handle returned from the event manager</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>@staticmethod\ndef stop_function_timer(event_manager, time_handle):\n    \"\"\"\n    Stops the timer event\n    :param unreal.DeadlineServiceTimerManager event_manager: Service Event manager\n    :param time_handle: Time handle returned from the event manager\n    \"\"\"\n    event_manager.stop_timer(time_handle)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.stop_job_updates","title":"<code>stop_job_updates()</code>","text":"<p>This method stops the auto update thread. This method should be explicitly called to stop the service from continuously updating the current tracked jobs.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def stop_job_updates(self):\n    \"\"\"\n    This method stops the auto update thread. This method should be explicitly called to stop the service from\n    continuously updating the current tracked jobs.\n    \"\"\"\n    if self._event_handler:\n\n        # Remove the event handle to the tick event\n        self.stop_function_timer(self._event_timer_manager, self._event_handler)\n        self._event_handler = None\n\n        if self._event_thread and self._event_thread.is_alive():\n            # Force stop the thread\n            self._exit_auto_update = True\n\n            # immediately stop the thread. Do not wait for jobs to complete.\n            self._event_thread.join(1.0)\n\n            # Usually if a thread is still alive after a timeout, then something went wrong\n            if self._event_thread.is_alive():\n                logger.error(\"An error occurred closing the auto update Thread!\")\n\n            # Reset the event, thread and tick handler\n            self._update_thread_event.set()\n            self._event_thread = None\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineService.submit_job","title":"<code>submit_job(job_object)</code>","text":"<p>This method submits the tracked job to the Deadline server :param DeadlineJob job_object: Deadline Job object :returns: Deadline <code>JobID</code> if an id was returned from the server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def submit_job(self, job_object):\n    \"\"\"\n    This method submits the tracked job to the Deadline server\n    :param DeadlineJob job_object: Deadline Job object\n    :returns: Deadline `JobID` if an id was returned from the server\n    \"\"\"\n    self._validate_job_object(job_object)\n\n    logger.debug(f\"Submitting {job_object} to {self.host}..\")\n\n    if str(id(job_object)) in self._current_jobs:\n        logger.warning(f\"{job_object} has already been added to the service\")\n\n        # Return the job ID of the submitted job\n        return job_object.job_id\n\n    job_id = None\n\n    job_data = job_object.get_submission_data()\n\n    # Set the job data to return the job ID on submission\n    job_data.update(IdOnly=\"true\")\n\n    # Update the job data to include the user and machine submitting the job\n    # Update the username if one is not supplied\n    if \"UserName\" not in job_data[\"JobInfo\"]:\n\n        # NOTE: Make sure this matches the expected naming convention by the server else the user will get\n        #  permission errors on job submission\n        # Todo: Make sure the username convention matches the username on the server\n        job_data[\"JobInfo\"].update(UserName=getuser())\n\n    job_data[\"JobInfo\"].update(MachineName=platform.node())\n\n    self._validate_job_info(job_data[\"JobInfo\"])\n\n    if self._get_use_deadline_cmd(): # if self._use_deadline_command:\n        # Submit the job to the Deadline server using the Deadline command\n        # Todo: Add support for the Deadline command\n        job_id = DeadlineCommand().submit_job(job_data)\n\n    else:\n        # Submit the job to the Deadline server using the HTTP API\n        try:\n            response = self.send_http_request(\n                HttpRequestType.POST,\n                \"api/jobs\",\n                payload=json.dumps(job_data).encode('utf-8'),\n                headers={'Content-Type': 'application/json'}\n            )\n\n        except DeadlineServiceError as exp:\n            logger.error(\n                f\"An error occurred submitting {job_object} to Deadline host `{self.host}`.\\n\\t{str(exp)}\"\n            )\n            self._failed_jobs.add(job_object)\n\n        else:\n            try:\n                response = json.loads(response.decode('utf-8'))\n\n            # If an error occurs trying to decode the json data, most likely an error occurred server side thereby\n            # returning a string instead of the data requested.\n            # Raise the decoded error\n            except Exception as err:\n                raise DeadlineServiceError(f\"An error occurred getting the server data:\\n\\t{response.decode('utf-8')}\")\n\n            job_id = response.get('_id', None)\n        if not job_id:\n            logger.warning(\n                f\"No JobId was returned from the server for {job_object}. \"\n                f\"The service will not be able to get job details for this job!\"\n            )\n        else:\n            # Register the job with the service.\n            self._register_job(job_object, job_id)\n\n        logger.info(f\"Submitted `{job_object.job_name}` to Deadline. JobID: {job_id}\")\n\n    return job_id\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.DeadlineServiceError","title":"<code>DeadlineServiceError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>General Exception class for the Deadline Service</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>class DeadlineServiceError(Exception):\n    \"\"\"\n    General Exception class for the Deadline Service\n    \"\"\"\n    pass\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_service.get_global_deadline_service_instance","title":"<code>get_global_deadline_service_instance()</code>","text":"<p>This method returns an instance of the service from the interpreter globals. :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_service.py</code> <pre><code>def get_global_deadline_service_instance():\n    \"\"\"\n    This method returns an instance of the service from\n    the interpreter globals.\n    :return:\n    \"\"\"\n    # This behavior is a result of unreal classes not able to store python object\n    # directly on the class due to limitations in the reflection system.\n    # The expectation is that uclass's that may not be able to store the service\n    # as a persistent attribute on a class can use the global service instance.\n\n    # BEWARE!!!!\n    # Due to the nature of the DeadlineService being a singleton, if you get the\n    # current instance and change the host path for the service, the connection will\n    # change for every other implementation that uses this service\n\n    deadline_globals = get_editor_deadline_globals()\n\n    if '__deadline_service_instance__' not in deadline_globals:\n        deadline_globals[\"__deadline_service_instance__\"] = DeadlineService()\n\n    return deadline_globals[\"__deadline_service_instance__\"]\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.html","title":"deadline_utils","text":"<p>General Deadline utility functions</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_utils.format_job_info_json_string","title":"<code>format_job_info_json_string(json_string, exclude_aux_files=False)</code>","text":"<p>Deadline Data asset returns a json string, load the string and format the job info in a dictionary :param str json_string: Json string from deadline preset struct :param bool exclude_aux_files: Excludes the aux files from the returned job info dictionary if True :return: job Info dictionary</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.py</code> <pre><code>def format_job_info_json_string(json_string, exclude_aux_files=False):\n    \"\"\"\n    Deadline Data asset returns a json string, load the string and format the job info in a dictionary\n    :param str json_string: Json string from deadline preset struct\n    :param bool exclude_aux_files: Excludes the aux files from the returned job info dictionary if True\n    :return: job Info dictionary\n    \"\"\"\n\n    if not json_string:\n        raise RuntimeError(f\"Expected json string value but got `{json_string}`\")\n\n    job_info = {}\n\n    try:\n        intermediate_info = json.loads(json_string)\n    except Exception as err:\n        raise RuntimeError(f\"An error occurred formatting the Job Info string. \\n\\t{err}\")\n\n    project_settings = unreal.get_default_object(unreal.DeadlineServiceEditorSettings)\n    script_category_mappings = project_settings.script_category_mappings\n\n    # The json string keys are camelCased keys which are not the expected input\n    # types for Deadline. Format the keys to PascalCase.\n    for key, value in intermediate_info.items():\n\n        # Remove empty values\n        if not value:\n            continue\n\n        # Deadline does not support native boolean so make it a string\n        if isinstance(value, bool):\n            value = str(value).lower()\n\n        pascal_case_key = re.sub(\"(^\\S)\", lambda string: string.group(1).upper(), key)\n\n        if (pascal_case_key == \"AuxFiles\") and not exclude_aux_files:\n\n            # The returned json string lists AuxFiles as a list of\n            # Dictionaries but the expected value is a list of\n            # strings. reformat this input into the expected value\n            aux_files = []\n            for files in value:\n                aux_files.append(files[\"filePath\"])\n\n            job_info[pascal_case_key] = aux_files\n\n            continue\n\n        # Extra option that can be set on the job info are packed inside a\n        # ExtraJobOptions key in the json string.\n        # Extract this is and add it as a flat setting in the job info\n        elif pascal_case_key == \"ExtraJobOptions\":\n            job_info.update(value)\n\n            continue\n\n        # Resolve the job script paths to be sent to be sent to the farm.\n        elif pascal_case_key in [\"PreJobScript\", \"PostJobScript\", \"PreTaskScript\", \"PostTaskScript\"]:\n\n            # The path mappings in the project settings are a dictionary\n            # type with the script category as a named path for specifying\n            # the root directory of a particular script. The User interface\n            # exposes the category which is what's in the json string. We\n            # will use this category to look up the actual path mappings in\n            # the project settings.\n            script_category = intermediate_info[key][\"scriptCategory\"]\n            script_name = intermediate_info[key][\"scriptName\"]\n            if script_category and script_name:\n                job_info[pascal_case_key] = f\"{script_category_mappings[script_category]}/{script_name}\"\n\n            continue\n\n        # Environment variables for Deadline are numbered key value pairs in\n        # the form EnvironmentKeyValue#.\n        # Conform the Env settings to the expected Deadline configuration\n        elif (pascal_case_key == \"EnvironmentKeyValue\") and value:\n\n            for index, (env_key, env_value) in enumerate(value.items()):\n                job_info[f\"EnvironmentKeyValue{index}\"] = f\"{env_key}={env_value}\"\n\n            continue\n\n        # ExtraInfoKeyValue for Deadline are numbered key value pairs in the\n        # form ExtraInfoKeyValue#.\n        # Conform the setting to the expected Deadline configuration\n        elif (pascal_case_key == \"ExtraInfoKeyValue\") and value:\n\n            for index, (env_key, env_value) in enumerate(value.items()):\n                job_info[f\"ExtraInfoKeyValue{index}\"] = f\"{env_key}={env_value}\"\n\n            continue\n\n        else:\n            # Set the rest of the functions\n            job_info[pascal_case_key] = value\n\n    # Remove our custom representation of Environment and ExtraInfo Key value\n    # pairs from the dictionary as the expectation is that these have been\n    # conformed to deadline's expected key value representation\n    for key in [\"EnvironmentKeyValue\", \"ExtraInfoKeyValue\"]:\n        job_info.pop(key, None)\n\n    return job_info\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_utils.format_plugin_info_json_string","title":"<code>format_plugin_info_json_string(json_string)</code>","text":"<p>Deadline Data asset returns a json string, load the string and format the plugin info in a dictionary :param str json_string: Json string from deadline preset struct :return: job Info dictionary</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.py</code> <pre><code>def format_plugin_info_json_string(json_string):\n    \"\"\"\n    Deadline Data asset returns a json string, load the string and format the plugin info in a dictionary\n    :param str json_string: Json string from deadline preset struct\n    :return: job Info dictionary\n    \"\"\"\n\n    if not json_string:\n        raise RuntimeError(f\"Expected json string value but got `{json_string}`\")\n\n    plugin_info = {}\n\n    try:\n        info = json.loads(json_string)\n        plugin_info = info[\"pluginInfo\"]\n\n    except Exception as err:\n        raise RuntimeError(f\"An error occurred formatting the Plugin Info string. \\n\\t{err}\")\n\n    # The plugin info is listed under the `plugin_info` key.\n    # The json string keys are camelCased on struct conversion to json.\n    return plugin_info\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_utils.get_deadline_info_from_preset","title":"<code>get_deadline_info_from_preset(job_preset=None, job_preset_struct=None)</code>","text":"<p>This method returns the job info and plugin info from a deadline preset :param unreal.DeadlineJobPreset job_preset:  Deadline preset asset :param unreal.DeadlineJobPresetStruct job_preset_struct: The job info and plugin info in the job preset :return: Returns a tuple with the job info and plugin info dictionary :rtype: Tuple</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.py</code> <pre><code>def get_deadline_info_from_preset(job_preset=None, job_preset_struct=None):\n    \"\"\"\n    This method returns the job info and plugin info from a deadline preset\n    :param unreal.DeadlineJobPreset job_preset:  Deadline preset asset\n    :param unreal.DeadlineJobPresetStruct job_preset_struct: The job info and plugin info in the job preset\n    :return: Returns a tuple with the job info and plugin info dictionary\n    :rtype: Tuple\n    \"\"\"\n\n    job_info = {}\n    plugin_info = {}\n    preset_struct = None\n\n    # TODO: Make sure the preset library is a loaded asset\n    if job_preset is not None:\n        preset_struct = job_preset.job_preset_struct\n\n    if job_preset_struct is not None:\n        preset_struct = job_preset_struct\n\n    if preset_struct:\n        # Get the Job Info and plugin Info\n        try:\n            job_info = dict(unreal.DeadlineServiceEditorHelpers.get_deadline_job_info(preset_struct))\n\n            plugin_info = dict(unreal.DeadlineServiceEditorHelpers.get_deadline_plugin_info(preset_struct))\n\n        # Fail the submission if any errors occur\n        except Exception as err:\n            unreal.log_error(\n                f\"Error occurred getting deadline job and plugin details. \\n\\tError: {err}\"\n            )\n            raise\n\n    return job_info, plugin_info\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_utils.get_editor_deadline_globals","title":"<code>get_editor_deadline_globals()</code>","text":"<p>Get global storage that will persist for the duration of the current interpreter/process.</p> <p>.. tip::</p> <pre><code>Please namespace or otherwise ensure unique naming of any data stored\ninto this dictionary, as key clashes are not handled/safety checked.\n</code></pre> <p>:return: Global storage :rtype: dict</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.py</code> <pre><code>def get_editor_deadline_globals():\n    \"\"\"\n    Get global storage that will persist for the duration of the\n    current interpreter/process.\n\n    .. tip::\n\n        Please namespace or otherwise ensure unique naming of any data stored\n        into this dictionary, as key clashes are not handled/safety checked.\n\n    :return: Global storage\n    :rtype: dict\n    \"\"\"\n    import __main__\n    try:\n        return __main__.__editor_deadline_globals__\n    except AttributeError:\n        __main__.__editor_deadline_globals__ = {}\n        return __main__.__editor_deadline_globals__\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_utils.merge_dictionaries","title":"<code>merge_dictionaries(first_dictionary, second_dictionary)</code>","text":"<p>This method merges two dictionaries and returns a new dictionary as a merger between the two :param dict first_dictionary: The first dictionary :param dict second_dictionary: The new dictionary to merge in :return: A new dictionary based on a merger of the input dictionaries :rtype: dict</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_utils.py</code> <pre><code>def merge_dictionaries(first_dictionary, second_dictionary):\n    \"\"\"\n    This method merges two dictionaries and returns a new dictionary as a merger between the two\n    :param dict first_dictionary: The first dictionary\n    :param dict second_dictionary: The new dictionary to merge in\n    :return: A new dictionary based on a merger of the input dictionaries\n    :rtype: dict\n    \"\"\"\n    # Make sure we do not overwrite our input dictionary\n    output_dictionary = deepcopy(first_dictionary)\n\n    for key in second_dictionary:\n        if isinstance(second_dictionary[key], dict):\n            if key not in output_dictionary:\n                output_dictionary[key] = {}\n            output_dictionary[key] = merge_dictionaries(output_dictionary[key], second_dictionary[key])\n        else:\n            output_dictionary[key] = second_dictionary[key]\n\n    return output_dictionary\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/init_unreal.html","title":"init_unreal","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/index.html","title":"deadline_menus","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.DeadlineToolBarMenu","title":"<code>DeadlineToolBarMenu</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for Deadline Unreal Toolbar menu</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.py</code> <pre><code>class DeadlineToolBarMenu(object):\n    \"\"\"\n    Class for Deadline Unreal Toolbar menu\n    \"\"\"\n\n    TOOLBAR_NAME = \"Deadline\"\n    TOOLBAR_OWNER = \"deadline.toolbar.menu\"\n    PARENT_MENU = \"LevelEditor.MainMenu\"\n    SECTION_NAME = \"deadline_section\"\n\n    def __init__(self):\n        \"\"\"Constructor\"\"\"\n\n        # Keep reference to tool menus from Unreal\n        self._tool_menus = None\n\n        # Keep track of all the action menus that have been registered to\n        # Unreal. Without keeping these around, the Unreal GC will remove the\n        # menu objects and break the in-engine menu\n        self.menu_entries = []\n\n        self._top_level_menu = f\"{self.PARENT_MENU}.{self.TOOLBAR_NAME}\"\n\n        self._initialize_toolbar()\n\n        # Set up a shutdown callback for when python is existing to cleanly\n        # clear the menus\n        unreal.register_python_shutdown_callback(self._shutdown)\n\n    @property\n    def _unreal_tools_menu(self):\n        \"\"\"Get Unreal Editor Tool menu\"\"\"\n        if not self._tool_menus or self._tool_menus is None:\n            self._tool_menus = unreal.ToolMenus.get()\n\n        return self._tool_menus\n\n    def _initialize_toolbar(self):\n        \"\"\"Initialize our custom toolbar with the Editor\"\"\"\n\n        tools_menu = self._unreal_tools_menu\n\n        # Create the custom menu and add it to Unreal Main Menu\n        main_menu = tools_menu.extend_menu(self.PARENT_MENU)\n\n        # Create the submenu object\n        main_menu.add_sub_menu(\n            self.TOOLBAR_OWNER,\n            \"\",\n            self.TOOLBAR_NAME,\n            self.TOOLBAR_NAME\n        )\n\n        # Register the custom deadline menu to the Editor Main Menu\n        tools_menu.register_menu(\n            self._top_level_menu,\n            \"\",\n            unreal.MultiBoxType.MENU,\n            False\n        )\n\n    def _shutdown(self):\n        \"\"\"Method to call when the editor is shutting down\"\"\"\n\n        # Unregister all menus owned by the integration\n        self._tool_menus.unregister_owner_by_name(self.TOOLBAR_OWNER)\n\n        # Clean up all the menu instances we are tracking\n        del self.menu_entries[:]\n\n    def register_submenu(\n        self,\n        menu_name,\n        callable_method,\n        label_name=None,\n        description=None\n    ):\n        \"\"\"\n        Register a menu to the toolbar.\n        Note: This currently creates a flat submenu in the Main Menu\n\n        :param str menu_name: The name of the submenu\n        :param object callable_method: A callable method to execute on menu\n            activation\n        :param str label_name: Nice Label name to display the menu\n        :param str description: Description of the menu. This will eb\n                displayed in the tooltip\n        \"\"\"\n\n        # Get an instance of a custom `unreal.ToolMenuEntryScript` class\n        # Wrap it in a try except block for instances where\n        # the unreal module has not loaded yet.\n\n        try:\n            entry = BaseActionMenuEntry(\n                callable_method,\n                parent=self\n            )\n            menu_entry_name = menu_name.replace(\" \", \"\")\n\n            entry.init_entry(\n                self.TOOLBAR_OWNER,\n                f\"{self._top_level_menu}.{menu_entry_name}\",\n                menu_entry_name,\n                label_name or menu_name,\n                tool_tip=description or \"\"\n            )\n\n            # Add the entry to our tracked list\n            self.menu_entries.append(entry)\n\n            # Get the registered top level menu\n            menu = self._tool_menus.find_menu(self._top_level_menu)\n\n            # Add the entry object to the menu\n            menu.add_menu_entry_object(entry)\n\n        except Exception as err:\n            raise RuntimeError(\n                \"Its possible unreal hasn't loaded yet. Here's the \"\n                \"error that occurred: {err}\".format(err=err)\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.DeadlineToolBarMenu.__init__","title":"<code>__init__()</code>","text":"<p>Constructor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.py</code> <pre><code>def __init__(self):\n    \"\"\"Constructor\"\"\"\n\n    # Keep reference to tool menus from Unreal\n    self._tool_menus = None\n\n    # Keep track of all the action menus that have been registered to\n    # Unreal. Without keeping these around, the Unreal GC will remove the\n    # menu objects and break the in-engine menu\n    self.menu_entries = []\n\n    self._top_level_menu = f\"{self.PARENT_MENU}.{self.TOOLBAR_NAME}\"\n\n    self._initialize_toolbar()\n\n    # Set up a shutdown callback for when python is existing to cleanly\n    # clear the menus\n    unreal.register_python_shutdown_callback(self._shutdown)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.DeadlineToolBarMenu.register_submenu","title":"<code>register_submenu(menu_name, callable_method, label_name=None, description=None)</code>","text":"<p>Register a menu to the toolbar. Note: This currently creates a flat submenu in the Main Menu</p> <p>:param str menu_name: The name of the submenu :param object callable_method: A callable method to execute on menu     activation :param str label_name: Nice Label name to display the menu :param str description: Description of the menu. This will eb         displayed in the tooltip</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.py</code> <pre><code>def register_submenu(\n    self,\n    menu_name,\n    callable_method,\n    label_name=None,\n    description=None\n):\n    \"\"\"\n    Register a menu to the toolbar.\n    Note: This currently creates a flat submenu in the Main Menu\n\n    :param str menu_name: The name of the submenu\n    :param object callable_method: A callable method to execute on menu\n        activation\n    :param str label_name: Nice Label name to display the menu\n    :param str description: Description of the menu. This will eb\n            displayed in the tooltip\n    \"\"\"\n\n    # Get an instance of a custom `unreal.ToolMenuEntryScript` class\n    # Wrap it in a try except block for instances where\n    # the unreal module has not loaded yet.\n\n    try:\n        entry = BaseActionMenuEntry(\n            callable_method,\n            parent=self\n        )\n        menu_entry_name = menu_name.replace(\" \", \"\")\n\n        entry.init_entry(\n            self.TOOLBAR_OWNER,\n            f\"{self._top_level_menu}.{menu_entry_name}\",\n            menu_entry_name,\n            label_name or menu_name,\n            tool_tip=description or \"\"\n        )\n\n        # Add the entry to our tracked list\n        self.menu_entries.append(entry)\n\n        # Get the registered top level menu\n        menu = self._tool_menus.find_menu(self._top_level_menu)\n\n        # Add the entry object to the menu\n        menu.add_menu_entry_object(entry)\n\n    except Exception as err:\n        raise RuntimeError(\n            \"Its possible unreal hasn't loaded yet. Here's the \"\n            \"error that occurred: {err}\".format(err=err)\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.html","title":"base_menu_action","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.base_menu_action.BaseActionMenuEntry","title":"<code>BaseActionMenuEntry</code>","text":"<p>               Bases: <code>ToolMenuEntryScript</code></p> <p>This is a custom Unreal Class that adds executable python menus to the Editor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.py</code> <pre><code>@unreal.uclass()\nclass BaseActionMenuEntry(unreal.ToolMenuEntryScript):\n    \"\"\"\n    This is a custom Unreal Class that adds executable python menus to the\n    Editor\n    \"\"\"\n\n    def __init__(self, callable_method, parent=None):\n        \"\"\"\n        Constructor\n        :param callable_method:  Callable method to execute\n        \"\"\"\n        super(BaseActionMenuEntry, self).__init__()\n\n        self._callable = callable_method\n        self.parent = parent\n\n    @unreal.ufunction(override=True)\n    def execute(self, context):\n        \"\"\"\n        Executes the callable method\n        :param context:\n        :return:\n        \"\"\"\n        self._callable()\n\n    @unreal.ufunction(override=True)\n    def can_execute(self, context):\n        \"\"\"\n        Determines if a menu can be executed\n        :param context:\n        :return:\n        \"\"\"\n        return True\n\n    @unreal.ufunction(override=True)\n    def get_tool_tip(self, context):\n        \"\"\"\n        Returns the tool tip for the menu\n        :param context:\n        :return:\n        \"\"\"\n        return self.data.tool_tip\n\n    @unreal.ufunction(override=True)\n    def get_label(self, context):\n        \"\"\"\n        Returns the label of the menu\n        :param context:\n        :return:\n        \"\"\"\n        return self.data.name\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.base_menu_action.BaseActionMenuEntry.__init__","title":"<code>__init__(callable_method, parent=None)</code>","text":"<p>Constructor :param callable_method:  Callable method to execute</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.py</code> <pre><code>def __init__(self, callable_method, parent=None):\n    \"\"\"\n    Constructor\n    :param callable_method:  Callable method to execute\n    \"\"\"\n    super(BaseActionMenuEntry, self).__init__()\n\n    self._callable = callable_method\n    self.parent = parent\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.base_menu_action.BaseActionMenuEntry.can_execute","title":"<code>can_execute(context)</code>","text":"<p>Determines if a menu can be executed :param context: :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.py</code> <pre><code>@unreal.ufunction(override=True)\ndef can_execute(self, context):\n    \"\"\"\n    Determines if a menu can be executed\n    :param context:\n    :return:\n    \"\"\"\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.base_menu_action.BaseActionMenuEntry.execute","title":"<code>execute(context)</code>","text":"<p>Executes the callable method :param context: :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.py</code> <pre><code>@unreal.ufunction(override=True)\ndef execute(self, context):\n    \"\"\"\n    Executes the callable method\n    :param context:\n    :return:\n    \"\"\"\n    self._callable()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.base_menu_action.BaseActionMenuEntry.get_label","title":"<code>get_label(context)</code>","text":"<p>Returns the label of the menu :param context: :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.py</code> <pre><code>@unreal.ufunction(override=True)\ndef get_label(self, context):\n    \"\"\"\n    Returns the label of the menu\n    :param context:\n    :return:\n    \"\"\"\n    return self.data.name\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.base_menu_action.BaseActionMenuEntry.get_tool_tip","title":"<code>get_tool_tip(context)</code>","text":"<p>Returns the tool tip for the menu :param context: :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/base_menu_action.py</code> <pre><code>@unreal.ufunction(override=True)\ndef get_tool_tip(self, context):\n    \"\"\"\n    Returns the tool tip for the menu\n    :param context:\n    :return:\n    \"\"\"\n    return self.data.tool_tip\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.html","title":"deadline_toolbar_menu","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.deadline_toolbar_menu.DeadlineToolBarMenu","title":"<code>DeadlineToolBarMenu</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for Deadline Unreal Toolbar menu</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.py</code> <pre><code>class DeadlineToolBarMenu(object):\n    \"\"\"\n    Class for Deadline Unreal Toolbar menu\n    \"\"\"\n\n    TOOLBAR_NAME = \"Deadline\"\n    TOOLBAR_OWNER = \"deadline.toolbar.menu\"\n    PARENT_MENU = \"LevelEditor.MainMenu\"\n    SECTION_NAME = \"deadline_section\"\n\n    def __init__(self):\n        \"\"\"Constructor\"\"\"\n\n        # Keep reference to tool menus from Unreal\n        self._tool_menus = None\n\n        # Keep track of all the action menus that have been registered to\n        # Unreal. Without keeping these around, the Unreal GC will remove the\n        # menu objects and break the in-engine menu\n        self.menu_entries = []\n\n        self._top_level_menu = f\"{self.PARENT_MENU}.{self.TOOLBAR_NAME}\"\n\n        self._initialize_toolbar()\n\n        # Set up a shutdown callback for when python is existing to cleanly\n        # clear the menus\n        unreal.register_python_shutdown_callback(self._shutdown)\n\n    @property\n    def _unreal_tools_menu(self):\n        \"\"\"Get Unreal Editor Tool menu\"\"\"\n        if not self._tool_menus or self._tool_menus is None:\n            self._tool_menus = unreal.ToolMenus.get()\n\n        return self._tool_menus\n\n    def _initialize_toolbar(self):\n        \"\"\"Initialize our custom toolbar with the Editor\"\"\"\n\n        tools_menu = self._unreal_tools_menu\n\n        # Create the custom menu and add it to Unreal Main Menu\n        main_menu = tools_menu.extend_menu(self.PARENT_MENU)\n\n        # Create the submenu object\n        main_menu.add_sub_menu(\n            self.TOOLBAR_OWNER,\n            \"\",\n            self.TOOLBAR_NAME,\n            self.TOOLBAR_NAME\n        )\n\n        # Register the custom deadline menu to the Editor Main Menu\n        tools_menu.register_menu(\n            self._top_level_menu,\n            \"\",\n            unreal.MultiBoxType.MENU,\n            False\n        )\n\n    def _shutdown(self):\n        \"\"\"Method to call when the editor is shutting down\"\"\"\n\n        # Unregister all menus owned by the integration\n        self._tool_menus.unregister_owner_by_name(self.TOOLBAR_OWNER)\n\n        # Clean up all the menu instances we are tracking\n        del self.menu_entries[:]\n\n    def register_submenu(\n        self,\n        menu_name,\n        callable_method,\n        label_name=None,\n        description=None\n    ):\n        \"\"\"\n        Register a menu to the toolbar.\n        Note: This currently creates a flat submenu in the Main Menu\n\n        :param str menu_name: The name of the submenu\n        :param object callable_method: A callable method to execute on menu\n            activation\n        :param str label_name: Nice Label name to display the menu\n        :param str description: Description of the menu. This will eb\n                displayed in the tooltip\n        \"\"\"\n\n        # Get an instance of a custom `unreal.ToolMenuEntryScript` class\n        # Wrap it in a try except block for instances where\n        # the unreal module has not loaded yet.\n\n        try:\n            entry = BaseActionMenuEntry(\n                callable_method,\n                parent=self\n            )\n            menu_entry_name = menu_name.replace(\" \", \"\")\n\n            entry.init_entry(\n                self.TOOLBAR_OWNER,\n                f\"{self._top_level_menu}.{menu_entry_name}\",\n                menu_entry_name,\n                label_name or menu_name,\n                tool_tip=description or \"\"\n            )\n\n            # Add the entry to our tracked list\n            self.menu_entries.append(entry)\n\n            # Get the registered top level menu\n            menu = self._tool_menus.find_menu(self._top_level_menu)\n\n            # Add the entry object to the menu\n            menu.add_menu_entry_object(entry)\n\n        except Exception as err:\n            raise RuntimeError(\n                \"Its possible unreal hasn't loaded yet. Here's the \"\n                \"error that occurred: {err}\".format(err=err)\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.deadline_toolbar_menu.DeadlineToolBarMenu.__init__","title":"<code>__init__()</code>","text":"<p>Constructor</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.py</code> <pre><code>def __init__(self):\n    \"\"\"Constructor\"\"\"\n\n    # Keep reference to tool menus from Unreal\n    self._tool_menus = None\n\n    # Keep track of all the action menus that have been registered to\n    # Unreal. Without keeping these around, the Unreal GC will remove the\n    # menu objects and break the in-engine menu\n    self.menu_entries = []\n\n    self._top_level_menu = f\"{self.PARENT_MENU}.{self.TOOLBAR_NAME}\"\n\n    self._initialize_toolbar()\n\n    # Set up a shutdown callback for when python is existing to cleanly\n    # clear the menus\n    unreal.register_python_shutdown_callback(self._shutdown)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_menus.deadline_toolbar_menu.DeadlineToolBarMenu.register_submenu","title":"<code>register_submenu(menu_name, callable_method, label_name=None, description=None)</code>","text":"<p>Register a menu to the toolbar. Note: This currently creates a flat submenu in the Main Menu</p> <p>:param str menu_name: The name of the submenu :param object callable_method: A callable method to execute on menu     activation :param str label_name: Nice Label name to display the menu :param str description: Description of the menu. This will eb         displayed in the tooltip</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_menus/deadline_toolbar_menu.py</code> <pre><code>def register_submenu(\n    self,\n    menu_name,\n    callable_method,\n    label_name=None,\n    description=None\n):\n    \"\"\"\n    Register a menu to the toolbar.\n    Note: This currently creates a flat submenu in the Main Menu\n\n    :param str menu_name: The name of the submenu\n    :param object callable_method: A callable method to execute on menu\n        activation\n    :param str label_name: Nice Label name to display the menu\n    :param str description: Description of the menu. This will eb\n            displayed in the tooltip\n    \"\"\"\n\n    # Get an instance of a custom `unreal.ToolMenuEntryScript` class\n    # Wrap it in a try except block for instances where\n    # the unreal module has not loaded yet.\n\n    try:\n        entry = BaseActionMenuEntry(\n            callable_method,\n            parent=self\n        )\n        menu_entry_name = menu_name.replace(\" \", \"\")\n\n        entry.init_entry(\n            self.TOOLBAR_OWNER,\n            f\"{self._top_level_menu}.{menu_entry_name}\",\n            menu_entry_name,\n            label_name or menu_name,\n            tool_tip=description or \"\"\n        )\n\n        # Add the entry to our tracked list\n        self.menu_entries.append(entry)\n\n        # Get the registered top level menu\n        menu = self._tool_menus.find_menu(self._top_level_menu)\n\n        # Add the entry object to the menu\n        menu.add_menu_entry_object(entry)\n\n    except Exception as err:\n        raise RuntimeError(\n            \"Its possible unreal hasn't loaded yet. Here's the \"\n            \"error that occurred: {err}\".format(err=err)\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/index.html","title":"deadline_rpc","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.BaseRPC","title":"<code>BaseRPC</code>","text":"<p>Base class for communicating with a Deadline RPC server. It is recommended this class is subclassed for any script that need to communicate with deadline. The class automatically handles connecting and marking tasks as complete when some abstract methods are implemented</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>class BaseRPC:\n    \"\"\"\n    Base class for communicating with a Deadline RPC server. It is\n    recommended this class is subclassed for any script that need to\n    communicate with deadline. The class automatically handles connecting and\n    marking tasks as complete when some abstract methods are implemented\n    \"\"\"\n\n    def __init__(self, port=None, ignore_rpc=False, verbose=False):\n        \"\"\"\n        This allows you to get an instance of the class without expecting\n        an automatic connection to a rpc server. This will allow you to have\n        a class that can both be executed in a deadline commandline interface or\n        as a class instance.\n        :param port: Optional port to connect to\n        :param ignore_rpc: Flag to short circuit connecting to a rpc server\n        \"\"\"\n        self._ignore_rpc = ignore_rpc\n        self._proxy = None\n        if not self._ignore_rpc:\n            if not port:\n                try:\n                    port = os.environ[\"DEADLINE_RPC_PORT\"]\n                except KeyError:\n                    raise RuntimeError(\n                        \"There was no port specified for the rpc server\"\n                    )\n\n            self._port = int(port)\n\n            # Make a connection to the RPC server\n            self._proxy = self.__establish_connection()\n\n        self.current_task_id = -1  # Setting this to -1 allows us to\n        # render the first task. i.e task 0\n        self._get_next_task = True\n        self._tick_handle = None\n\n        self._verbose_logging = verbose\n\n        # Set up a property to notify the class when a task is complete\n        self.__create_on_task_complete_global()\n        self.task_complete = False\n        self._sent_task_status = False\n\n        # Start getting tasks to process\n        self._execute()\n\n    @staticmethod\n    def __create_on_task_complete_global():\n        \"\"\"\n        Creates a property in the globals that allows fire and forget tasks\n        to notify the class when a task is complete and allowing it to get\n        the next task\n        :return:\n        \"\"\"\n        if not hasattr(__main__, \"__notify_task_complete__\"):\n            __main__.__notify_task_complete__ = False\n\n        return __main__.__notify_task_complete__\n\n    def __establish_connection(self):\n        \"\"\"\n        Makes a connection to the Deadline RPC server\n        \"\"\"\n        print(f\"Connecting to rpc server on port `{self._port}`\")\n        try:\n            _client = RPCClient(port=int(self._port))\n            proxy = _client.proxy\n            proxy.connect()\n        except Exception:\n            raise\n        else:\n            if not proxy.is_connected():\n                raise RuntimeError(\n                    \"A connection could not be made with the server\"\n                )\n            print(f\"Connection to server established!\")\n            return proxy\n\n    def _wait_for_next_task(self, delta_seconds):\n        \"\"\"\n        Checks to see if there are any new tasks and executes when there is\n        :param delta_seconds:\n        :return:\n        \"\"\"\n\n        # skip if our task is the same as previous\n        if self.proxy.get_task_id() == self.current_task_id:\n            if self._verbose_logging:\n                print(\"Waiting on next task..\")\n            return\n\n        print(\"New task received!\")\n\n        # Make sure we are explicitly told the task is complete by clearing\n        # the globals when we get a new task\n        __main__.__notify_task_complete__ = False\n        self.task_complete = False\n\n        # Unregister the tick handle and execute the task\n        unreal.unregister_slate_post_tick_callback(self._tick_handle)\n        self._tick_handle = None\n\n        # Set the current task and execute\n        self.current_task_id = self.proxy.get_task_id()\n        self._get_next_task = False\n\n        print(f\"Executing task `{self.current_task_id}`\")\n        self.proxy.set_status_message(\"Executing task command\")\n\n        # Execute the next task\n        # Make sure we fail the job if we encounter any exceptions and\n        # provide the traceback to the proxy server\n        try:\n            self.execute()\n        except Exception:\n            trace = traceback.format_exc()\n            print(trace)\n            self.proxy.fail_render(trace)\n            raise\n\n        # Start a non-blocking loop that waits till its notified a task is\n        # complete\n        self._tick_handle = unreal.register_slate_post_tick_callback(\n            self._wait_on_task_complete\n        )\n\n    def _wait_on_task_complete(self, delta_seconds):\n        \"\"\"\n        Waits till a task is mark as completed\n        :param delta_seconds:\n        :return:\n        \"\"\"\n        if self._verbose_logging:\n            print(\"Waiting on task to complete..\")\n        if not self._sent_task_status:\n            self.proxy.set_status_message(\"Waiting on task completion..\")\n            self._sent_task_status = True\n        if __main__.__notify_task_complete__ or self.task_complete:\n\n            # Exiting the waiting loop\n            unreal.unregister_slate_post_tick_callback(self._tick_handle)\n            self._tick_handle = None\n\n            print(\"Task marked complete. Getting next Task\")\n            self.proxy.set_status_message(\"Task complete!\")\n\n            # Reset the task status notification\n            self._sent_task_status = False\n\n            # Automatically marks a task complete when the execute function\n            # exits\n            with _RPCContextManager(self.proxy, self.current_task_id):\n\n                self._get_next_task = True\n\n            # This will allow us to keep getting tasks till the process is\n            # closed\n            self._execute()\n\n    def _execute(self):\n        \"\"\"\n        Start the execution process\n        \"\"\"\n\n        if self._get_next_task and not self._ignore_rpc:\n\n            # register a callback with the editor that will check and execute\n            # the task on editor tick\n            self._tick_handle = unreal.register_slate_post_tick_callback(\n                self._wait_for_next_task\n            )\n\n    @property\n    def proxy(self):\n        \"\"\"\n        Returns an instance of the Client proxy\n        :return:\n        \"\"\"\n        if not self._proxy:\n            raise RuntimeError(\"There is no connected proxy!\")\n\n        return self._proxy\n\n    @property\n    def is_connected(self):\n        \"\"\"\n        Property that returns if a connection was made with the server\n        :return:\n        \"\"\"\n        return self.proxy.is_connected()\n\n    @abstractmethod\n    def execute(self):\n        \"\"\"\n        Abstract methods that is executed to perform a task job/command.\n        This method must be implemented when communicating with a Deadline\n        RPC server\n        :return:\n        \"\"\"\n        pass\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.BaseRPC.is_connected","title":"<code>is_connected</code>  <code>property</code>","text":"<p>Property that returns if a connection was made with the server :return:</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.BaseRPC.proxy","title":"<code>proxy</code>  <code>property</code>","text":"<p>Returns an instance of the Client proxy :return:</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.BaseRPC.__create_on_task_complete_global","title":"<code>__create_on_task_complete_global()</code>  <code>staticmethod</code>","text":"<p>Creates a property in the globals that allows fire and forget tasks to notify the class when a task is complete and allowing it to get the next task :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>@staticmethod\ndef __create_on_task_complete_global():\n    \"\"\"\n    Creates a property in the globals that allows fire and forget tasks\n    to notify the class when a task is complete and allowing it to get\n    the next task\n    :return:\n    \"\"\"\n    if not hasattr(__main__, \"__notify_task_complete__\"):\n        __main__.__notify_task_complete__ = False\n\n    return __main__.__notify_task_complete__\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.BaseRPC.__establish_connection","title":"<code>__establish_connection()</code>","text":"<p>Makes a connection to the Deadline RPC server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>def __establish_connection(self):\n    \"\"\"\n    Makes a connection to the Deadline RPC server\n    \"\"\"\n    print(f\"Connecting to rpc server on port `{self._port}`\")\n    try:\n        _client = RPCClient(port=int(self._port))\n        proxy = _client.proxy\n        proxy.connect()\n    except Exception:\n        raise\n    else:\n        if not proxy.is_connected():\n            raise RuntimeError(\n                \"A connection could not be made with the server\"\n            )\n        print(f\"Connection to server established!\")\n        return proxy\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.BaseRPC.__init__","title":"<code>__init__(port=None, ignore_rpc=False, verbose=False)</code>","text":"<p>This allows you to get an instance of the class without expecting an automatic connection to a rpc server. This will allow you to have a class that can both be executed in a deadline commandline interface or as a class instance. :param port: Optional port to connect to :param ignore_rpc: Flag to short circuit connecting to a rpc server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>def __init__(self, port=None, ignore_rpc=False, verbose=False):\n    \"\"\"\n    This allows you to get an instance of the class without expecting\n    an automatic connection to a rpc server. This will allow you to have\n    a class that can both be executed in a deadline commandline interface or\n    as a class instance.\n    :param port: Optional port to connect to\n    :param ignore_rpc: Flag to short circuit connecting to a rpc server\n    \"\"\"\n    self._ignore_rpc = ignore_rpc\n    self._proxy = None\n    if not self._ignore_rpc:\n        if not port:\n            try:\n                port = os.environ[\"DEADLINE_RPC_PORT\"]\n            except KeyError:\n                raise RuntimeError(\n                    \"There was no port specified for the rpc server\"\n                )\n\n        self._port = int(port)\n\n        # Make a connection to the RPC server\n        self._proxy = self.__establish_connection()\n\n    self.current_task_id = -1  # Setting this to -1 allows us to\n    # render the first task. i.e task 0\n    self._get_next_task = True\n    self._tick_handle = None\n\n    self._verbose_logging = verbose\n\n    # Set up a property to notify the class when a task is complete\n    self.__create_on_task_complete_global()\n    self.task_complete = False\n    self._sent_task_status = False\n\n    # Start getting tasks to process\n    self._execute()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/index.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.BaseRPC.execute","title":"<code>execute()</code>  <code>abstractmethod</code>","text":"<p>Abstract methods that is executed to perform a task job/command. This method must be implemented when communicating with a Deadline RPC server :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>@abstractmethod\ndef execute(self):\n    \"\"\"\n    Abstract methods that is executed to perform a task job/command.\n    This method must be implemented when communicating with a Deadline\n    RPC server\n    :return:\n    \"\"\"\n    pass\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html","title":"base_server","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServer","title":"<code>BaseRPCServer</code>","text":"Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>class BaseRPCServer:\n    def __init__(self, name, port, is_thread=False):\n        \"\"\"\n        Initialize the base server.\n\n        :param str name: The name of the server.\n        :param int port: The number of the server port.\n        :param bool is_thread: Whether or not the server is encapsulated in a thread.\n        \"\"\"\n        self.server = BaseServer(\n            (os.environ.get('RPC_HOST', '127.0.0.1'), port),\n            logRequests=False,\n            allow_none=True\n        )\n        self.is_thread = is_thread\n        self.server.register_function(self.add_new_callable)\n        self.server.register_function(self.kill)\n        self.server.register_function(self.is_running)\n        self.server.register_function(self.set_env)\n        self.server.register_introspection_functions()\n        self.server.register_multicall_functions()\n        logger.info(f'Started RPC server \"{name}\".')\n\n    @staticmethod\n    def is_running():\n        \"\"\"\n        Responds if the server is running.\n        \"\"\"\n        return True\n\n    @staticmethod\n    def set_env(name, value):\n        \"\"\"\n        Sets an environment variable in the server's python environment.\n\n        :param str name: The name of the variable.\n        :param str value: The value.\n        \"\"\"\n        os.environ[name] = str(value)\n\n    def kill(self):\n        \"\"\"\n        Kill the running server from the client. Only if running in blocking mode.\n        \"\"\"\n        self.server.quit = True\n        return True\n\n    def add_new_callable(self, callable_name, code, client_system_path, remap_pairs=None):\n        \"\"\"\n        Adds a new callable defined in the client to the server.\n\n        :param str callable_name: The name of the function that will added to the server.\n        :param str code: The code of the callable that will be added to the server.\n        :param list[str] client_system_path: The list of python system paths from the client.\n        :param list(tuple) remap_pairs: A list of tuples with first value being the client python path root and the\n        second being the new server path root. This can be useful if the client and server are on two different file\n        systems and the root of the import paths need to be dynamically replaced.\n        :return str: A response message back to the client.\n        \"\"\"\n        for path in client_system_path:\n            # if a list of remap pairs are provided, they will be remapped before being added to the system path\n            for client_path_root, matching_server_path_root in remap_pairs or []:\n                if path.startswith(client_path_root):\n                    path = os.path.join(\n                        matching_server_path_root,\n                        path.replace(client_path_root, '').replace(os.sep, '/').strip('/')\n                    )\n\n            if path not in sys.path:\n                sys.path.append(path)\n\n        # run the function code\n        exec(code)\n        callable_instance = locals().copy().get(callable_name)\n\n        # grab it from the locals and register it with the server\n        if callable_instance:\n            if self.is_thread:\n                self.server.register_function(\n                    self.thread_safe_call(callable_instance),\n                    callable_name\n                )\n            else:\n                self.server.register_function(\n                    callable_instance,\n                    callable_name\n                )\n        return f'The function \"{callable_name}\" has been successfully registered with the server!'\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServer.__init__","title":"<code>__init__(name, port, is_thread=False)</code>","text":"<p>Initialize the base server.</p> <p>:param str name: The name of the server. :param int port: The number of the server port. :param bool is_thread: Whether or not the server is encapsulated in a thread.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def __init__(self, name, port, is_thread=False):\n    \"\"\"\n    Initialize the base server.\n\n    :param str name: The name of the server.\n    :param int port: The number of the server port.\n    :param bool is_thread: Whether or not the server is encapsulated in a thread.\n    \"\"\"\n    self.server = BaseServer(\n        (os.environ.get('RPC_HOST', '127.0.0.1'), port),\n        logRequests=False,\n        allow_none=True\n    )\n    self.is_thread = is_thread\n    self.server.register_function(self.add_new_callable)\n    self.server.register_function(self.kill)\n    self.server.register_function(self.is_running)\n    self.server.register_function(self.set_env)\n    self.server.register_introspection_functions()\n    self.server.register_multicall_functions()\n    logger.info(f'Started RPC server \"{name}\".')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServer.add_new_callable","title":"<code>add_new_callable(callable_name, code, client_system_path, remap_pairs=None)</code>","text":"<p>Adds a new callable defined in the client to the server.</p> <p>:param str callable_name: The name of the function that will added to the server. :param str code: The code of the callable that will be added to the server. :param list[str] client_system_path: The list of python system paths from the client. :param list(tuple) remap_pairs: A list of tuples with first value being the client python path root and the second being the new server path root. This can be useful if the client and server are on two different file systems and the root of the import paths need to be dynamically replaced. :return str: A response message back to the client.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def add_new_callable(self, callable_name, code, client_system_path, remap_pairs=None):\n    \"\"\"\n    Adds a new callable defined in the client to the server.\n\n    :param str callable_name: The name of the function that will added to the server.\n    :param str code: The code of the callable that will be added to the server.\n    :param list[str] client_system_path: The list of python system paths from the client.\n    :param list(tuple) remap_pairs: A list of tuples with first value being the client python path root and the\n    second being the new server path root. This can be useful if the client and server are on two different file\n    systems and the root of the import paths need to be dynamically replaced.\n    :return str: A response message back to the client.\n    \"\"\"\n    for path in client_system_path:\n        # if a list of remap pairs are provided, they will be remapped before being added to the system path\n        for client_path_root, matching_server_path_root in remap_pairs or []:\n            if path.startswith(client_path_root):\n                path = os.path.join(\n                    matching_server_path_root,\n                    path.replace(client_path_root, '').replace(os.sep, '/').strip('/')\n                )\n\n        if path not in sys.path:\n            sys.path.append(path)\n\n    # run the function code\n    exec(code)\n    callable_instance = locals().copy().get(callable_name)\n\n    # grab it from the locals and register it with the server\n    if callable_instance:\n        if self.is_thread:\n            self.server.register_function(\n                self.thread_safe_call(callable_instance),\n                callable_name\n            )\n        else:\n            self.server.register_function(\n                callable_instance,\n                callable_name\n            )\n    return f'The function \"{callable_name}\" has been successfully registered with the server!'\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServer.is_running","title":"<code>is_running()</code>  <code>staticmethod</code>","text":"<p>Responds if the server is running.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>@staticmethod\ndef is_running():\n    \"\"\"\n    Responds if the server is running.\n    \"\"\"\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServer.kill","title":"<code>kill()</code>","text":"<p>Kill the running server from the client. Only if running in blocking mode.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def kill(self):\n    \"\"\"\n    Kill the running server from the client. Only if running in blocking mode.\n    \"\"\"\n    self.server.quit = True\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServer.set_env","title":"<code>set_env(name, value)</code>  <code>staticmethod</code>","text":"<p>Sets an environment variable in the server's python environment.</p> <p>:param str name: The name of the variable. :param str value: The value.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>@staticmethod\ndef set_env(name, value):\n    \"\"\"\n    Sets an environment variable in the server's python environment.\n\n    :param str name: The name of the variable.\n    :param str value: The value.\n    \"\"\"\n    os.environ[name] = str(value)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerManager","title":"<code>BaseRPCServerManager</code>","text":"Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>class BaseRPCServerManager:\n    @abc.abstractmethod\n    def __init__(self):\n        \"\"\"\n        Initialize the server manager.\n        Note: when this class is subclassed `name`, `port`, `threaded_server_class` need to be defined.\n        \"\"\"\n        self.server_thread = None\n        self.server_blocking = None\n        self._server = None\n\n    def start_server_thread(self):\n        \"\"\"\n        Starts the server in a thread.\n        \"\"\"\n        self.server_thread = self.threaded_server_class(self.name, self.port)\n        self._server = self.server_thread.server\n        self.server_thread.start()\n\n    def start_server_blocking(self):\n        \"\"\"\n        Starts the server in the main thread, which blocks all other processes. This can only\n        be killed by the client.\n        \"\"\"\n        self.server_blocking = BaseRPCServer(self.name, self.port)\n        self._server = self.server_blocking.server\n        self._server.serve_until_killed()\n\n    def start(self, threaded=True):\n        \"\"\"\n        Starts the server.\n\n        :param bool threaded: Whether or not to start the server in a thread. If not threaded\n        it will block all other processes.\n        \"\"\"\n        # start the server in a thread\n        if threaded and not self.server_thread:\n            self.start_server_thread()\n\n        # start the blocking server\n        elif not threaded and not self.server_blocking:\n            self.start_server_blocking()\n\n        else:\n            logger.info(f'RPC server \"{self.name}\" is already running...')\n\n    def is_running(self):\n        \"\"\"\n        Checks to see if a blocking or threaded RPC server is still running\n        \"\"\"\n        if self._server:\n            try:\n                return self._server.is_running()\n            except (AttributeError, RuntimeError, Exception):\n                return False\n\n        return False\n\n    def get_server(self):\n        \"\"\"\n        Returns the rpc server running. This is useful when executing in a\n        thread and not blocking\n        \"\"\"\n        if not self._server:\n            raise RuntimeError(\"There is no server configured for this Manager\")\n\n        return self._server\n\n    def shutdown(self):\n        \"\"\"\n        Shuts down the server.\n        \"\"\"\n        if self.server_thread:\n            logger.info(f'RPC server \"{self.name}\" is shutting down...')\n\n            # kill the server in the thread\n            if self._server:\n                self._server.shutdown()\n                self._server.server_close()\n\n            self.server_thread.join()\n\n            logger.info(f'RPC server \"{self.name}\" has shutdown.')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerManager.__init__","title":"<code>__init__()</code>  <code>abstractmethod</code>","text":"<p>Initialize the server manager. Note: when this class is subclassed <code>name</code>, <code>port</code>, <code>threaded_server_class</code> need to be defined.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>@abc.abstractmethod\ndef __init__(self):\n    \"\"\"\n    Initialize the server manager.\n    Note: when this class is subclassed `name`, `port`, `threaded_server_class` need to be defined.\n    \"\"\"\n    self.server_thread = None\n    self.server_blocking = None\n    self._server = None\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerManager.get_server","title":"<code>get_server()</code>","text":"<p>Returns the rpc server running. This is useful when executing in a thread and not blocking</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def get_server(self):\n    \"\"\"\n    Returns the rpc server running. This is useful when executing in a\n    thread and not blocking\n    \"\"\"\n    if not self._server:\n        raise RuntimeError(\"There is no server configured for this Manager\")\n\n    return self._server\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerManager.is_running","title":"<code>is_running()</code>","text":"<p>Checks to see if a blocking or threaded RPC server is still running</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def is_running(self):\n    \"\"\"\n    Checks to see if a blocking or threaded RPC server is still running\n    \"\"\"\n    if self._server:\n        try:\n            return self._server.is_running()\n        except (AttributeError, RuntimeError, Exception):\n            return False\n\n    return False\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerManager.shutdown","title":"<code>shutdown()</code>","text":"<p>Shuts down the server.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def shutdown(self):\n    \"\"\"\n    Shuts down the server.\n    \"\"\"\n    if self.server_thread:\n        logger.info(f'RPC server \"{self.name}\" is shutting down...')\n\n        # kill the server in the thread\n        if self._server:\n            self._server.shutdown()\n            self._server.server_close()\n\n        self.server_thread.join()\n\n        logger.info(f'RPC server \"{self.name}\" has shutdown.')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerManager.start","title":"<code>start(threaded=True)</code>","text":"<p>Starts the server.</p> <p>:param bool threaded: Whether or not to start the server in a thread. If not threaded it will block all other processes.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def start(self, threaded=True):\n    \"\"\"\n    Starts the server.\n\n    :param bool threaded: Whether or not to start the server in a thread. If not threaded\n    it will block all other processes.\n    \"\"\"\n    # start the server in a thread\n    if threaded and not self.server_thread:\n        self.start_server_thread()\n\n    # start the blocking server\n    elif not threaded and not self.server_blocking:\n        self.start_server_blocking()\n\n    else:\n        logger.info(f'RPC server \"{self.name}\" is already running...')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerManager.start_server_blocking","title":"<code>start_server_blocking()</code>","text":"<p>Starts the server in the main thread, which blocks all other processes. This can only be killed by the client.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def start_server_blocking(self):\n    \"\"\"\n    Starts the server in the main thread, which blocks all other processes. This can only\n    be killed by the client.\n    \"\"\"\n    self.server_blocking = BaseRPCServer(self.name, self.port)\n    self._server = self.server_blocking.server\n    self._server.serve_until_killed()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerManager.start_server_thread","title":"<code>start_server_thread()</code>","text":"<p>Starts the server in a thread.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def start_server_thread(self):\n    \"\"\"\n    Starts the server in a thread.\n    \"\"\"\n    self.server_thread = self.threaded_server_class(self.name, self.port)\n    self._server = self.server_thread.server\n    self.server_thread.start()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerThread","title":"<code>BaseRPCServerThread</code>","text":"<p>               Bases: <code>Thread</code>, <code>BaseRPCServer</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>class BaseRPCServerThread(threading.Thread, BaseRPCServer):\n    def __init__(self, name, port):\n        \"\"\"\n        Initialize the base rpc server.\n\n        :param str name: The name of the server.\n        :param int port: The number of the server port.\n        \"\"\"\n        threading.Thread.__init__(self, name=name, daemon=True)\n        BaseRPCServer.__init__(self, name, port, is_thread=True)\n\n    def run(self):\n        \"\"\"\n        Overrides the run method.\n        \"\"\"\n        self.server.serve_forever()\n\n    @abc.abstractmethod\n    def thread_safe_call(self, callable_instance, *args):\n        \"\"\"\n        Implements thread safe execution of a call.\n        \"\"\"\n        return\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerThread.__init__","title":"<code>__init__(name, port)</code>","text":"<p>Initialize the base rpc server.</p> <p>:param str name: The name of the server. :param int port: The number of the server port.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def __init__(self, name, port):\n    \"\"\"\n    Initialize the base rpc server.\n\n    :param str name: The name of the server.\n    :param int port: The number of the server port.\n    \"\"\"\n    threading.Thread.__init__(self, name=name, daemon=True)\n    BaseRPCServer.__init__(self, name, port, is_thread=True)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerThread.run","title":"<code>run()</code>","text":"<p>Overrides the run method.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def run(self):\n    \"\"\"\n    Overrides the run method.\n    \"\"\"\n    self.server.serve_forever()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseRPCServerThread.thread_safe_call","title":"<code>thread_safe_call(callable_instance, *args)</code>  <code>abstractmethod</code>","text":"<p>Implements thread safe execution of a call.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>@abc.abstractmethod\ndef thread_safe_call(self, callable_instance, *args):\n    \"\"\"\n    Implements thread safe execution of a call.\n    \"\"\"\n    return\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseServer","title":"<code>BaseServer</code>","text":"<p>               Bases: <code>SimpleXMLRPCServer</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>class BaseServer(SimpleXMLRPCServer):\n    def serve_until_killed(self):\n        \"\"\"\n        Serves till killed by the client.\n        \"\"\"\n        self.quit = False\n        while not self.quit:\n            self.handle_request()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.BaseServer.serve_until_killed","title":"<code>serve_until_killed()</code>","text":"<p>Serves till killed by the client.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def serve_until_killed(self):\n    \"\"\"\n    Serves till killed by the client.\n    \"\"\"\n    self.quit = False\n    while not self.quit:\n        self.handle_request()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.execute_queued_calls","title":"<code>execute_queued_calls(*extra_args)</code>","text":"<p>Runs calls in the execution que till they are gone. Designed to be passed to a recurring event in an integration like a timer.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def execute_queued_calls(*extra_args):\n    \"\"\"\n    Runs calls in the execution que till they are gone. Designed to be passed to a\n    recurring event in an integration like a timer.\n    \"\"\"\n    while not EXECUTION_QUEUE.empty():\n        if RETURN_VALUE_NAME not in globals():\n            callable_instance, args = EXECUTION_QUEUE.get()\n            try:\n                globals()[RETURN_VALUE_NAME] = callable_instance(*args)\n            except Exception as error:\n                # store the error in the globals and re-raise it\n                globals()[ERROR_VALUE_NAME] = error\n                raise error\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_server.run_in_main_thread","title":"<code>run_in_main_thread(callable_instance, *args)</code>","text":"<p>Runs the provided callable instance in the main thread by added it to a que that is processed by a recurring event in an integration like a timer.</p> <p>:param call callable_instance: A callable. :return: The return value of any call from the client.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_server.py</code> <pre><code>def run_in_main_thread(callable_instance, *args):\n    \"\"\"\n    Runs the provided callable instance in the main thread by added it to a que\n    that is processed by a recurring event in an integration like a timer.\n\n    :param call callable_instance: A callable.\n    :return: The return value of any call from the client.\n    \"\"\"\n    timeout = int(os.environ.get('RPC_TIME_OUT', 20))\n\n    globals().pop(RETURN_VALUE_NAME, None)\n    globals().pop(ERROR_VALUE_NAME, None)\n    EXECUTION_QUEUE.put((callable_instance, args))\n\n    for attempt in range(timeout * 10):\n        if RETURN_VALUE_NAME in globals():\n            return globals().get(RETURN_VALUE_NAME)\n        elif ERROR_VALUE_NAME in globals():\n            raise globals()[ERROR_VALUE_NAME]\n        else:\n            time.sleep(0.1)\n\n    if RETURN_VALUE_NAME not in globals():\n        raise TimeoutError(\n            f'The call \"{callable_instance.__name__}\" timed out because it hit the timeout limit'\n            f' of {timeout} seconds.'\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.html","title":"base_ue_rpc","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_ue_rpc.BaseRPC","title":"<code>BaseRPC</code>","text":"<p>Base class for communicating with a Deadline RPC server. It is recommended this class is subclassed for any script that need to communicate with deadline. The class automatically handles connecting and marking tasks as complete when some abstract methods are implemented</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>class BaseRPC:\n    \"\"\"\n    Base class for communicating with a Deadline RPC server. It is\n    recommended this class is subclassed for any script that need to\n    communicate with deadline. The class automatically handles connecting and\n    marking tasks as complete when some abstract methods are implemented\n    \"\"\"\n\n    def __init__(self, port=None, ignore_rpc=False, verbose=False):\n        \"\"\"\n        This allows you to get an instance of the class without expecting\n        an automatic connection to a rpc server. This will allow you to have\n        a class that can both be executed in a deadline commandline interface or\n        as a class instance.\n        :param port: Optional port to connect to\n        :param ignore_rpc: Flag to short circuit connecting to a rpc server\n        \"\"\"\n        self._ignore_rpc = ignore_rpc\n        self._proxy = None\n        if not self._ignore_rpc:\n            if not port:\n                try:\n                    port = os.environ[\"DEADLINE_RPC_PORT\"]\n                except KeyError:\n                    raise RuntimeError(\n                        \"There was no port specified for the rpc server\"\n                    )\n\n            self._port = int(port)\n\n            # Make a connection to the RPC server\n            self._proxy = self.__establish_connection()\n\n        self.current_task_id = -1  # Setting this to -1 allows us to\n        # render the first task. i.e task 0\n        self._get_next_task = True\n        self._tick_handle = None\n\n        self._verbose_logging = verbose\n\n        # Set up a property to notify the class when a task is complete\n        self.__create_on_task_complete_global()\n        self.task_complete = False\n        self._sent_task_status = False\n\n        # Start getting tasks to process\n        self._execute()\n\n    @staticmethod\n    def __create_on_task_complete_global():\n        \"\"\"\n        Creates a property in the globals that allows fire and forget tasks\n        to notify the class when a task is complete and allowing it to get\n        the next task\n        :return:\n        \"\"\"\n        if not hasattr(__main__, \"__notify_task_complete__\"):\n            __main__.__notify_task_complete__ = False\n\n        return __main__.__notify_task_complete__\n\n    def __establish_connection(self):\n        \"\"\"\n        Makes a connection to the Deadline RPC server\n        \"\"\"\n        print(f\"Connecting to rpc server on port `{self._port}`\")\n        try:\n            _client = RPCClient(port=int(self._port))\n            proxy = _client.proxy\n            proxy.connect()\n        except Exception:\n            raise\n        else:\n            if not proxy.is_connected():\n                raise RuntimeError(\n                    \"A connection could not be made with the server\"\n                )\n            print(f\"Connection to server established!\")\n            return proxy\n\n    def _wait_for_next_task(self, delta_seconds):\n        \"\"\"\n        Checks to see if there are any new tasks and executes when there is\n        :param delta_seconds:\n        :return:\n        \"\"\"\n\n        # skip if our task is the same as previous\n        if self.proxy.get_task_id() == self.current_task_id:\n            if self._verbose_logging:\n                print(\"Waiting on next task..\")\n            return\n\n        print(\"New task received!\")\n\n        # Make sure we are explicitly told the task is complete by clearing\n        # the globals when we get a new task\n        __main__.__notify_task_complete__ = False\n        self.task_complete = False\n\n        # Unregister the tick handle and execute the task\n        unreal.unregister_slate_post_tick_callback(self._tick_handle)\n        self._tick_handle = None\n\n        # Set the current task and execute\n        self.current_task_id = self.proxy.get_task_id()\n        self._get_next_task = False\n\n        print(f\"Executing task `{self.current_task_id}`\")\n        self.proxy.set_status_message(\"Executing task command\")\n\n        # Execute the next task\n        # Make sure we fail the job if we encounter any exceptions and\n        # provide the traceback to the proxy server\n        try:\n            self.execute()\n        except Exception:\n            trace = traceback.format_exc()\n            print(trace)\n            self.proxy.fail_render(trace)\n            raise\n\n        # Start a non-blocking loop that waits till its notified a task is\n        # complete\n        self._tick_handle = unreal.register_slate_post_tick_callback(\n            self._wait_on_task_complete\n        )\n\n    def _wait_on_task_complete(self, delta_seconds):\n        \"\"\"\n        Waits till a task is mark as completed\n        :param delta_seconds:\n        :return:\n        \"\"\"\n        if self._verbose_logging:\n            print(\"Waiting on task to complete..\")\n        if not self._sent_task_status:\n            self.proxy.set_status_message(\"Waiting on task completion..\")\n            self._sent_task_status = True\n        if __main__.__notify_task_complete__ or self.task_complete:\n\n            # Exiting the waiting loop\n            unreal.unregister_slate_post_tick_callback(self._tick_handle)\n            self._tick_handle = None\n\n            print(\"Task marked complete. Getting next Task\")\n            self.proxy.set_status_message(\"Task complete!\")\n\n            # Reset the task status notification\n            self._sent_task_status = False\n\n            # Automatically marks a task complete when the execute function\n            # exits\n            with _RPCContextManager(self.proxy, self.current_task_id):\n\n                self._get_next_task = True\n\n            # This will allow us to keep getting tasks till the process is\n            # closed\n            self._execute()\n\n    def _execute(self):\n        \"\"\"\n        Start the execution process\n        \"\"\"\n\n        if self._get_next_task and not self._ignore_rpc:\n\n            # register a callback with the editor that will check and execute\n            # the task on editor tick\n            self._tick_handle = unreal.register_slate_post_tick_callback(\n                self._wait_for_next_task\n            )\n\n    @property\n    def proxy(self):\n        \"\"\"\n        Returns an instance of the Client proxy\n        :return:\n        \"\"\"\n        if not self._proxy:\n            raise RuntimeError(\"There is no connected proxy!\")\n\n        return self._proxy\n\n    @property\n    def is_connected(self):\n        \"\"\"\n        Property that returns if a connection was made with the server\n        :return:\n        \"\"\"\n        return self.proxy.is_connected()\n\n    @abstractmethod\n    def execute(self):\n        \"\"\"\n        Abstract methods that is executed to perform a task job/command.\n        This method must be implemented when communicating with a Deadline\n        RPC server\n        :return:\n        \"\"\"\n        pass\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_ue_rpc.BaseRPC.is_connected","title":"<code>is_connected</code>  <code>property</code>","text":"<p>Property that returns if a connection was made with the server :return:</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_ue_rpc.BaseRPC.proxy","title":"<code>proxy</code>  <code>property</code>","text":"<p>Returns an instance of the Client proxy :return:</p>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_ue_rpc.BaseRPC.__create_on_task_complete_global","title":"<code>__create_on_task_complete_global()</code>  <code>staticmethod</code>","text":"<p>Creates a property in the globals that allows fire and forget tasks to notify the class when a task is complete and allowing it to get the next task :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>@staticmethod\ndef __create_on_task_complete_global():\n    \"\"\"\n    Creates a property in the globals that allows fire and forget tasks\n    to notify the class when a task is complete and allowing it to get\n    the next task\n    :return:\n    \"\"\"\n    if not hasattr(__main__, \"__notify_task_complete__\"):\n        __main__.__notify_task_complete__ = False\n\n    return __main__.__notify_task_complete__\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_ue_rpc.BaseRPC.__establish_connection","title":"<code>__establish_connection()</code>","text":"<p>Makes a connection to the Deadline RPC server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>def __establish_connection(self):\n    \"\"\"\n    Makes a connection to the Deadline RPC server\n    \"\"\"\n    print(f\"Connecting to rpc server on port `{self._port}`\")\n    try:\n        _client = RPCClient(port=int(self._port))\n        proxy = _client.proxy\n        proxy.connect()\n    except Exception:\n        raise\n    else:\n        if not proxy.is_connected():\n            raise RuntimeError(\n                \"A connection could not be made with the server\"\n            )\n        print(f\"Connection to server established!\")\n        return proxy\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_ue_rpc.BaseRPC.__init__","title":"<code>__init__(port=None, ignore_rpc=False, verbose=False)</code>","text":"<p>This allows you to get an instance of the class without expecting an automatic connection to a rpc server. This will allow you to have a class that can both be executed in a deadline commandline interface or as a class instance. :param port: Optional port to connect to :param ignore_rpc: Flag to short circuit connecting to a rpc server</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>def __init__(self, port=None, ignore_rpc=False, verbose=False):\n    \"\"\"\n    This allows you to get an instance of the class without expecting\n    an automatic connection to a rpc server. This will allow you to have\n    a class that can both be executed in a deadline commandline interface or\n    as a class instance.\n    :param port: Optional port to connect to\n    :param ignore_rpc: Flag to short circuit connecting to a rpc server\n    \"\"\"\n    self._ignore_rpc = ignore_rpc\n    self._proxy = None\n    if not self._ignore_rpc:\n        if not port:\n            try:\n                port = os.environ[\"DEADLINE_RPC_PORT\"]\n            except KeyError:\n                raise RuntimeError(\n                    \"There was no port specified for the rpc server\"\n                )\n\n        self._port = int(port)\n\n        # Make a connection to the RPC server\n        self._proxy = self.__establish_connection()\n\n    self.current_task_id = -1  # Setting this to -1 allows us to\n    # render the first task. i.e task 0\n    self._get_next_task = True\n    self._tick_handle = None\n\n    self._verbose_logging = verbose\n\n    # Set up a property to notify the class when a task is complete\n    self.__create_on_task_complete_global()\n    self.task_complete = False\n    self._sent_task_status = False\n\n    # Start getting tasks to process\n    self._execute()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.base_ue_rpc.BaseRPC.execute","title":"<code>execute()</code>  <code>abstractmethod</code>","text":"<p>Abstract methods that is executed to perform a task job/command. This method must be implemented when communicating with a Deadline RPC server :return:</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/base_ue_rpc.py</code> <pre><code>@abstractmethod\ndef execute(self):\n    \"\"\"\n    Abstract methods that is executed to perform a task job/command.\n    This method must be implemented when communicating with a Deadline\n    RPC server\n    :return:\n    \"\"\"\n    pass\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html","title":"client","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.client.RPCClient","title":"<code>RPCClient</code>","text":"Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.py</code> <pre><code>class RPCClient:\n    def __init__(self, port, marshall_exceptions=True):\n        \"\"\"\n        Initializes the rpc client.\n\n        :param int port: A port number the client should connect to.\n        :param bool marshall_exceptions: Whether or not the exceptions should be marshalled.\n        \"\"\"\n        if marshall_exceptions:\n            proxy_class = RPCServerProxy\n        else:\n            proxy_class = ServerProxy\n\n        server_ip = os.environ.get('RPC_SERVER_IP', '127.0.0.1')\n\n        self.proxy = proxy_class(\n            \"http://{server_ip}:{port}\".format(server_ip=server_ip, port=port),\n            allow_none=True,\n        )\n        self.marshall_exceptions = marshall_exceptions\n        self.port = port\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.client.RPCClient.__init__","title":"<code>__init__(port, marshall_exceptions=True)</code>","text":"<p>Initializes the rpc client.</p> <p>:param int port: A port number the client should connect to. :param bool marshall_exceptions: Whether or not the exceptions should be marshalled.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.py</code> <pre><code>def __init__(self, port, marshall_exceptions=True):\n    \"\"\"\n    Initializes the rpc client.\n\n    :param int port: A port number the client should connect to.\n    :param bool marshall_exceptions: Whether or not the exceptions should be marshalled.\n    \"\"\"\n    if marshall_exceptions:\n        proxy_class = RPCServerProxy\n    else:\n        proxy_class = ServerProxy\n\n    server_ip = os.environ.get('RPC_SERVER_IP', '127.0.0.1')\n\n    self.proxy = proxy_class(\n        \"http://{server_ip}:{port}\".format(server_ip=server_ip, port=port),\n        allow_none=True,\n    )\n    self.marshall_exceptions = marshall_exceptions\n    self.port = port\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.client.RPCServerProxy","title":"<code>RPCServerProxy</code>","text":"<p>               Bases: <code>ServerProxy</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.py</code> <pre><code>class RPCServerProxy(ServerProxy):\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Override so we can redefine the ServerProxy to use our custom transport.\n        \"\"\"\n        kwargs['transport'] = RPCTransport()\n        ServerProxy.__init__(self, *args, **kwargs)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.client.RPCServerProxy.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Override so we can redefine the ServerProxy to use our custom transport.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Override so we can redefine the ServerProxy to use our custom transport.\n    \"\"\"\n    kwargs['transport'] = RPCTransport()\n    ServerProxy.__init__(self, *args, **kwargs)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.client.RPCTransport","title":"<code>RPCTransport</code>","text":"<p>               Bases: <code>Transport</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.py</code> <pre><code>class RPCTransport(Transport):\n    def getparser(self):\n        \"\"\"\n        Override so we can redefine our transport to use its own custom unmarshaller.\n\n        :return tuple(ExpatParser, RPCUnmarshaller): The parser and unmarshaller instances.\n        \"\"\"\n        unmarshaller = RPCUnmarshaller()\n        parser = ExpatParser(unmarshaller)\n        return parser, unmarshaller\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.client.RPCTransport.getparser","title":"<code>getparser()</code>","text":"<p>Override so we can redefine our transport to use its own custom unmarshaller.</p> <p>:return tuple(ExpatParser, RPCUnmarshaller): The parser and unmarshaller instances.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.py</code> <pre><code>def getparser(self):\n    \"\"\"\n    Override so we can redefine our transport to use its own custom unmarshaller.\n\n    :return tuple(ExpatParser, RPCUnmarshaller): The parser and unmarshaller instances.\n    \"\"\"\n    unmarshaller = RPCUnmarshaller()\n    parser = ExpatParser(unmarshaller)\n    return parser, unmarshaller\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.client.RPCUnmarshaller","title":"<code>RPCUnmarshaller</code>","text":"<p>               Bases: <code>Unmarshaller</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.py</code> <pre><code>class RPCUnmarshaller(Unmarshaller):\n    def __init__(self, *args, **kwargs):\n        Unmarshaller.__init__(self, *args, **kwargs)\n        self.error_pattern = re.compile(r'(?P&lt;exception&gt;[^:]*):(?P&lt;exception_message&gt;.*$)')\n        self.builtin_exceptions = self._get_built_in_exceptions()\n\n    @staticmethod\n    def _get_built_in_exceptions():\n        \"\"\"\n        Gets a list of the built in exception classes in python.\n\n        :return list[BaseException] A list of the built in exception classes in python:\n        \"\"\"\n        builtin_exceptions = []\n        for builtin_name, builtin_class in globals().get('__builtins__').items():\n            if inspect.isclass(builtin_class) and issubclass(builtin_class, BaseException):\n                builtin_exceptions.append(builtin_class)\n\n        return builtin_exceptions\n\n    def close(self):\n        \"\"\"\n        Override so we redefine the unmarshaller.\n\n        :return tuple: A tuple of marshallables.\n        \"\"\"\n        if self._type is None or self._marks:\n            raise ResponseError()\n\n        if self._type == 'fault':\n            marshallables = self._stack[0]\n            match = self.error_pattern.match(marshallables.get('faultString', ''))\n            if match:\n                exception_name = match.group('exception').strip(\"&lt;class '\").strip(\"'&gt;\")\n                exception_message = match.group('exception_message')\n\n                if exception_name:\n                    for exception in self.builtin_exceptions:\n                        if exception.__name__ == exception_name:\n                            raise exception(exception_message)\n\n            # if all else fails just raise the fault\n            raise Fault(**marshallables)\n        return tuple(self._stack)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.client.RPCUnmarshaller.close","title":"<code>close()</code>","text":"<p>Override so we redefine the unmarshaller.</p> <p>:return tuple: A tuple of marshallables.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/client.py</code> <pre><code>def close(self):\n    \"\"\"\n    Override so we redefine the unmarshaller.\n\n    :return tuple: A tuple of marshallables.\n    \"\"\"\n    if self._type is None or self._marks:\n        raise ResponseError()\n\n    if self._type == 'fault':\n        marshallables = self._stack[0]\n        match = self.error_pattern.match(marshallables.get('faultString', ''))\n        if match:\n            exception_name = match.group('exception').strip(\"&lt;class '\").strip(\"'&gt;\")\n            exception_message = match.group('exception_message')\n\n            if exception_name:\n                for exception in self.builtin_exceptions:\n                    if exception.__name__ == exception_name:\n                        raise exception(exception_message)\n\n        # if all else fails just raise the fault\n        raise Fault(**marshallables)\n    return tuple(self._stack)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.html","title":"exceptions","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.exceptions.BaseRPCException","title":"<code>BaseRPCException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a rpc class method is not authored as a static method.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.py</code> <pre><code>class BaseRPCException(Exception):\n    \"\"\"\n    Raised when a rpc class method is not authored as a static method.\n    \"\"\"\n    def __init__(self, message=None, line_link=''):\n        self.message = message + line_link\n        super().__init__(self.message)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.exceptions.FileNotSavedOnDisk","title":"<code>FileNotSavedOnDisk</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc function is called in a context where it is not a saved file on disk.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.py</code> <pre><code>class FileNotSavedOnDisk(BaseRPCException):\n    \"\"\"\n    Raised when a rpc function is called in a context where it is not a saved file on disk.\n    \"\"\"\n    def __init__(self, function, message=None):\n        self.message = message\n\n        if message is None:\n            self.message = (\n                f'\\n  \"{function.__name__}\" is not being called from a saved file. The RPC client does not '\n                f'support code that is not saved. Please save your code to a file on disk and re-run it.'\n            )\n        BaseRPCException.__init__(self, self.message)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.exceptions.InvalidClassMethod","title":"<code>InvalidClassMethod</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc class method is not authored as a static method.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.py</code> <pre><code>class InvalidClassMethod(BaseRPCException):\n    \"\"\"\n    Raised when a rpc class method is not authored as a static method.\n    \"\"\"\n    def __init__(self, cls, method, message=None, line_link=''):\n        self.message = message\n\n        if message is None:\n            self.message = (\n                f'\\n  {cls.__name__}.{method.__name__} is not a static method. Please decorate with @staticmethod.'\n            )\n        BaseRPCException.__init__(self, self.message, line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.exceptions.InvalidKeyWordParameters","title":"<code>InvalidKeyWordParameters</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc function has key word arguments in its parameters.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.py</code> <pre><code>class InvalidKeyWordParameters(BaseRPCException):\n    \"\"\"\n    Raised when a rpc function has key word arguments in its parameters.\n    \"\"\"\n    def __init__(self, function, kwargs, message=None, line_link=''):\n        self.message = message\n\n        if message is None:\n            self.message = (\n                    f'\\n  Keyword arguments \"{kwargs}\" were found on \"{function.__name__}\". The RPC client does not '\n                    f'support key word arguments . Please change your code to use only arguments.'\n                )\n        BaseRPCException.__init__(self, self.message, line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.exceptions.InvalidTestCasePort","title":"<code>InvalidTestCasePort</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc test case class does not have a port defined.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.py</code> <pre><code>class InvalidTestCasePort(BaseRPCException):\n    \"\"\"\n    Raised when a rpc test case class does not have a port defined.\n    \"\"\"\n    def __init__(self, cls, message=None, line_link=''):\n        self.message = message\n\n        if message is None:\n            self.message = f'\\n  You must set {cls.__name__}.port to a supported RPC port.'\n        BaseRPCException.__init__(self, self.message, line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.exceptions.UnsupportedArgumentType","title":"<code>UnsupportedArgumentType</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc function's argument type is not supported.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/exceptions.py</code> <pre><code>class UnsupportedArgumentType(BaseRPCException):\n    \"\"\"\n    Raised when a rpc function's argument type is not supported.\n    \"\"\"\n    def __init__(self, function, arg, supported_types, message=None, line_link=''):\n        self.message = message\n\n        if message is None:\n            self.message = (\n                f'\\n  \"{function.__name__}\" has an argument of type \"{arg.__class__.__name__}\". The only types that are'\n                f' supported by the RPC client are {[supported_type.__name__ for supported_type in supported_types]}.'\n            )\n        BaseRPCException.__init__(self, self.message, line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.html","title":"factory","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.factory.RPCFactory","title":"<code>RPCFactory</code>","text":"Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.py</code> <pre><code>class RPCFactory:\n    def __init__(self, rpc_client, remap_pairs=None, default_imports=None):\n        self.rpc_client = rpc_client\n        self.file_path = None\n        self.remap_pairs = remap_pairs\n        self.default_imports = default_imports or []\n\n    def _get_callstack_references(self, code, function):\n        \"\"\"\n        Gets all references for the given code.\n\n        :param list[str] code: The code of the callable.\n        :param callable function: A callable.\n        :return str: The new code of the callable with all its references added.\n        \"\"\"\n        import_code = self.default_imports\n\n        client_module = inspect.getmodule(function)\n        self.file_path = get_source_file_path(function)\n\n        # if a list of remap pairs have been set, the file path will be remapped to the new server location\n        # Note: The is useful when the server and client are not on the same machine.\n        server_module_path = self.file_path\n        for client_path_root, matching_server_path_root in self.remap_pairs or []:\n            if self.file_path.startswith(client_path_root):\n                server_module_path = os.path.join(\n                    matching_server_path_root,\n                    self.file_path.replace(client_path_root, '').replace(os.sep, '/').strip('/')\n                )\n                break\n\n        for key in dir(client_module):\n            for line_number, line in enumerate(code):\n                if line.startswith('def '):\n                    continue\n\n                if key in re.split('\\.|\\(| ', line.strip()):\n                    if os.path.basename(self.file_path) == '__init__.py':\n                        base_name = os.path.basename(os.path.dirname(self.file_path))\n                    else:\n                        base_name = os.path.basename(self.file_path)\n\n                    module_name, file_extension = os.path.splitext(base_name)\n                    import_code.append(\n                        f'{module_name} = SourceFileLoader(\"{module_name}\", r\"{server_module_path}\").load_module()'\n                    )\n                    import_code.append(f'from {module_name} import {key}')\n                    break\n\n        return textwrap.indent('\\n'.join(import_code), ' ' * 4)\n\n    def _get_code(self, function):\n        \"\"\"\n        Gets the code from a callable.\n\n        :param callable function: A callable.\n        :return str: The code of the callable.\n        \"\"\"\n        code = textwrap.dedent(inspect.getsource(function)).split('\\n')\n        code = [line for line in code if not line.startswith('@')]\n\n        # get import code and insert them inside the function\n        import_code = self._get_callstack_references(code, function)\n        code.insert(1, import_code)\n\n        # log out the generated code\n        if os.environ.get('RPC_LOG_CODE'):\n            for line in code:\n                logger.debug(line)\n\n        return code\n\n    def _register(self, function):\n        \"\"\"\n        Registers a given callable with the server.\n\n        :param  callable function: A callable.\n        :return Any: The return value.\n        \"\"\"\n        code = self._get_code(function)\n        try:\n            # if additional paths are explicitly set, then use them. This is useful with the client is on another\n            # machine and the python paths are different\n            additional_paths = list(filter(None, os.environ.get('RPC_ADDITIONAL_PYTHON_PATHS', '').split(',')))\n\n            if not additional_paths:\n                # otherwise use the current system path\n                additional_paths = sys.path\n\n            response = self.rpc_client.proxy.add_new_callable(\n                function.__name__, '\\n'.join(code),\n                additional_paths\n            )\n            if os.environ.get('RPC_DEBUG'):\n                logger.debug(response)\n\n        except ConnectionRefusedError:\n            server_name = os.environ.get(f'RPC_SERVER_{self.rpc_client.port}', self.rpc_client.port)\n            raise ConnectionRefusedError(f'No connection could be made with \"{server_name}\"')\n\n    def run_function_remotely(self, function, args):\n        \"\"\"\n        Handles running the given function on remotely.\n\n        :param callable function: A function reference.\n        :param tuple(Any) args: The function's arguments.\n        :return callable: A remote callable.\n        \"\"\"\n        validate_arguments(function, args)\n\n        # get the remote function instance\n        self._register(function)\n        remote_function = getattr(self.rpc_client.proxy, function.__name__)\n\n        current_frame = inspect.currentframe()\n        outer_frame_info = inspect.getouterframes(current_frame)\n        # step back 2 frames in the callstack\n        caller_frame = outer_frame_info[2][0]\n        # create a trace back that is relevant to the remote code rather than the code transporting it\n        call_traceback = types.TracebackType(None, caller_frame, caller_frame.f_lasti, caller_frame.f_lineno)\n        # call the remote function\n        if not self.rpc_client.marshall_exceptions:\n            # if exceptions are not marshalled then receive the default Faut\n            return remote_function(*args)\n\n        # otherwise catch them and add a line link to them\n        try:\n            return remote_function(*args)\n        except Exception as exception:\n            stack_trace = str(exception) + get_line_link(function)\n            if isinstance(exception, Fault):\n                raise Fault(exception.faultCode, exception.faultString)\n            raise exception.__class__(stack_trace).with_traceback(call_traceback)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.factory.RPCFactory.run_function_remotely","title":"<code>run_function_remotely(function, args)</code>","text":"<p>Handles running the given function on remotely.</p> <p>:param callable function: A function reference. :param tuple(Any) args: The function's arguments. :return callable: A remote callable.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.py</code> <pre><code>def run_function_remotely(self, function, args):\n    \"\"\"\n    Handles running the given function on remotely.\n\n    :param callable function: A function reference.\n    :param tuple(Any) args: The function's arguments.\n    :return callable: A remote callable.\n    \"\"\"\n    validate_arguments(function, args)\n\n    # get the remote function instance\n    self._register(function)\n    remote_function = getattr(self.rpc_client.proxy, function.__name__)\n\n    current_frame = inspect.currentframe()\n    outer_frame_info = inspect.getouterframes(current_frame)\n    # step back 2 frames in the callstack\n    caller_frame = outer_frame_info[2][0]\n    # create a trace back that is relevant to the remote code rather than the code transporting it\n    call_traceback = types.TracebackType(None, caller_frame, caller_frame.f_lasti, caller_frame.f_lineno)\n    # call the remote function\n    if not self.rpc_client.marshall_exceptions:\n        # if exceptions are not marshalled then receive the default Faut\n        return remote_function(*args)\n\n    # otherwise catch them and add a line link to them\n    try:\n        return remote_function(*args)\n    except Exception as exception:\n        stack_trace = str(exception) + get_line_link(function)\n        if isinstance(exception, Fault):\n            raise Fault(exception.faultCode, exception.faultString)\n        raise exception.__class__(stack_trace).with_traceback(call_traceback)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.factory.RPCTestCase","title":"<code>RPCTestCase</code>","text":"<p>               Bases: <code>TestCase</code></p> <p>Subclasses unittest.TestCase to implement a RPC compatible TestCase.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.py</code> <pre><code>class RPCTestCase(unittest.TestCase):\n    \"\"\"\n    Subclasses unittest.TestCase to implement a RPC compatible TestCase.\n    \"\"\"\n    port = None\n    remap_pairs = None\n    default_imports = None\n\n    @classmethod\n    def run_remotely(cls, method, args):\n        \"\"\"\n        Run the given method remotely.\n\n        :param callable method: A method to wrap.\n        \"\"\"\n        default_imports = cls.__dict__.get('default_imports', None)\n        port = cls.__dict__.get('port', None)\n        remap_pairs = cls.__dict__.get('remap_pairs', None)\n        rpc_factory = RPCFactory(\n            rpc_client=RPCClient(port),\n            default_imports=default_imports,\n            remap_pairs=remap_pairs\n        )\n        return rpc_factory.run_function_remotely(method, args)\n\n    def _callSetUp(self):\n        \"\"\"\n        Overrides the TestCase._callSetUp method by passing it to be run remotely.\n        Notice None is passed as an argument instead of self. This is because only static methods\n        are allowed by the RPCClient.\n        \"\"\"\n        self.run_remotely(self.setUp, [None])\n\n    def _callTearDown(self):\n        \"\"\"\n        Overrides the TestCase._callTearDown method by passing it to be run remotely.\n        Notice None is passed as an argument instead of self. This is because only static methods\n        are allowed by the RPCClient.\n        \"\"\"\n        # notice None is passed as an argument instead of self so self can't be used\n        self.run_remotely(self.tearDown, [None])\n\n    def _callTestMethod(self, method):\n        \"\"\"\n        Overrides the TestCase._callTestMethod method by capturing the test case method that would be run and then\n        passing it to be run remotely. Notice no arguments are passed. This is because only static methods\n        are allowed by the RPCClient.\n\n        :param callable method: A method from the test case.\n        \"\"\"\n        self.run_remotely(method, [])\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.factory.RPCTestCase.run_remotely","title":"<code>run_remotely(method, args)</code>  <code>classmethod</code>","text":"<p>Run the given method remotely.</p> <p>:param callable method: A method to wrap.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.py</code> <pre><code>@classmethod\ndef run_remotely(cls, method, args):\n    \"\"\"\n    Run the given method remotely.\n\n    :param callable method: A method to wrap.\n    \"\"\"\n    default_imports = cls.__dict__.get('default_imports', None)\n    port = cls.__dict__.get('port', None)\n    remap_pairs = cls.__dict__.get('remap_pairs', None)\n    rpc_factory = RPCFactory(\n        rpc_client=RPCClient(port),\n        default_imports=default_imports,\n        remap_pairs=remap_pairs\n    )\n    return rpc_factory.run_function_remotely(method, args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.factory.remote_call","title":"<code>remote_call(port, default_imports=None, remap_pairs=None)</code>","text":"<p>A decorator that makes this function run remotely.</p> <p>:param Enum port: The name of the port application i.e. maya, blender, unreal. :param list[str] default_imports: A list of import commands that include modules in every call. :param list(tuple) remap_pairs: A list of tuples with first value being the client file path root and the second being the matching server path root. This can be useful if the client and server are on two different file systems and the root of the import paths need to be dynamically replaced.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.py</code> <pre><code>def remote_call(port, default_imports=None, remap_pairs=None):\n    \"\"\"\n    A decorator that makes this function run remotely.\n\n    :param Enum port: The name of the port application i.e. maya, blender, unreal.\n    :param list[str] default_imports: A list of import commands that include modules in every call.\n    :param list(tuple) remap_pairs: A list of tuples with first value being the client file path root and the\n    second being the matching server path root. This can be useful if the client and server are on two different file\n    systems and the root of the import paths need to be dynamically replaced.\n    \"\"\"\n    def decorator(function):\n        def wrapper(*args, **kwargs):\n            validate_file_is_saved(function)\n            validate_key_word_parameters(function, kwargs)\n            rpc_factory = RPCFactory(\n                rpc_client=RPCClient(port),\n                remap_pairs=remap_pairs,\n                default_imports=default_imports\n            )\n            return rpc_factory.run_function_remotely(function, args)\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.factory.remote_class","title":"<code>remote_class(decorator)</code>","text":"<p>A decorator that makes this class run remotely.</p> <p>:param remote_call decorator: The remote call decorator. :return: A decorated class.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/factory.py</code> <pre><code>def remote_class(decorator):\n    \"\"\"\n    A decorator that makes this class run remotely.\n\n    :param remote_call decorator: The remote call decorator.\n    :return: A decorated class.\n    \"\"\"\n    def decorate(cls):\n        for attribute, value in cls.__dict__.items():\n            validate_class_method(cls, value)\n            if callable(getattr(cls, attribute)):\n                setattr(cls, attribute, decorator(getattr(cls, attribute)))\n        return cls\n    return decorate\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.html","title":"server","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.server.RPCServer","title":"<code>RPCServer</code>","text":"<p>               Bases: <code>BaseRPCServerManager</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.py</code> <pre><code>class RPCServer(BaseRPCServerManager):\n    def __init__(self, port=None):\n        \"\"\"\n        Initialize the blender rpc server, with its name and specific port.\n        \"\"\"\n        super(RPCServer, self).__init__()\n        self.name = 'RPCServer'\n        self.port = int(os.environ.get('RPC_PORT', port))\n        self.threaded_server_class = RPCServerThread\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.server.RPCServer.__init__","title":"<code>__init__(port=None)</code>","text":"<p>Initialize the blender rpc server, with its name and specific port.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.py</code> <pre><code>def __init__(self, port=None):\n    \"\"\"\n    Initialize the blender rpc server, with its name and specific port.\n    \"\"\"\n    super(RPCServer, self).__init__()\n    self.name = 'RPCServer'\n    self.port = int(os.environ.get('RPC_PORT', port))\n    self.threaded_server_class = RPCServerThread\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.server.RPCServerThread","title":"<code>RPCServerThread</code>","text":"<p>               Bases: <code>BaseRPCServerThread</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.py</code> <pre><code>class RPCServerThread(BaseRPCServerThread):\n    def thread_safe_call(self, callable_instance, *args):\n        \"\"\"\n        Implementation of a thread safe call in Unreal.\n        \"\"\"\n        return callable_instance(*args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.server.RPCServerThread.thread_safe_call","title":"<code>thread_safe_call(callable_instance, *args)</code>","text":"<p>Implementation of a thread safe call in Unreal.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/server.py</code> <pre><code>def thread_safe_call(self, callable_instance, *args):\n    \"\"\"\n    Implementation of a thread safe call in Unreal.\n    \"\"\"\n    return callable_instance(*args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.html","title":"validations","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.validations.get_line_link","title":"<code>get_line_link(function)</code>","text":"<p>Gets the line number of a function.</p> <p>:param callable function: A callable. :return int: The line number</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.py</code> <pre><code>def get_line_link(function):\n    \"\"\"\n    Gets the line number of a function.\n\n    :param callable function: A callable.\n    :return int: The line number\n    \"\"\"\n    lines, line_number = inspect.getsourcelines(function)\n    file_path = get_source_file_path(function)\n    return f'  File \"{file_path}\", line {line_number}'\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.validations.get_source_file_path","title":"<code>get_source_file_path(function)</code>","text":"<p>Gets the full path to the source code.</p> <p>:param callable function: A callable. :return str: A file path.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.py</code> <pre><code>def get_source_file_path(function):\n    \"\"\"\n    Gets the full path to the source code.\n\n    :param callable function: A callable.\n    :return str: A file path.\n    \"\"\"\n    client_module = inspect.getmodule(function)\n    return client_module.__file__\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.validations.validate_arguments","title":"<code>validate_arguments(function, args)</code>","text":"<p>Validates arguments to ensure they are a supported type.</p> <p>:param callable function: A function reference. :param tuple(Any) args: A list of arguments.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.py</code> <pre><code>def validate_arguments(function, args):\n    \"\"\"\n    Validates arguments to ensure they are a supported type.\n\n    :param callable function: A function reference.\n    :param tuple(Any) args: A list of arguments.\n    \"\"\"\n    supported_types = [str, int, float, tuple, list, dict, bool]\n    line_link = get_line_link(function)\n    for arg in args:\n        if arg is None:\n            continue\n\n        if type(arg) not in supported_types:\n            raise UnsupportedArgumentType(function, arg, supported_types, line_link=line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.validations.validate_class_method","title":"<code>validate_class_method(cls, method)</code>","text":"<p>Validates a method on a class.</p> <p>:param Any cls: A class. :param callable method: A callable.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.py</code> <pre><code>def validate_class_method(cls, method):\n    \"\"\"\n    Validates a method on a class.\n\n    :param Any cls: A class.\n    :param callable method: A callable.\n    \"\"\"\n    if callable(method) and not isinstance(method, staticmethod):\n        line_link = get_line_link(method)\n        raise InvalidClassMethod(cls, method, line_link=line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.validations.validate_file_is_saved","title":"<code>validate_file_is_saved(function)</code>","text":"<p>Validates that the file that the function is from is saved on disk.</p> <p>:param callable function: A callable.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.py</code> <pre><code>def validate_file_is_saved(function):\n    \"\"\"\n    Validates that the file that the function is from is saved on disk.\n\n    :param callable function: A callable.\n    \"\"\"\n    try:\n        inspect.getsourcelines(function)\n    except OSError:\n        raise FileNotSavedOnDisk(function)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.validations.validate_key_word_parameters","title":"<code>validate_key_word_parameters(function, kwargs)</code>","text":"<p>Validates a method on a class.</p> <p>:param callable function: A callable. :param dict kwargs: A dictionary of key word arguments.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.py</code> <pre><code>def validate_key_word_parameters(function, kwargs):\n    \"\"\"\n    Validates a method on a class.\n\n    :param callable function: A callable.\n    :param dict kwargs: A dictionary of key word arguments.\n    \"\"\"\n    if kwargs:\n        line_link = get_line_link(function)\n        raise InvalidKeyWordParameters(function, kwargs, line_link=line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.deadline_rpc.validations.validate_test_case_class","title":"<code>validate_test_case_class(cls)</code>","text":"<p>This is use to validate a subclass of RPCTestCase. While building your test suite you can call this method on each class preemptively to validate that it was defined correctly.</p> <p>:param RPCTestCase cls: A class. :param str file_path: Optionally, a file path to the test case can be passed to give further context into where the error is occurring.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/deadline_rpc/validations.py</code> <pre><code>def validate_test_case_class(cls):\n    \"\"\"\n    This is use to validate a subclass of RPCTestCase. While building your test\n    suite you can call this method on each class preemptively to validate that it\n    was defined correctly.\n\n    :param RPCTestCase cls: A class.\n    :param str file_path: Optionally, a file path to the test case can be passed to give\n    further context into where the error is occurring.\n    \"\"\"\n    line_link = get_line_link(cls)\n    if not cls.__dict__.get('port'):\n        raise InvalidTestCasePort(cls, line_link=line_link)\n\n    for attribute, method in cls.__dict__.items():\n        if callable(method) and not isinstance(method, staticmethod):\n            if method.__name__.startswith('test'):\n                raise InvalidClassMethod(cls, method, line_link=line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/service_actions/index.html","title":"service_actions","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/service_actions/submit_job_action.html","title":"submit_job_action","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/service_actions/submit_job_action.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.UnrealEnginePlugins.UnrealDeadlineService.Content.Python.service_actions.submit_job_action.register_menu_action","title":"<code>register_menu_action()</code>","text":"<p>Creates the toolbar menu</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/UnrealEnginePlugins/UnrealDeadlineService/Content/Python/service_actions/submit_job_action.py</code> <pre><code>def register_menu_action():\n    \"\"\"\n    Creates the toolbar menu\n    \"\"\"\n\n    if not _validate_euw_asset_exists():\n        unreal.log_warning(\n            f\"EUW {EDITOR_UTILITY_WIDGET} does not exist in the Asset registry!\"\n        )\n        return\n\n    toolbar = DeadlineToolBarMenu()\n\n    toolbar.register_submenu(\n        \"SubmitDeadlineJob\",\n        _launch_job_submitter,\n        label_name=\"Submit Deadline Job\",\n        description=\"Submits a job to Deadline\"\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/index.html","title":"ue_utils","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/submit_deadline_job.html","title":"submit_deadline_job","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/submit_deadline_job.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.submit_deadline_job.submit_job","title":"<code>submit_job(name, job_info, plugin_info, aux_files=None)</code>","text":"<p>Creates a job and plugin file and submits it to deadline as a job :param name: Name of the plugin :param job_info: The job dictionary :type job_info dict :param plugin_info: The plugin dictionary :type plugin_info dict :param aux_files: The files submitted to the farm :type aux_files list</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/submit_deadline_job.py</code> <pre><code>def submit_job(name, job_info, plugin_info, aux_files=None):\n    \"\"\"\n    Creates a job and plugin file and submits it to deadline as a job\n    :param name: Name of the plugin\n    :param job_info: The job dictionary\n    :type job_info dict\n    :param plugin_info: The plugin dictionary\n    :type plugin_info dict\n    :param aux_files: The files submitted to the farm\n    :type aux_files list\n    \"\"\"\n\n    # Create a job file\n    JobInfoFilename = Path.Combine(\n        ClientUtils.GetDeadlineTempPath(),\n        \"{name}_job_info.job\".format(name=name),\n    )\n    # Get a job info file writer\n    writer = StreamWriter(JobInfoFilename, False, Encoding.Unicode)\n\n    for key, value in job_info.items():\n        writer.WriteLine(\"{key}={value}\".format(key=key, value=value))\n\n    writer.Close()\n\n    # Create a plugin file\n    PluginInfoFilename = Path.Combine(\n        ClientUtils.GetDeadlineTempPath(),\n        \"{name}_plugin_info.job\".format(name=name),\n    )\n    # Get a plugin info file writer\n    writer = StreamWriter(PluginInfoFilename, False, Encoding.Unicode)\n\n    for key, value in plugin_info.items():\n        writer.WriteLine(\"{key}={value}\".format(key=key, value=value))\n\n    # Add Aux Files if any\n    if aux_files:\n        for index, aux_files in enumerate(aux_files):\n            writer.WriteLine(\n                \"File{index}={val}\".format(index=index, val=aux_files)\n            )\n\n    writer.Close()\n\n    # Create the commandline arguments\n    args = StringCollection()\n\n    args.Add(JobInfoFilename)\n    args.Add(PluginInfoFilename)\n\n    # Add aux files to the plugin data\n    if aux_files:\n        for scene_file in aux_files:\n            args.Add(scene_file)\n\n\n    results = ClientUtils.ExecuteCommandAndGetOutput(args)\n\n    # TODO: Return the Job ID and results\n\n    return results\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/index.html","title":"rpc","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html","title":"base_server","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServer","title":"<code>BaseRPCServer</code>","text":"Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>class BaseRPCServer:\n    def __init__(self, name, port, is_thread=False):\n        \"\"\"\n        Initialize the base server.\n\n        :param str name: The name of the server.\n        :param int port: The number of the server port.\n        :param bool is_thread: Whether or not the server is encapsulated in a thread.\n        \"\"\"\n        self.server = BaseServer(\n            (os.environ.get('RPC_HOST', '127.0.0.1'), port),\n            logRequests=False,\n            allow_none=True\n        )\n        self.is_thread = is_thread\n        self.server.register_function(self.add_new_callable)\n        self.server.register_function(self.kill)\n        self.server.register_function(self.is_running)\n        self.server.register_function(self.set_env)\n        self.server.register_introspection_functions()\n        self.server.register_multicall_functions()\n        logger.info(f'Started RPC server \"{name}\".')\n\n    @staticmethod\n    def is_running():\n        \"\"\"\n        Responds if the server is running.\n        \"\"\"\n        return True\n\n    @staticmethod\n    def set_env(name, value):\n        \"\"\"\n        Sets an environment variable in the server's python environment.\n\n        :param str name: The name of the variable.\n        :param str value: The value.\n        \"\"\"\n        os.environ[name] = str(value)\n\n    def kill(self):\n        \"\"\"\n        Kill the running server from the client. Only if running in blocking mode.\n        \"\"\"\n        self.server.quit = True\n        return True\n\n    def add_new_callable(self, callable_name, code, client_system_path, remap_pairs=None):\n        \"\"\"\n        Adds a new callable defined in the client to the server.\n\n        :param str callable_name: The name of the function that will added to the server.\n        :param str code: The code of the callable that will be added to the server.\n        :param list[str] client_system_path: The list of python system paths from the client.\n        :param list(tuple) remap_pairs: A list of tuples with first value being the client python path root and the\n        second being the new server path root. This can be useful if the client and server are on two different file\n        systems and the root of the import paths need to be dynamically replaced.\n        :return str: A response message back to the client.\n        \"\"\"\n        for path in client_system_path:\n            # if a list of remap pairs are provided, they will be remapped before being added to the system path\n            for client_path_root, matching_server_path_root in remap_pairs or []:\n                if path.startswith(client_path_root):\n                    path = os.path.join(\n                        matching_server_path_root,\n                        path.replace(client_path_root, '').replace(os.sep, '/').strip('/')\n                    )\n\n            if path not in sys.path:\n                sys.path.append(path)\n\n        # run the function code\n        exec(code)\n        callable_instance = locals().copy().get(callable_name)\n\n        # grab it from the locals and register it with the server\n        if callable_instance:\n            if self.is_thread:\n                self.server.register_function(\n                    self.thread_safe_call(callable_instance),\n                    callable_name\n                )\n            else:\n                self.server.register_function(\n                    callable_instance,\n                    callable_name\n                )\n        return f'The function \"{callable_name}\" has been successfully registered with the server!'\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServer.__init__","title":"<code>__init__(name, port, is_thread=False)</code>","text":"<p>Initialize the base server.</p> <p>:param str name: The name of the server. :param int port: The number of the server port. :param bool is_thread: Whether or not the server is encapsulated in a thread.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def __init__(self, name, port, is_thread=False):\n    \"\"\"\n    Initialize the base server.\n\n    :param str name: The name of the server.\n    :param int port: The number of the server port.\n    :param bool is_thread: Whether or not the server is encapsulated in a thread.\n    \"\"\"\n    self.server = BaseServer(\n        (os.environ.get('RPC_HOST', '127.0.0.1'), port),\n        logRequests=False,\n        allow_none=True\n    )\n    self.is_thread = is_thread\n    self.server.register_function(self.add_new_callable)\n    self.server.register_function(self.kill)\n    self.server.register_function(self.is_running)\n    self.server.register_function(self.set_env)\n    self.server.register_introspection_functions()\n    self.server.register_multicall_functions()\n    logger.info(f'Started RPC server \"{name}\".')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServer.add_new_callable","title":"<code>add_new_callable(callable_name, code, client_system_path, remap_pairs=None)</code>","text":"<p>Adds a new callable defined in the client to the server.</p> <p>:param str callable_name: The name of the function that will added to the server. :param str code: The code of the callable that will be added to the server. :param list[str] client_system_path: The list of python system paths from the client. :param list(tuple) remap_pairs: A list of tuples with first value being the client python path root and the second being the new server path root. This can be useful if the client and server are on two different file systems and the root of the import paths need to be dynamically replaced. :return str: A response message back to the client.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def add_new_callable(self, callable_name, code, client_system_path, remap_pairs=None):\n    \"\"\"\n    Adds a new callable defined in the client to the server.\n\n    :param str callable_name: The name of the function that will added to the server.\n    :param str code: The code of the callable that will be added to the server.\n    :param list[str] client_system_path: The list of python system paths from the client.\n    :param list(tuple) remap_pairs: A list of tuples with first value being the client python path root and the\n    second being the new server path root. This can be useful if the client and server are on two different file\n    systems and the root of the import paths need to be dynamically replaced.\n    :return str: A response message back to the client.\n    \"\"\"\n    for path in client_system_path:\n        # if a list of remap pairs are provided, they will be remapped before being added to the system path\n        for client_path_root, matching_server_path_root in remap_pairs or []:\n            if path.startswith(client_path_root):\n                path = os.path.join(\n                    matching_server_path_root,\n                    path.replace(client_path_root, '').replace(os.sep, '/').strip('/')\n                )\n\n        if path not in sys.path:\n            sys.path.append(path)\n\n    # run the function code\n    exec(code)\n    callable_instance = locals().copy().get(callable_name)\n\n    # grab it from the locals and register it with the server\n    if callable_instance:\n        if self.is_thread:\n            self.server.register_function(\n                self.thread_safe_call(callable_instance),\n                callable_name\n            )\n        else:\n            self.server.register_function(\n                callable_instance,\n                callable_name\n            )\n    return f'The function \"{callable_name}\" has been successfully registered with the server!'\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServer.is_running","title":"<code>is_running()</code>  <code>staticmethod</code>","text":"<p>Responds if the server is running.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>@staticmethod\ndef is_running():\n    \"\"\"\n    Responds if the server is running.\n    \"\"\"\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServer.kill","title":"<code>kill()</code>","text":"<p>Kill the running server from the client. Only if running in blocking mode.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def kill(self):\n    \"\"\"\n    Kill the running server from the client. Only if running in blocking mode.\n    \"\"\"\n    self.server.quit = True\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServer.set_env","title":"<code>set_env(name, value)</code>  <code>staticmethod</code>","text":"<p>Sets an environment variable in the server's python environment.</p> <p>:param str name: The name of the variable. :param str value: The value.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>@staticmethod\ndef set_env(name, value):\n    \"\"\"\n    Sets an environment variable in the server's python environment.\n\n    :param str name: The name of the variable.\n    :param str value: The value.\n    \"\"\"\n    os.environ[name] = str(value)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerManager","title":"<code>BaseRPCServerManager</code>","text":"Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>class BaseRPCServerManager:\n    @abc.abstractmethod\n    def __init__(self):\n        \"\"\"\n        Initialize the server manager.\n        Note: when this class is subclassed `name`, `port`, `threaded_server_class` need to be defined.\n        \"\"\"\n        self.server_thread = None\n        self.server_blocking = None\n        self._server = None\n\n    def start_server_thread(self):\n        \"\"\"\n        Starts the server in a thread.\n        \"\"\"\n        self.server_thread = self.threaded_server_class(self.name, self.port)\n        self._server = self.server_thread.server\n        self.server_thread.start()\n\n    def start_server_blocking(self):\n        \"\"\"\n        Starts the server in the main thread, which blocks all other processes. This can only\n        be killed by the client.\n        \"\"\"\n        self.server_blocking = BaseRPCServer(self.name, self.port)\n        self._server = self.server_blocking.server\n        self._server.serve_until_killed()\n\n    def start(self, threaded=True):\n        \"\"\"\n        Starts the server.\n\n        :param bool threaded: Whether or not to start the server in a thread. If not threaded\n        it will block all other processes.\n        \"\"\"\n        # start the server in a thread\n        if threaded and not self.server_thread:\n            self.start_server_thread()\n\n        # start the blocking server\n        elif not threaded and not self.server_blocking:\n            self.start_server_blocking()\n\n        else:\n            logger.info(f'RPC server \"{self.name}\" is already running...')\n\n    def is_running(self):\n        \"\"\"\n        Checks to see if a blocking or threaded RPC server is still running\n        \"\"\"\n        if self._server:\n            try:\n                return self._server.is_running()\n            except (AttributeError, RuntimeError, Exception):\n                return False\n\n        return False\n\n    def get_server(self):\n        \"\"\"\n        Returns the rpc server running. This is useful when executing in a\n        thread and not blocking\n        \"\"\"\n        if not self._server:\n            raise RuntimeError(\"There is no server configured for this Manager\")\n\n        return self._server\n\n    def shutdown(self):\n        \"\"\"\n        Shuts down the server.\n        \"\"\"\n        if self.server_thread:\n            logger.info(f'RPC server \"{self.name}\" is shutting down...')\n\n            # kill the server in the thread\n            if self._server:\n                self._server.shutdown()\n                self._server.server_close()\n\n            self.server_thread.join()\n\n            logger.info(f'RPC server \"{self.name}\" has shutdown.')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerManager.__init__","title":"<code>__init__()</code>  <code>abstractmethod</code>","text":"<p>Initialize the server manager. Note: when this class is subclassed <code>name</code>, <code>port</code>, <code>threaded_server_class</code> need to be defined.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>@abc.abstractmethod\ndef __init__(self):\n    \"\"\"\n    Initialize the server manager.\n    Note: when this class is subclassed `name`, `port`, `threaded_server_class` need to be defined.\n    \"\"\"\n    self.server_thread = None\n    self.server_blocking = None\n    self._server = None\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerManager.get_server","title":"<code>get_server()</code>","text":"<p>Returns the rpc server running. This is useful when executing in a thread and not blocking</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def get_server(self):\n    \"\"\"\n    Returns the rpc server running. This is useful when executing in a\n    thread and not blocking\n    \"\"\"\n    if not self._server:\n        raise RuntimeError(\"There is no server configured for this Manager\")\n\n    return self._server\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerManager.is_running","title":"<code>is_running()</code>","text":"<p>Checks to see if a blocking or threaded RPC server is still running</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def is_running(self):\n    \"\"\"\n    Checks to see if a blocking or threaded RPC server is still running\n    \"\"\"\n    if self._server:\n        try:\n            return self._server.is_running()\n        except (AttributeError, RuntimeError, Exception):\n            return False\n\n    return False\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerManager.shutdown","title":"<code>shutdown()</code>","text":"<p>Shuts down the server.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def shutdown(self):\n    \"\"\"\n    Shuts down the server.\n    \"\"\"\n    if self.server_thread:\n        logger.info(f'RPC server \"{self.name}\" is shutting down...')\n\n        # kill the server in the thread\n        if self._server:\n            self._server.shutdown()\n            self._server.server_close()\n\n        self.server_thread.join()\n\n        logger.info(f'RPC server \"{self.name}\" has shutdown.')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerManager.start","title":"<code>start(threaded=True)</code>","text":"<p>Starts the server.</p> <p>:param bool threaded: Whether or not to start the server in a thread. If not threaded it will block all other processes.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def start(self, threaded=True):\n    \"\"\"\n    Starts the server.\n\n    :param bool threaded: Whether or not to start the server in a thread. If not threaded\n    it will block all other processes.\n    \"\"\"\n    # start the server in a thread\n    if threaded and not self.server_thread:\n        self.start_server_thread()\n\n    # start the blocking server\n    elif not threaded and not self.server_blocking:\n        self.start_server_blocking()\n\n    else:\n        logger.info(f'RPC server \"{self.name}\" is already running...')\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerManager.start_server_blocking","title":"<code>start_server_blocking()</code>","text":"<p>Starts the server in the main thread, which blocks all other processes. This can only be killed by the client.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def start_server_blocking(self):\n    \"\"\"\n    Starts the server in the main thread, which blocks all other processes. This can only\n    be killed by the client.\n    \"\"\"\n    self.server_blocking = BaseRPCServer(self.name, self.port)\n    self._server = self.server_blocking.server\n    self._server.serve_until_killed()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerManager.start_server_thread","title":"<code>start_server_thread()</code>","text":"<p>Starts the server in a thread.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def start_server_thread(self):\n    \"\"\"\n    Starts the server in a thread.\n    \"\"\"\n    self.server_thread = self.threaded_server_class(self.name, self.port)\n    self._server = self.server_thread.server\n    self.server_thread.start()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerThread","title":"<code>BaseRPCServerThread</code>","text":"<p>               Bases: <code>Thread</code>, <code>BaseRPCServer</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>class BaseRPCServerThread(threading.Thread, BaseRPCServer):\n    def __init__(self, name, port):\n        \"\"\"\n        Initialize the base rpc server.\n\n        :param str name: The name of the server.\n        :param int port: The number of the server port.\n        \"\"\"\n        threading.Thread.__init__(self, name=name, daemon=True)\n        BaseRPCServer.__init__(self, name, port, is_thread=True)\n\n    def run(self):\n        \"\"\"\n        Overrides the run method.\n        \"\"\"\n        self.server.serve_forever()\n\n    @abc.abstractmethod\n    def thread_safe_call(self, callable_instance, *args):\n        \"\"\"\n        Implements thread safe execution of a call.\n        \"\"\"\n        return\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerThread.__init__","title":"<code>__init__(name, port)</code>","text":"<p>Initialize the base rpc server.</p> <p>:param str name: The name of the server. :param int port: The number of the server port.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def __init__(self, name, port):\n    \"\"\"\n    Initialize the base rpc server.\n\n    :param str name: The name of the server.\n    :param int port: The number of the server port.\n    \"\"\"\n    threading.Thread.__init__(self, name=name, daemon=True)\n    BaseRPCServer.__init__(self, name, port, is_thread=True)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerThread.run","title":"<code>run()</code>","text":"<p>Overrides the run method.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def run(self):\n    \"\"\"\n    Overrides the run method.\n    \"\"\"\n    self.server.serve_forever()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseRPCServerThread.thread_safe_call","title":"<code>thread_safe_call(callable_instance, *args)</code>  <code>abstractmethod</code>","text":"<p>Implements thread safe execution of a call.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>@abc.abstractmethod\ndef thread_safe_call(self, callable_instance, *args):\n    \"\"\"\n    Implements thread safe execution of a call.\n    \"\"\"\n    return\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseServer","title":"<code>BaseServer</code>","text":"<p>               Bases: <code>SimpleXMLRPCServer</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>class BaseServer(SimpleXMLRPCServer):\n    def serve_until_killed(self):\n        \"\"\"\n        Serves till killed by the client.\n        \"\"\"\n        self.quit = False\n        while not self.quit:\n            self.handle_request()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.BaseServer.serve_until_killed","title":"<code>serve_until_killed()</code>","text":"<p>Serves till killed by the client.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def serve_until_killed(self):\n    \"\"\"\n    Serves till killed by the client.\n    \"\"\"\n    self.quit = False\n    while not self.quit:\n        self.handle_request()\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.execute_queued_calls","title":"<code>execute_queued_calls(*extra_args)</code>","text":"<p>Runs calls in the execution que till they are gone. Designed to be passed to a recurring event in an integration like a timer.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def execute_queued_calls(*extra_args):\n    \"\"\"\n    Runs calls in the execution que till they are gone. Designed to be passed to a\n    recurring event in an integration like a timer.\n    \"\"\"\n    while not EXECUTION_QUEUE.empty():\n        if RETURN_VALUE_NAME not in globals():\n            callable_instance, args = EXECUTION_QUEUE.get()\n            try:\n                globals()[RETURN_VALUE_NAME] = callable_instance(*args)\n            except Exception as error:\n                # store the error in the globals and re-raise it\n                globals()[ERROR_VALUE_NAME] = error\n                raise error\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.base_server.run_in_main_thread","title":"<code>run_in_main_thread(callable_instance, *args)</code>","text":"<p>Runs the provided callable instance in the main thread by added it to a que that is processed by a recurring event in an integration like a timer.</p> <p>:param call callable_instance: A callable. :return: The return value of any call from the client.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/base_server.py</code> <pre><code>def run_in_main_thread(callable_instance, *args):\n    \"\"\"\n    Runs the provided callable instance in the main thread by added it to a que\n    that is processed by a recurring event in an integration like a timer.\n\n    :param call callable_instance: A callable.\n    :return: The return value of any call from the client.\n    \"\"\"\n    timeout = int(os.environ.get('RPC_TIME_OUT', 20))\n\n    globals().pop(RETURN_VALUE_NAME, None)\n    globals().pop(ERROR_VALUE_NAME, None)\n    EXECUTION_QUEUE.put((callable_instance, args))\n\n    for attempt in range(timeout * 10):\n        if RETURN_VALUE_NAME in globals():\n            return globals().get(RETURN_VALUE_NAME)\n        elif ERROR_VALUE_NAME in globals():\n            raise globals()[ERROR_VALUE_NAME]\n        else:\n            time.sleep(0.1)\n\n    if RETURN_VALUE_NAME not in globals():\n        raise TimeoutError(\n            f'The call \"{callable_instance.__name__}\" timed out because it hit the timeout limit'\n            f' of {timeout} seconds.'\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html","title":"client","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.client.RPCClient","title":"<code>RPCClient</code>","text":"Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.py</code> <pre><code>class RPCClient:\n    def __init__(self, port, marshall_exceptions=True):\n        \"\"\"\n        Initializes the rpc client.\n\n        :param int port: A port number the client should connect to.\n        :param bool marshall_exceptions: Whether or not the exceptions should be marshalled.\n        \"\"\"\n        if marshall_exceptions:\n            proxy_class = RPCServerProxy\n        else:\n            proxy_class = ServerProxy\n\n        server_ip = os.environ.get('RPC_SERVER_IP', '127.0.0.1')\n\n        self.proxy = proxy_class(\n            \"http://{server_ip}:{port}\".format(server_ip=server_ip, port=port),\n            allow_none=True,\n        )\n        self.marshall_exceptions = marshall_exceptions\n        self.port = port\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.client.RPCClient.__init__","title":"<code>__init__(port, marshall_exceptions=True)</code>","text":"<p>Initializes the rpc client.</p> <p>:param int port: A port number the client should connect to. :param bool marshall_exceptions: Whether or not the exceptions should be marshalled.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.py</code> <pre><code>def __init__(self, port, marshall_exceptions=True):\n    \"\"\"\n    Initializes the rpc client.\n\n    :param int port: A port number the client should connect to.\n    :param bool marshall_exceptions: Whether or not the exceptions should be marshalled.\n    \"\"\"\n    if marshall_exceptions:\n        proxy_class = RPCServerProxy\n    else:\n        proxy_class = ServerProxy\n\n    server_ip = os.environ.get('RPC_SERVER_IP', '127.0.0.1')\n\n    self.proxy = proxy_class(\n        \"http://{server_ip}:{port}\".format(server_ip=server_ip, port=port),\n        allow_none=True,\n    )\n    self.marshall_exceptions = marshall_exceptions\n    self.port = port\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.client.RPCServerProxy","title":"<code>RPCServerProxy</code>","text":"<p>               Bases: <code>ServerProxy</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.py</code> <pre><code>class RPCServerProxy(ServerProxy):\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Override so we can redefine the ServerProxy to use our custom transport.\n        \"\"\"\n        kwargs['transport'] = RPCTransport()\n        ServerProxy.__init__(self, *args, **kwargs)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.client.RPCServerProxy.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Override so we can redefine the ServerProxy to use our custom transport.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Override so we can redefine the ServerProxy to use our custom transport.\n    \"\"\"\n    kwargs['transport'] = RPCTransport()\n    ServerProxy.__init__(self, *args, **kwargs)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.client.RPCTransport","title":"<code>RPCTransport</code>","text":"<p>               Bases: <code>Transport</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.py</code> <pre><code>class RPCTransport(Transport):\n    def getparser(self):\n        \"\"\"\n        Override so we can redefine our transport to use its own custom unmarshaller.\n\n        :return tuple(ExpatParser, RPCUnmarshaller): The parser and unmarshaller instances.\n        \"\"\"\n        unmarshaller = RPCUnmarshaller()\n        parser = ExpatParser(unmarshaller)\n        return parser, unmarshaller\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.client.RPCTransport.getparser","title":"<code>getparser()</code>","text":"<p>Override so we can redefine our transport to use its own custom unmarshaller.</p> <p>:return tuple(ExpatParser, RPCUnmarshaller): The parser and unmarshaller instances.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.py</code> <pre><code>def getparser(self):\n    \"\"\"\n    Override so we can redefine our transport to use its own custom unmarshaller.\n\n    :return tuple(ExpatParser, RPCUnmarshaller): The parser and unmarshaller instances.\n    \"\"\"\n    unmarshaller = RPCUnmarshaller()\n    parser = ExpatParser(unmarshaller)\n    return parser, unmarshaller\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.client.RPCUnmarshaller","title":"<code>RPCUnmarshaller</code>","text":"<p>               Bases: <code>Unmarshaller</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.py</code> <pre><code>class RPCUnmarshaller(Unmarshaller):\n    def __init__(self, *args, **kwargs):\n        Unmarshaller.__init__(self, *args, **kwargs)\n        self.error_pattern = re.compile(r'(?P&lt;exception&gt;[^:]*):(?P&lt;exception_message&gt;.*$)')\n        self.builtin_exceptions = self._get_built_in_exceptions()\n\n    @staticmethod\n    def _get_built_in_exceptions():\n        \"\"\"\n        Gets a list of the built in exception classes in python.\n\n        :return list[BaseException] A list of the built in exception classes in python:\n        \"\"\"\n        builtin_exceptions = []\n        for builtin_name, builtin_class in globals().get('__builtins__').items():\n            if inspect.isclass(builtin_class) and issubclass(builtin_class, BaseException):\n                builtin_exceptions.append(builtin_class)\n\n        return builtin_exceptions\n\n    def close(self):\n        \"\"\"\n        Override so we redefine the unmarshaller.\n\n        :return tuple: A tuple of marshallables.\n        \"\"\"\n        if self._type is None or self._marks:\n            raise ResponseError()\n\n        if self._type == 'fault':\n            marshallables = self._stack[0]\n            match = self.error_pattern.match(marshallables.get('faultString', ''))\n            if match:\n                exception_name = match.group('exception').strip(\"&lt;class '\").strip(\"'&gt;\")\n                exception_message = match.group('exception_message')\n\n                if exception_name:\n                    for exception in self.builtin_exceptions:\n                        if exception.__name__ == exception_name:\n                            raise exception(exception_message)\n\n            # if all else fails just raise the fault\n            raise Fault(**marshallables)\n        return tuple(self._stack)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.client.RPCUnmarshaller.close","title":"<code>close()</code>","text":"<p>Override so we redefine the unmarshaller.</p> <p>:return tuple: A tuple of marshallables.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/client.py</code> <pre><code>def close(self):\n    \"\"\"\n    Override so we redefine the unmarshaller.\n\n    :return tuple: A tuple of marshallables.\n    \"\"\"\n    if self._type is None or self._marks:\n        raise ResponseError()\n\n    if self._type == 'fault':\n        marshallables = self._stack[0]\n        match = self.error_pattern.match(marshallables.get('faultString', ''))\n        if match:\n            exception_name = match.group('exception').strip(\"&lt;class '\").strip(\"'&gt;\")\n            exception_message = match.group('exception_message')\n\n            if exception_name:\n                for exception in self.builtin_exceptions:\n                    if exception.__name__ == exception_name:\n                        raise exception(exception_message)\n\n        # if all else fails just raise the fault\n        raise Fault(**marshallables)\n    return tuple(self._stack)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.html","title":"exceptions","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.exceptions.BaseRPCException","title":"<code>BaseRPCException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a rpc class method is not authored as a static method.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.py</code> <pre><code>class BaseRPCException(Exception):\n    \"\"\"\n    Raised when a rpc class method is not authored as a static method.\n    \"\"\"\n    def __init__(self, message=None, line_link=''):\n        self.message = message + line_link\n        super().__init__(self.message)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.exceptions.FileNotSavedOnDisk","title":"<code>FileNotSavedOnDisk</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc function is called in a context where it is not a saved file on disk.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.py</code> <pre><code>class FileNotSavedOnDisk(BaseRPCException):\n    \"\"\"\n    Raised when a rpc function is called in a context where it is not a saved file on disk.\n    \"\"\"\n    def __init__(self, function, message=None):\n        self.message = message\n\n        if message is None:\n            self.message = (\n                f'\\n  \"{function.__name__}\" is not being called from a saved file. The RPC client does not '\n                f'support code that is not saved. Please save your code to a file on disk and re-run it.'\n            )\n        BaseRPCException.__init__(self, self.message)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.exceptions.InvalidClassMethod","title":"<code>InvalidClassMethod</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc class method is not authored as a static method.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.py</code> <pre><code>class InvalidClassMethod(BaseRPCException):\n    \"\"\"\n    Raised when a rpc class method is not authored as a static method.\n    \"\"\"\n    def __init__(self, cls, method, message=None, line_link=''):\n        self.message = message\n\n        if message is None:\n            self.message = (\n                f'\\n  {cls.__name__}.{method.__name__} is not a static method. Please decorate with @staticmethod.'\n            )\n        BaseRPCException.__init__(self, self.message, line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.exceptions.InvalidKeyWordParameters","title":"<code>InvalidKeyWordParameters</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc function has key word arguments in its parameters.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.py</code> <pre><code>class InvalidKeyWordParameters(BaseRPCException):\n    \"\"\"\n    Raised when a rpc function has key word arguments in its parameters.\n    \"\"\"\n    def __init__(self, function, kwargs, message=None, line_link=''):\n        self.message = message\n\n        if message is None:\n            self.message = (\n                    f'\\n  Keyword arguments \"{kwargs}\" were found on \"{function.__name__}\". The RPC client does not '\n                    f'support key word arguments . Please change your code to use only arguments.'\n                )\n        BaseRPCException.__init__(self, self.message, line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.exceptions.InvalidTestCasePort","title":"<code>InvalidTestCasePort</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc test case class does not have a port defined.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.py</code> <pre><code>class InvalidTestCasePort(BaseRPCException):\n    \"\"\"\n    Raised when a rpc test case class does not have a port defined.\n    \"\"\"\n    def __init__(self, cls, message=None, line_link=''):\n        self.message = message\n\n        if message is None:\n            self.message = f'\\n  You must set {cls.__name__}.port to a supported RPC port.'\n        BaseRPCException.__init__(self, self.message, line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.exceptions.UnsupportedArgumentType","title":"<code>UnsupportedArgumentType</code>","text":"<p>               Bases: <code>BaseRPCException</code></p> <p>Raised when a rpc function's argument type is not supported.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/exceptions.py</code> <pre><code>class UnsupportedArgumentType(BaseRPCException):\n    \"\"\"\n    Raised when a rpc function's argument type is not supported.\n    \"\"\"\n    def __init__(self, function, arg, supported_types, message=None, line_link=''):\n        self.message = message\n\n        if message is None:\n            self.message = (\n                f'\\n  \"{function.__name__}\" has an argument of type \"{arg.__class__.__name__}\". The only types that are'\n                f' supported by the RPC client are {[supported_type.__name__ for supported_type in supported_types]}.'\n            )\n        BaseRPCException.__init__(self, self.message, line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.html","title":"factory","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.factory.RPCFactory","title":"<code>RPCFactory</code>","text":"Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.py</code> <pre><code>class RPCFactory:\n    def __init__(self, rpc_client, remap_pairs=None, default_imports=None):\n        self.rpc_client = rpc_client\n        self.file_path = None\n        self.remap_pairs = remap_pairs\n        self.default_imports = default_imports or []\n\n    def _get_callstack_references(self, code, function):\n        \"\"\"\n        Gets all references for the given code.\n\n        :param list[str] code: The code of the callable.\n        :param callable function: A callable.\n        :return str: The new code of the callable with all its references added.\n        \"\"\"\n        import_code = self.default_imports\n\n        client_module = inspect.getmodule(function)\n        self.file_path = get_source_file_path(function)\n\n        # if a list of remap pairs have been set, the file path will be remapped to the new server location\n        # Note: The is useful when the server and client are not on the same machine.\n        server_module_path = self.file_path\n        for client_path_root, matching_server_path_root in self.remap_pairs or []:\n            if self.file_path.startswith(client_path_root):\n                server_module_path = os.path.join(\n                    matching_server_path_root,\n                    self.file_path.replace(client_path_root, '').replace(os.sep, '/').strip('/')\n                )\n                break\n\n        for key in dir(client_module):\n            for line_number, line in enumerate(code):\n                if line.startswith('def '):\n                    continue\n\n                if key in re.split('\\.|\\(| ', line.strip()):\n                    if os.path.basename(self.file_path) == '__init__.py':\n                        base_name = os.path.basename(os.path.dirname(self.file_path))\n                    else:\n                        base_name = os.path.basename(self.file_path)\n\n                    module_name, file_extension = os.path.splitext(base_name)\n                    import_code.append(\n                        f'{module_name} = SourceFileLoader(\"{module_name}\", r\"{server_module_path}\").load_module()'\n                    )\n                    import_code.append(f'from {module_name} import {key}')\n                    break\n\n        return textwrap.indent('\\n'.join(import_code), ' ' * 4)\n\n    def _get_code(self, function):\n        \"\"\"\n        Gets the code from a callable.\n\n        :param callable function: A callable.\n        :return str: The code of the callable.\n        \"\"\"\n        code = textwrap.dedent(inspect.getsource(function)).split('\\n')\n        code = [line for line in code if not line.startswith('@')]\n\n        # get import code and insert them inside the function\n        import_code = self._get_callstack_references(code, function)\n        code.insert(1, import_code)\n\n        # log out the generated code\n        if os.environ.get('RPC_LOG_CODE'):\n            for line in code:\n                logger.debug(line)\n\n        return code\n\n    def _register(self, function):\n        \"\"\"\n        Registers a given callable with the server.\n\n        :param  callable function: A callable.\n        :return Any: The return value.\n        \"\"\"\n        code = self._get_code(function)\n        try:\n            # if additional paths are explicitly set, then use them. This is useful with the client is on another\n            # machine and the python paths are different\n            additional_paths = list(filter(None, os.environ.get('RPC_ADDITIONAL_PYTHON_PATHS', '').split(',')))\n\n            if not additional_paths:\n                # otherwise use the current system path\n                additional_paths = sys.path\n\n            response = self.rpc_client.proxy.add_new_callable(\n                function.__name__, '\\n'.join(code),\n                additional_paths\n            )\n            if os.environ.get('RPC_DEBUG'):\n                logger.debug(response)\n\n        except ConnectionRefusedError:\n            server_name = os.environ.get(f'RPC_SERVER_{self.rpc_client.port}', self.rpc_client.port)\n            raise ConnectionRefusedError(f'No connection could be made with \"{server_name}\"')\n\n    def run_function_remotely(self, function, args):\n        \"\"\"\n        Handles running the given function on remotely.\n\n        :param callable function: A function reference.\n        :param tuple(Any) args: The function's arguments.\n        :return callable: A remote callable.\n        \"\"\"\n        validate_arguments(function, args)\n\n        # get the remote function instance\n        self._register(function)\n        remote_function = getattr(self.rpc_client.proxy, function.__name__)\n\n        current_frame = inspect.currentframe()\n        outer_frame_info = inspect.getouterframes(current_frame)\n        # step back 2 frames in the callstack\n        caller_frame = outer_frame_info[2][0]\n        # create a trace back that is relevant to the remote code rather than the code transporting it\n        call_traceback = types.TracebackType(None, caller_frame, caller_frame.f_lasti, caller_frame.f_lineno)\n        # call the remote function\n        if not self.rpc_client.marshall_exceptions:\n            # if exceptions are not marshalled then receive the default Faut\n            return remote_function(*args)\n\n        # otherwise catch them and add a line link to them\n        try:\n            return remote_function(*args)\n        except Exception as exception:\n            stack_trace = str(exception) + get_line_link(function)\n            if isinstance(exception, Fault):\n                raise Fault(exception.faultCode, exception.faultString)\n            raise exception.__class__(stack_trace).with_traceback(call_traceback)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.factory.RPCFactory.run_function_remotely","title":"<code>run_function_remotely(function, args)</code>","text":"<p>Handles running the given function on remotely.</p> <p>:param callable function: A function reference. :param tuple(Any) args: The function's arguments. :return callable: A remote callable.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.py</code> <pre><code>def run_function_remotely(self, function, args):\n    \"\"\"\n    Handles running the given function on remotely.\n\n    :param callable function: A function reference.\n    :param tuple(Any) args: The function's arguments.\n    :return callable: A remote callable.\n    \"\"\"\n    validate_arguments(function, args)\n\n    # get the remote function instance\n    self._register(function)\n    remote_function = getattr(self.rpc_client.proxy, function.__name__)\n\n    current_frame = inspect.currentframe()\n    outer_frame_info = inspect.getouterframes(current_frame)\n    # step back 2 frames in the callstack\n    caller_frame = outer_frame_info[2][0]\n    # create a trace back that is relevant to the remote code rather than the code transporting it\n    call_traceback = types.TracebackType(None, caller_frame, caller_frame.f_lasti, caller_frame.f_lineno)\n    # call the remote function\n    if not self.rpc_client.marshall_exceptions:\n        # if exceptions are not marshalled then receive the default Faut\n        return remote_function(*args)\n\n    # otherwise catch them and add a line link to them\n    try:\n        return remote_function(*args)\n    except Exception as exception:\n        stack_trace = str(exception) + get_line_link(function)\n        if isinstance(exception, Fault):\n            raise Fault(exception.faultCode, exception.faultString)\n        raise exception.__class__(stack_trace).with_traceback(call_traceback)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.factory.RPCTestCase","title":"<code>RPCTestCase</code>","text":"<p>               Bases: <code>TestCase</code></p> <p>Subclasses unittest.TestCase to implement a RPC compatible TestCase.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.py</code> <pre><code>class RPCTestCase(unittest.TestCase):\n    \"\"\"\n    Subclasses unittest.TestCase to implement a RPC compatible TestCase.\n    \"\"\"\n    port = None\n    remap_pairs = None\n    default_imports = None\n\n    @classmethod\n    def run_remotely(cls, method, args):\n        \"\"\"\n        Run the given method remotely.\n\n        :param callable method: A method to wrap.\n        \"\"\"\n        default_imports = cls.__dict__.get('default_imports', None)\n        port = cls.__dict__.get('port', None)\n        remap_pairs = cls.__dict__.get('remap_pairs', None)\n        rpc_factory = RPCFactory(\n            rpc_client=RPCClient(port),\n            default_imports=default_imports,\n            remap_pairs=remap_pairs\n        )\n        return rpc_factory.run_function_remotely(method, args)\n\n    def _callSetUp(self):\n        \"\"\"\n        Overrides the TestCase._callSetUp method by passing it to be run remotely.\n        Notice None is passed as an argument instead of self. This is because only static methods\n        are allowed by the RPCClient.\n        \"\"\"\n        self.run_remotely(self.setUp, [None])\n\n    def _callTearDown(self):\n        \"\"\"\n        Overrides the TestCase._callTearDown method by passing it to be run remotely.\n        Notice None is passed as an argument instead of self. This is because only static methods\n        are allowed by the RPCClient.\n        \"\"\"\n        # notice None is passed as an argument instead of self so self can't be used\n        self.run_remotely(self.tearDown, [None])\n\n    def _callTestMethod(self, method):\n        \"\"\"\n        Overrides the TestCase._callTestMethod method by capturing the test case method that would be run and then\n        passing it to be run remotely. Notice no arguments are passed. This is because only static methods\n        are allowed by the RPCClient.\n\n        :param callable method: A method from the test case.\n        \"\"\"\n        self.run_remotely(method, [])\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.factory.RPCTestCase.run_remotely","title":"<code>run_remotely(method, args)</code>  <code>classmethod</code>","text":"<p>Run the given method remotely.</p> <p>:param callable method: A method to wrap.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.py</code> <pre><code>@classmethod\ndef run_remotely(cls, method, args):\n    \"\"\"\n    Run the given method remotely.\n\n    :param callable method: A method to wrap.\n    \"\"\"\n    default_imports = cls.__dict__.get('default_imports', None)\n    port = cls.__dict__.get('port', None)\n    remap_pairs = cls.__dict__.get('remap_pairs', None)\n    rpc_factory = RPCFactory(\n        rpc_client=RPCClient(port),\n        default_imports=default_imports,\n        remap_pairs=remap_pairs\n    )\n    return rpc_factory.run_function_remotely(method, args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.factory.remote_call","title":"<code>remote_call(port, default_imports=None, remap_pairs=None)</code>","text":"<p>A decorator that makes this function run remotely.</p> <p>:param Enum port: The name of the port application i.e. maya, blender, unreal. :param list[str] default_imports: A list of import commands that include modules in every call. :param list(tuple) remap_pairs: A list of tuples with first value being the client file path root and the second being the matching server path root. This can be useful if the client and server are on two different file systems and the root of the import paths need to be dynamically replaced.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.py</code> <pre><code>def remote_call(port, default_imports=None, remap_pairs=None):\n    \"\"\"\n    A decorator that makes this function run remotely.\n\n    :param Enum port: The name of the port application i.e. maya, blender, unreal.\n    :param list[str] default_imports: A list of import commands that include modules in every call.\n    :param list(tuple) remap_pairs: A list of tuples with first value being the client file path root and the\n    second being the matching server path root. This can be useful if the client and server are on two different file\n    systems and the root of the import paths need to be dynamically replaced.\n    \"\"\"\n    def decorator(function):\n        def wrapper(*args, **kwargs):\n            validate_file_is_saved(function)\n            validate_key_word_parameters(function, kwargs)\n            rpc_factory = RPCFactory(\n                rpc_client=RPCClient(port),\n                remap_pairs=remap_pairs,\n                default_imports=default_imports\n            )\n            return rpc_factory.run_function_remotely(function, args)\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.factory.remote_class","title":"<code>remote_class(decorator)</code>","text":"<p>A decorator that makes this class run remotely.</p> <p>:param remote_call decorator: The remote call decorator. :return: A decorated class.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/factory.py</code> <pre><code>def remote_class(decorator):\n    \"\"\"\n    A decorator that makes this class run remotely.\n\n    :param remote_call decorator: The remote call decorator.\n    :return: A decorated class.\n    \"\"\"\n    def decorate(cls):\n        for attribute, value in cls.__dict__.items():\n            validate_class_method(cls, value)\n            if callable(getattr(cls, attribute)):\n                setattr(cls, attribute, decorator(getattr(cls, attribute)))\n        return cls\n    return decorate\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.html","title":"server","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.server.RPCServer","title":"<code>RPCServer</code>","text":"<p>               Bases: <code>BaseRPCServerManager</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.py</code> <pre><code>class RPCServer(BaseRPCServerManager):\n    def __init__(self, port=None):\n        \"\"\"\n        Initialize the blender rpc server, with its name and specific port.\n        \"\"\"\n        super(RPCServer, self).__init__()\n        self.name = 'RPCServer'\n        self.port = int(os.environ.get('RPC_PORT', port))\n        self.threaded_server_class = RPCServerThread\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.server.RPCServer.__init__","title":"<code>__init__(port=None)</code>","text":"<p>Initialize the blender rpc server, with its name and specific port.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.py</code> <pre><code>def __init__(self, port=None):\n    \"\"\"\n    Initialize the blender rpc server, with its name and specific port.\n    \"\"\"\n    super(RPCServer, self).__init__()\n    self.name = 'RPCServer'\n    self.port = int(os.environ.get('RPC_PORT', port))\n    self.threaded_server_class = RPCServerThread\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.server.RPCServerThread","title":"<code>RPCServerThread</code>","text":"<p>               Bases: <code>BaseRPCServerThread</code></p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.py</code> <pre><code>class RPCServerThread(BaseRPCServerThread):\n    def thread_safe_call(self, callable_instance, *args):\n        \"\"\"\n        Implementation of a thread safe call in Unreal.\n        \"\"\"\n        return callable_instance(*args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.server.RPCServerThread.thread_safe_call","title":"<code>thread_safe_call(callable_instance, *args)</code>","text":"<p>Implementation of a thread safe call in Unreal.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/server.py</code> <pre><code>def thread_safe_call(self, callable_instance, *args):\n    \"\"\"\n    Implementation of a thread safe call in Unreal.\n    \"\"\"\n    return callable_instance(*args)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.html","title":"validations","text":""},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.validations.get_line_link","title":"<code>get_line_link(function)</code>","text":"<p>Gets the line number of a function.</p> <p>:param callable function: A callable. :return int: The line number</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.py</code> <pre><code>def get_line_link(function):\n    \"\"\"\n    Gets the line number of a function.\n\n    :param callable function: A callable.\n    :return int: The line number\n    \"\"\"\n    lines, line_number = inspect.getsourcelines(function)\n    file_path = get_source_file_path(function)\n    return f'  File \"{file_path}\", line {line_number}'\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.validations.get_source_file_path","title":"<code>get_source_file_path(function)</code>","text":"<p>Gets the full path to the source code.</p> <p>:param callable function: A callable. :return str: A file path.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.py</code> <pre><code>def get_source_file_path(function):\n    \"\"\"\n    Gets the full path to the source code.\n\n    :param callable function: A callable.\n    :return str: A file path.\n    \"\"\"\n    client_module = inspect.getmodule(function)\n    return client_module.__file__\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.validations.validate_arguments","title":"<code>validate_arguments(function, args)</code>","text":"<p>Validates arguments to ensure they are a supported type.</p> <p>:param callable function: A function reference. :param tuple(Any) args: A list of arguments.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.py</code> <pre><code>def validate_arguments(function, args):\n    \"\"\"\n    Validates arguments to ensure they are a supported type.\n\n    :param callable function: A function reference.\n    :param tuple(Any) args: A list of arguments.\n    \"\"\"\n    supported_types = [str, int, float, tuple, list, dict, bool]\n    line_link = get_line_link(function)\n    for arg in args:\n        if arg is None:\n            continue\n\n        if type(arg) not in supported_types:\n            raise UnsupportedArgumentType(function, arg, supported_types, line_link=line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.validations.validate_class_method","title":"<code>validate_class_method(cls, method)</code>","text":"<p>Validates a method on a class.</p> <p>:param Any cls: A class. :param callable method: A callable.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.py</code> <pre><code>def validate_class_method(cls, method):\n    \"\"\"\n    Validates a method on a class.\n\n    :param Any cls: A class.\n    :param callable method: A callable.\n    \"\"\"\n    if callable(method) and not isinstance(method, staticmethod):\n        line_link = get_line_link(method)\n        raise InvalidClassMethod(cls, method, line_link=line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.validations.validate_file_is_saved","title":"<code>validate_file_is_saved(function)</code>","text":"<p>Validates that the file that the function is from is saved on disk.</p> <p>:param callable function: A callable.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.py</code> <pre><code>def validate_file_is_saved(function):\n    \"\"\"\n    Validates that the file that the function is from is saved on disk.\n\n    :param callable function: A callable.\n    \"\"\"\n    try:\n        inspect.getsourcelines(function)\n    except OSError:\n        raise FileNotSavedOnDisk(function)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.validations.validate_key_word_parameters","title":"<code>validate_key_word_parameters(function, kwargs)</code>","text":"<p>Validates a method on a class.</p> <p>:param callable function: A callable. :param dict kwargs: A dictionary of key word arguments.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.py</code> <pre><code>def validate_key_word_parameters(function, kwargs):\n    \"\"\"\n    Validates a method on a class.\n\n    :param callable function: A callable.\n    :param dict kwargs: A dictionary of key word arguments.\n    \"\"\"\n    if kwargs:\n        line_link = get_line_link(function)\n        raise InvalidKeyWordParameters(function, kwargs, line_link=line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.html#client.ayon_deadline.repository.custom.plugins.UnrealEngine5.ue_utils.rpc.validations.validate_test_case_class","title":"<code>validate_test_case_class(cls)</code>","text":"<p>This is use to validate a subclass of RPCTestCase. While building your test suite you can call this method on each class preemptively to validate that it was defined correctly.</p> <p>:param RPCTestCase cls: A class. :param str file_path: Optionally, a file path to the test case can be passed to give further context into where the error is occurring.</p> Source code in <code>client/ayon_deadline/repository/custom/plugins/UnrealEngine5/ue_utils/rpc/validations.py</code> <pre><code>def validate_test_case_class(cls):\n    \"\"\"\n    This is use to validate a subclass of RPCTestCase. While building your test\n    suite you can call this method on each class preemptively to validate that it\n    was defined correctly.\n\n    :param RPCTestCase cls: A class.\n    :param str file_path: Optionally, a file path to the test case can be passed to give\n    further context into where the error is occurring.\n    \"\"\"\n    line_link = get_line_link(cls)\n    if not cls.__dict__.get('port'):\n        raise InvalidTestCasePort(cls, line_link=line_link)\n\n    for attribute, method in cls.__dict__.items():\n        if callable(method) and not isinstance(method, staticmethod):\n            if method.__name__.startswith('test'):\n                raise InvalidClassMethod(cls, method, line_link=line_link)\n</code></pre>"},{"location":"autoapi/client/ayon_deadline/scripts/index.html","title":"scripts","text":""},{"location":"autoapi/client/ayon_deadline/scripts/remote_publish.html","title":"remote_publish","text":""},{"location":"autoapi/server/index.html","title":"server","text":""},{"location":"autoapi/server/settings/index.html","title":"settings","text":""},{"location":"autoapi/server/settings/main.html","title":"main","text":""},{"location":"autoapi/server/settings/main.html#server.settings.main.ServerItemSubmodel","title":"<code>ServerItemSubmodel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Connection info about configured DL servers.</p> Source code in <code>server/settings/main.py</code> <pre><code>class ServerItemSubmodel(BaseSettingsModel):\n    \"\"\"Connection info about configured DL servers.\"\"\"\n    _layout = \"expanded\"\n    name: str = SettingsField(title=\"Name\")\n    value: str = SettingsField(title=\"Url\")\n    require_authentication: bool = SettingsField(\n        False, title=\"Require authentication\")\n    not_verify_ssl: bool = SettingsField(\n        False, title=\"Don't verify SSL\")\n    default_username: str = SettingsField(\n        \"\",\n        title=\"Default user name\",\n        description=\"Webservice username, 'Require authentication' must be \"\n                    \"enabled.\"\n    )\n    default_password: str = SettingsField(\n        \"\",\n        title=\"Default password\",\n        description=\"Webservice password, 'Require authentication' must be \"\n                    \"enabled.\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/main.html#server.settings.main.defined_deadline_ws_name_enum_resolver","title":"<code>defined_deadline_ws_name_enum_resolver(addon, settings_variant=None)</code>  <code>async</code>","text":"<p>Provides list of names of configured Deadline webservice urls.</p> Source code in <code>server/settings/main.py</code> <pre><code>async def defined_deadline_ws_name_enum_resolver(\n    addon: \"BaseServerAddon\",\n    settings_variant: str = None,\n) -&gt; list[str]:\n    \"\"\"Provides list of names of configured Deadline webservice urls.\"\"\"\n    if addon is None:\n        return []\n\n    settings = await addon.get_studio_settings(variant=settings_variant)\n\n    ws_server_name = []\n    for deadline_url_item in settings.deadline_urls:\n        ws_server_name.append(deadline_url_item.name)\n\n    return ws_server_name\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html","title":"publish_plugins","text":""},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.FusionSubmitDeadlineModel","title":"<code>FusionSubmitDeadlineModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Fusion-specific settings</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class FusionSubmitDeadlineModel(BaseSettingsModel):\n    \"\"\"Fusion-specific settings\"\"\"\n    plugin: str = SettingsField(\"Fusion\",\n                                enum_resolver=fusion_deadline_plugin_enum,\n                                title=\"Deadline Plugin\")\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.HoudiniSubmitDeadlineModel","title":"<code>HoudiniSubmitDeadlineModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Houdini Export Job settings</p> <p>Submitting from Houdini can be configured to first export a renderable scene file (e.g. <code>usd</code>, <code>ifd</code>, <code>ass</code>) instead of rendering directly from the Houdini file. These settings apply to this Houdini Export Job.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class HoudiniSubmitDeadlineModel(BaseSettingsModel):\n    \"\"\"Houdini Export Job settings\n\n    Submitting from Houdini can be configured to first export a renderable\n    scene file (e.g. `usd`, `ifd`, `ass`) instead of rendering directly from\n    the Houdini file. These settings apply to this Houdini **Export Job**.\n    \"\"\"\n\n    export_priority: int = SettingsField(title=\"Export Priority\")\n    export_chunk_size: int = SettingsField(title=\"Export Frames Per Task\")\n    export_group: str = SettingsField(title=\"Export Group\")\n    export_limits: str = SettingsField(\n        title=\"Export Limit Groups\",\n        description=(\n            \"Enter a comma separated list of limits.\\n\"\n            \"Specifies the limit groups that this job is a member\"\n            \" of (default = blank).\"\n        )\n    )\n    export_machine_limit: int = SettingsField(\n        title=\"Export Machine Limit\",\n        description=(\n            \"Specifies the maximum number of machines this job can be\"\n            \" rendered on at the same time (default = 0, which means\"\n            \" unlimited).\"\n        )\n    )\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.MayaSubmitDeadlineModel","title":"<code>MayaSubmitDeadlineModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Maya-specific settings</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class MayaSubmitDeadlineModel(BaseSettingsModel):\n    \"\"\"Maya-specific settings\"\"\"\n\n    import_reference: bool = SettingsField(\n        title=\"Use Scene with Imported Reference\"\n    )\n    tile_priority: int = SettingsField(title=\"Tile Priority\")\n\n    tile_assembler_plugin: str = SettingsField(\n        title=\"Tile Assembler Plugin\",\n        enum_resolver=tile_assembler_enum,\n    )\n\n    scene_patches: list[ScenePatchesSubmodel] = SettingsField(\n        default_factory=list,\n        title=\"Scene patches\",\n    )\n    strict_error_checking: bool = SettingsField(\n        title=\"Disable Strict Error Check profiles\"\n    )\n\n    @validator(\"scene_patches\")\n    def validate_unique_names(cls, value):\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.NukeSubmitDeadlineModel","title":"<code>NukeSubmitDeadlineModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke-specific settings</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class NukeSubmitDeadlineModel(BaseSettingsModel):\n    \"\"\"Nuke-specific settings\"\"\"\n\n    use_gpu: bool = SettingsField(True, title=\"Use GPU\")\n    node_class_limit_groups: list[LimitGroupsSubmodel] = SettingsField(\n        default_factory=list,\n        title=\"Node based Limit Groups\",\n        description=\n            \"Provide list of Nuke node classes to get particular limit group. \"\n            \"Example: 'OFX.absoft.neatvideo5_v5'\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.ProcessCacheJobFarmModel","title":"<code>ProcessCacheJobFarmModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Houdini cache submission settings</p> <p>These settings apply only to Houdini cache publish jobs. Those are the publish jobs for any farm submitted caching, like for Alembic or VDB products.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class ProcessCacheJobFarmModel(BaseSettingsModel):\n    \"\"\"Houdini cache submission settings\n\n    These settings apply only to Houdini cache publish jobs. Those are the\n    **publish jobs** for any farm submitted caching, like for Alembic\n    or VDB products.\n    \"\"\"\n\n    deadline_priority: int = SettingsField(title=\"Priority\")\n    deadline_group: str = SettingsField(title=\"Group\")\n    deadline_pool: str = SettingsField(title=\"Pool\")\n    deadline_department: str = SettingsField(title=\"Department\")\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.ProcessSubmittedJobOnFarmModel","title":"<code>ProcessSubmittedJobOnFarmModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Publish job settings</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class ProcessSubmittedJobOnFarmModel(BaseSettingsModel):\n    \"\"\"Publish job settings\"\"\"\n\n    deadline_priority: int = SettingsField(title=\"Priority\")\n    deadline_group: str = SettingsField(title=\"Group\")\n    deadline_pool: str = SettingsField(title=\"Pool\")\n    deadline_department: str = SettingsField(title=\"Department\")\n    skip_integration_repre_list: list[str] = SettingsField(\n        default_factory=list,\n        title=\"Skip integration of representation with ext\"\n    )\n    families_transfer: list[str] = SettingsField(\n        default_factory=list,\n        title=(\n            \"List of family names to transfer\\n\"\n            \"to generated instances (AOVs for example).\"\n        )\n    )\n    aov_filter: list[AOVFilterSubmodel] = SettingsField(\n        default_factory=list,\n        title=\"Reviewable products filter\",\n    )\n\n    add_rendered_dependencies: bool = SettingsField(\n        False,\n        title=\"Add rendered files as Dependencies\",\n        description=\"Add all expected rendered files as job Dependencies.\"\n                    \"Publish job won't trigger until all files are present.\"\n    )\n\n    @validator(\"aov_filter\")\n    def validate_unique_names(cls, value):\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.ValidateExpectedFilesModel","title":"<code>ValidateExpectedFilesModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Validate render frames match the job's expected outputs.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class ValidateExpectedFilesModel(BaseSettingsModel):\n    \"\"\"Validate render frames match the job's expected outputs.\"\"\"\n    enabled: bool = SettingsField(True, title=\"Enabled\")\n    active: bool = SettingsField(True, title=\"Active\")\n    allow_user_override: bool = SettingsField(\n        True, title=\"Allow user change frame range\",\n        description=(\n            \"Allow user to override the frame range of the job in Deadline \"\n            \"Monitor and use this as the new expected files. \"\n            \"This is useful when artist should be allowed control on the \"\n            \"render frame range.\"\n        )\n    )\n    families: list[str] = SettingsField(\n        default_factory=list, title=\"Trigger on families\"\n    )\n    targets: list[str] = SettingsField(\n        default_factory=list, title=\"Trigger for plugins\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.extract_jobinfo_overrides_enum","title":"<code>extract_jobinfo_overrides_enum()</code>","text":"<p>Enum of fields that could be overridden by artist in Publisher UI</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>def extract_jobinfo_overrides_enum():\n    \"\"\"Enum of fields that could be overridden by artist in Publisher UI\"\"\"\n    return [\n        {\"value\": \"department\", \"label\": \"Department\"},\n        {\"value\": \"job_delay\", \"label\": \"Delay job (timecode dd:hh:mm:ss)\"},\n        {\"value\": \"chunk_size\", \"label\": \"Frames per Task\"},\n        {\"value\": \"group\", \"label\": \"Group\"},\n        {\"value\": \"priority\", \"label\": \"Priority\"},\n        {\"value\": \"limit_groups\", \"label\": \"Limit groups\"},\n        {\"value\": \"primary_pool\", \"label\": \"Primary pool\"},\n        {\"value\": \"secondary_pool\", \"label\": \"Secondary pool\"},\n        {\"value\": \"machine_list\", \"label\": \"Machine List\"},\n        {\"value\": \"machine_list_deny\", \"label\": \"Machine List is a Deny\"},\n        {\"value\": \"concurrent_tasks\", \"label\": \"Number of Concurrent Tasks\"},\n        {\"value\": \"publish_job_state\", \"label\": \"Publish Job State\"},\n    ]\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.fusion_deadline_plugin_enum","title":"<code>fusion_deadline_plugin_enum()</code>","text":"<p>Return a list of value/label dicts for the enumerator.</p> <p>Returning a list of dicts is used to allow for a custom label to be displayed in the UI.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>def fusion_deadline_plugin_enum():\n    \"\"\"Return a list of value/label dicts for the enumerator.\n\n    Returning a list of dicts is used to allow for a custom label to be\n    displayed in the UI.\n    \"\"\"\n    return [\n        {\n            \"value\": \"Fusion\",\n            \"label\": \"Fusion\"\n        },\n        {\n            \"value\": \"FusionCmd\",\n            \"label\": \"FusionCmd\"\n        }\n    ]\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.publish_job_state_enum","title":"<code>publish_job_state_enum()</code>","text":"<p>Enum for initial state of publish job</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>def publish_job_state_enum():\n    \"\"\"Enum for initial state of publish job\"\"\"\n    return [\n        {\"value\": \"active\", \"label\": \"Active\"},\n        {\"value\": \"suspended\", \"label\": \"Suspended\"},\n    ]\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.tile_assembler_enum","title":"<code>tile_assembler_enum()</code>","text":"<p>Return a list of value/label dicts for the enumerator.</p> <p>Returning a list of dicts is used to allow for a custom label to be displayed in the UI.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>def tile_assembler_enum():\n    \"\"\"Return a list of value/label dicts for the enumerator.\n\n    Returning a list of dicts is used to allow for a custom label to be\n    displayed in the UI.\n    \"\"\"\n    return [\n        {\n            \"value\": \"DraftTileAssembler\",\n            \"label\": \"Draft Tile Assembler\"\n        }\n    ]\n</code></pre>"},{"location":"autoapi/server/settings/site_settings.html","title":"site_settings","text":""},{"location":"autoapi/server/settings/site_settings.html#server.settings.site_settings.CredentialPerServerModel","title":"<code>CredentialPerServerModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Provide credentials for configured DL servers</p> Source code in <code>server/settings/site_settings.py</code> <pre><code>class CredentialPerServerModel(BaseSettingsModel):\n    \"\"\"Provide credentials for configured DL servers\"\"\"\n    _layout = \"expanded\"\n    server_name: str = SettingsField(\n        \"\",\n        title=\"DL server name\",\n        enum_resolver=defined_deadline_ws_name_enum_resolver\n    )\n    username: str = SettingsField(\"\", title=\"Username\")\n    password: str = SettingsField(\"\", title=\"Password\")\n</code></pre>"}]}